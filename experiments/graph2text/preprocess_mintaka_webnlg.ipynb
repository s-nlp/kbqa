{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2fdd94f5-d0c7-43fd-ac18-b63a441d917f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32757\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from datasets import load_dataset\n",
    "\n",
    "ds = \"mixtral\"\n",
    "train_ds = load_dataset(\"s-nlp/KGQA_Subgraphs_Ranking\", f\"{ds}_subgraphs\")[\n",
    "    \"train\"\n",
    "].to_pandas()\n",
    "test_ds = load_dataset(\"s-nlp/KGQA_Subgraphs_Ranking\", f\"{ds}_subgraphs\")[\n",
    "    \"test\"\n",
    "].to_pandas()\n",
    "dev_ds = load_dataset(\"s-nlp/KGQA_Subgraphs_Ranking\", f\"{ds}_subgraphs\")[\n",
    "    \"validation\"\n",
    "].to_pandas()\n",
    "\n",
    "print(len(dev_ds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0c115d7f-9c03-47b3-a01a-e9ee8539a969",
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_counter = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "aeff9d9f-8123-46aa-bf98-b44307a021b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "\n",
    "entity_status_linker = {\n",
    "    \"INTERNAL\": 0,\n",
    "    \"QUESTIONS_ENTITY\": 1,\n",
    "    \"ANSWER_CANDIDATE_ENTITY\": 2,\n",
    "}\n",
    "\n",
    "\n",
    "def get_webnlg_like_mapper(data, i):\n",
    "    webnlg_mapper = {}\n",
    "    graph = ast.literal_eval(data[\"graph\"][i])\n",
    "    links = graph[\"links\"]\n",
    "    nodes = graph[\"nodes\"]\n",
    "\n",
    "    for node in nodes:\n",
    "        if node[\"label\"] == None:\n",
    "            node_label = \"unknown entity\"\n",
    "        else:\n",
    "            node_label = node[\"label\"]\n",
    "        webnlg_mapper[node[\"id\"]] = {\"source_label\": node_label, \"type\": node[\"type\"]}\n",
    "    for link in links:\n",
    "        link_dict = {}\n",
    "        link_dict[\"target_label\"] = webnlg_mapper[link[\"target\"]][\"source_label\"]\n",
    "        link_dict[\"relation_label\"] = link[\"label\"]\n",
    "        links_array = webnlg_mapper[link[\"source\"]].get(\"links_array\", -1)\n",
    "        if links_array == -1:\n",
    "            webnlg_mapper[link[\"source\"]][\"links_array\"] = [link_dict]\n",
    "        else:\n",
    "            webnlg_mapper[link[\"source\"]][\"links_array\"].append(link_dict)\n",
    "    return webnlg_mapper\n",
    "\n",
    "\n",
    "def get_json_format(webnlg_mapper):\n",
    "    json_converet = {}\n",
    "    ind = 0\n",
    "    for j, indx in enumerate(webnlg_mapper):\n",
    "        source_label = webnlg_mapper[indx].get(\"source_label\", -1)\n",
    "        entity_type = entity_status_linker[webnlg_mapper[indx][\"type\"]]\n",
    "        links_array = webnlg_mapper[indx].get(\"links_array\", -1)\n",
    "        if links_array == -1:\n",
    "            pass\n",
    "        else:\n",
    "            for link_dict in links_array:\n",
    "                target_label = link_dict[\"target_label\"]\n",
    "                relation_label = link_dict[\"relation_label\"]\n",
    "                json_converet[f\"W{ind}\"] = [\n",
    "                    source_label,\n",
    "                    source_label,\n",
    "                    [[relation_label, target_label]],\n",
    "                    entity_type,\n",
    "                ]\n",
    "                ind += 1\n",
    "    return json_converet\n",
    "\n",
    "\n",
    "def convert_to_webnlg_format(data, i):\n",
    "    webnlg_format = {}\n",
    "    webnlg_mapper = get_webnlg_like_mapper(data, i)\n",
    "    json_converet = get_json_format(webnlg_mapper)\n",
    "    webnlg_format[\"id\"] = i\n",
    "    webnlg_format[\"kbs\"] = json_converet\n",
    "    webnlg_format[\"text\"] = [\"example of text\"]\n",
    "\n",
    "    return webnlg_format\n",
    "\n",
    "\n",
    "def get_all_entities_per_sample(mark_entity_number, mark_entity, entry):\n",
    "    text_entity = set()\n",
    "    text_relation = set()\n",
    "    for entity_id in mark_entity_number:\n",
    "        entity = entry[\"kbs\"][entity_id]\n",
    "        if len(entity[0]) == 0:\n",
    "            continue\n",
    "        for rel in entity[2]:\n",
    "            if len(rel[0]) != 0 and len(rel[1]) != 0:\n",
    "                text_relation.add(rel[0])\n",
    "                text_entity.add(rel[1])\n",
    "\n",
    "    text_entity_list = list(text_entity) + list(text_relation)\n",
    "    text_relation_list = list(text_relation)\n",
    "    for entity_ele in mark_entity:\n",
    "        if entity_ele in text_entity_list:\n",
    "            text_entity_list.remove(entity_ele)\n",
    "\n",
    "    return text_entity_list, text_relation_list  # все кроме start entities\n",
    "\n",
    "\n",
    "def filter_entities_by_len(entry, limit=51):\n",
    "    webnlg_format = entry\n",
    "    array_of_entities = []\n",
    "    for key, value in webnlg_format[\"kbs\"].items():\n",
    "        array_of_entities.append((value[0], value[1], value[2], value[3]))\n",
    "    sorted_array_of_entities = sorted(\n",
    "        array_of_entities, key=lambda x: x[3], reverse=True\n",
    "    )\n",
    "\n",
    "    curr_len = check_total_len(entry)\n",
    "\n",
    "    global filter_counter\n",
    "    if curr_len > limit:\n",
    "        filter_counter = filter_counter + 1\n",
    "    while curr_len > limit:\n",
    "        webnlg_format = {}\n",
    "        sorted_array_of_entities = sorted_array_of_entities[\n",
    "            : len(sorted_array_of_entities) - 1\n",
    "        ]\n",
    "        json_converet = {}\n",
    "\n",
    "        for ind, entity in enumerate(sorted_array_of_entities):\n",
    "            json_converet[f\"W{ind}\"] = [entity[0], entity[1], entity[2]]\n",
    "\n",
    "        webnlg_format[\"id\"] = entry[\"id\"]\n",
    "        webnlg_format[\"kbs\"] = json_converet\n",
    "        webnlg_format[\"text\"] = [\"example of text\"]\n",
    "        curr_len = check_total_len(webnlg_format)\n",
    "\n",
    "    return webnlg_format\n",
    "\n",
    "\n",
    "def check_total_len(entry):\n",
    "    entities = []\n",
    "    for _ in entry[\"kbs\"]:\n",
    "        entities.append(_)\n",
    "\n",
    "    mark_entity = [entry[\"kbs\"][ele_entity][0] for ele_entity in entities]\n",
    "    mark_entity_number = entities\n",
    "    text_entity, text_relation = get_all_entities_per_sample(\n",
    "        mark_entity_number, mark_entity, entry\n",
    "    )\n",
    "    total_entity = mark_entity + text_entity\n",
    "\n",
    "    return len(total_entity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b6e4797c-5af2-4480-a507-1cc52e5d6cb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9749/9749 [00:01<00:00, 6077.69it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "list_of_data = []\n",
    "for i in tqdm(range(len(test_ds))):\n",
    "    webnlg_format = convert_to_webnlg_format(test_ds, i)\n",
    "    # right_data = filter_entities_by_len(webnlg_format, 51)\n",
    "    right_data = webnlg_format\n",
    "\n",
    "    list_of_data.append(right_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "89f96d2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "Path(f\"./data/{ds}\").mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e2735c30-9dec-4cb4-a731-52b81f7bca2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9749\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "with open(f\"./configs/data/{ds}/test.json\", \"w+\") as f:\n",
    "    json.dump(list_of_data, f)\n",
    "print(len(list_of_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d5a9ebaf-642b-4149-b2a9-2d775af22ee7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 32757/32757 [00:05<00:00, 5885.47it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "list_of_data_train = []\n",
    "for i in tqdm(range(len(train_ds))):\n",
    "    webnlg_format = convert_to_webnlg_format(train_ds, i)\n",
    "    # right_data = filter_entities_by_len(webnlg_format, 51)\n",
    "    right_data = webnlg_format\n",
    "\n",
    "    list_of_data_train.append(right_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "77e4788d-f9e7-4b7d-a35b-440e232c09c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32757\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "with open(f\"./configs/data/{ds}/train.json\", \"w+\") as f:\n",
    "    json.dump(list_of_data_train, f)\n",
    "print(len(list_of_data_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b56b2fe2-dafc-4aad-8909-549df9758d24",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 358/32757 [00:00<00:09, 3572.58it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 32757/32757 [00:05<00:00, 5605.12it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "list_of_data_dev = []\n",
    "for i in tqdm(range(len(dev_ds))):\n",
    "    webnlg_format = convert_to_webnlg_format(dev_ds, i)\n",
    "    # right_data = webnlg_format\n",
    "    right_data = filter_entities_by_len(webnlg_format, 51)\n",
    "    list_of_data_dev.append(right_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "968a5b89-cb87-4075-a60d-a472f1fd23c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32757\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "with open(f\"./configs/data/{ds}/dev.json\", \"w\") as f:\n",
    "    json.dump(list_of_data_dev, f)\n",
    "print(len(list_of_data_dev))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
