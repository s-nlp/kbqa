{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "import torch\n",
    "sys.path.append(\"/workspace/kbqa/\")  # go to parent dir\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reading and Processing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading train and test\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "print('reading train and test')\n",
    "processed_train_df = pd.read_csv('/workspace/storage/misc/features_reranking/features_train_new_seqs.csv')\n",
    "processed_test_df = pd.read_csv('/workspace/storage/misc/features_reranking/features_test_new_seqs.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to whether use embedding features or not\n",
    "use_embeddings = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def get_numeric_cols(df):\n",
    "    \"\"\"return all cols with numeric features\"\"\"\n",
    "    cols_numeric = []\n",
    "    for k, v in df.dtypes.to_dict().items():\n",
    "        if (v is np.dtype(\"int64\") or v is np.dtype(\"float64\")) and k != \"correct\":\n",
    "            cols_numeric.append(k)\n",
    "\n",
    "    return cols_numeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "\n",
    "\n",
    "def apply_col_scale(df, col):\n",
    "    \"\"\"apply min max scaling\"\"\"\n",
    "    df[col] = min_max_scaler.fit_transform(df[col])\n",
    "    return df\n",
    "\n",
    "\n",
    "# get the numerica cols in train and test to scale\n",
    "train_numeric_cols = get_numeric_cols(processed_train_df)\n",
    "test_numeric_cols = get_numeric_cols(processed_test_df)\n",
    "\n",
    "processed_train_df = apply_col_scale(processed_train_df, train_numeric_cols)\n",
    "processed_test_df = apply_col_scale(processed_test_df, test_numeric_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>question_answer</th>\n",
       "      <th>num_nodes</th>\n",
       "      <th>num_edges</th>\n",
       "      <th>density</th>\n",
       "      <th>cycle</th>\n",
       "      <th>bridge</th>\n",
       "      <th>katz_centrality</th>\n",
       "      <th>page_rank</th>\n",
       "      <th>avg_ssp_length</th>\n",
       "      <th>graph_sequence</th>\n",
       "      <th>graph_sequence_embedding</th>\n",
       "      <th>updated_graph_sequence_embedding</th>\n",
       "      <th>question_answer_embedding</th>\n",
       "      <th>tfidf_vector</th>\n",
       "      <th>correct</th>\n",
       "      <th>updated_graph_sequence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What is the seventh tallest mountain in North ...</td>\n",
       "      <td>What is the seventh tallest mountain in North ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.217391</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0625</td>\n",
       "      <td>0.874914</td>\n",
       "      <td>0.53152</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Mount Rainier,continent,North America</td>\n",
       "      <td>0.034756005,-0.023538165,-0.01432218,0.0284024...</td>\n",
       "      <td>0.0307673,0.009273613,-0.018254131,0.04655365,...</td>\n",
       "      <td>0.010093523,0.0059077474,-0.0011233741,0.02769...</td>\n",
       "      <td>7.074399696475794,7.029381555603603,6.89603869...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Mount Rainier is located in North America.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What is the seventh tallest mountain in North ...</td>\n",
       "      <td>What is the seventh tallest mountain in North ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.017857</td>\n",
       "      <td>0.478261</td>\n",
       "      <td>0.001898</td>\n",
       "      <td>0.0625</td>\n",
       "      <td>0.938945</td>\n",
       "      <td>0.76576</td>\n",
       "      <td>0.0</td>\n",
       "      <td>North America,shares border with,Eurasia,Euras...</td>\n",
       "      <td>0.006314811,0.013446206,-0.030191861,-0.004628...</td>\n",
       "      <td>0.0018651504,0.018196316,-0.014988141,-0.01599...</td>\n",
       "      <td>0.021559492,-0.003825337,-0.0013305206,0.00150...</td>\n",
       "      <td>7.074399696475794,7.029381555603603,6.89603869...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>North America and Eurasia share a border.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What is the seventh tallest mountain in North ...</td>\n",
       "      <td>What is the seventh tallest mountain in North ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.035714</td>\n",
       "      <td>0.739130</td>\n",
       "      <td>0.003795</td>\n",
       "      <td>0.0625</td>\n",
       "      <td>0.938945</td>\n",
       "      <td>0.76576</td>\n",
       "      <td>0.0</td>\n",
       "      <td>North America,has part(s),Greenland,Greenland,...</td>\n",
       "      <td>0.024753027,-0.004211257,-0.042537164,-0.03131...</td>\n",
       "      <td>0.02677703,0.013835486,-0.029348638,-0.0018101...</td>\n",
       "      <td>0.024931252,0.007847421,-0.010111074,-5.701548...</td>\n",
       "      <td>7.074399696475794,7.029381555603603,6.89603869...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Greenland is part of North America.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question  \\\n",
       "0  What is the seventh tallest mountain in North ...   \n",
       "1  What is the seventh tallest mountain in North ...   \n",
       "2  What is the seventh tallest mountain in North ...   \n",
       "\n",
       "                                     question_answer  num_nodes  num_edges  \\\n",
       "0  What is the seventh tallest mountain in North ...        0.0   0.000000   \n",
       "1  What is the seventh tallest mountain in North ...        0.0   0.017857   \n",
       "2  What is the seventh tallest mountain in North ...        0.0   0.035714   \n",
       "\n",
       "    density     cycle  bridge  katz_centrality  page_rank  avg_ssp_length  \\\n",
       "0  0.217391  0.000000  0.0625         0.874914    0.53152             0.0   \n",
       "1  0.478261  0.001898  0.0625         0.938945    0.76576             0.0   \n",
       "2  0.739130  0.003795  0.0625         0.938945    0.76576             0.0   \n",
       "\n",
       "                                      graph_sequence  \\\n",
       "0              Mount Rainier,continent,North America   \n",
       "1  North America,shares border with,Eurasia,Euras...   \n",
       "2  North America,has part(s),Greenland,Greenland,...   \n",
       "\n",
       "                            graph_sequence_embedding  \\\n",
       "0  0.034756005,-0.023538165,-0.01432218,0.0284024...   \n",
       "1  0.006314811,0.013446206,-0.030191861,-0.004628...   \n",
       "2  0.024753027,-0.004211257,-0.042537164,-0.03131...   \n",
       "\n",
       "                    updated_graph_sequence_embedding  \\\n",
       "0  0.0307673,0.009273613,-0.018254131,0.04655365,...   \n",
       "1  0.0018651504,0.018196316,-0.014988141,-0.01599...   \n",
       "2  0.02677703,0.013835486,-0.029348638,-0.0018101...   \n",
       "\n",
       "                           question_answer_embedding  \\\n",
       "0  0.010093523,0.0059077474,-0.0011233741,0.02769...   \n",
       "1  0.021559492,-0.003825337,-0.0013305206,0.00150...   \n",
       "2  0.024931252,0.007847421,-0.010111074,-5.701548...   \n",
       "\n",
       "                                        tfidf_vector  correct  \\\n",
       "0  7.074399696475794,7.029381555603603,6.89603869...      0.0   \n",
       "1  7.074399696475794,7.029381555603603,6.89603869...      0.0   \n",
       "2  7.074399696475794,7.029381555603603,6.89603869...      0.0   \n",
       "\n",
       "                       updated_graph_sequence  \n",
       "0  Mount Rainier is located in North America.  \n",
       "1   North America and Eurasia share a border.  \n",
       "2         Greenland is part of North America.  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_train_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def str_to_arr(str):\n",
    "    arr = str.split(',')\n",
    "    arr = [float(a) for a in arr]\n",
    "    return np.array(arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_features = [\n",
    "        \"graph_sequence_embedding\",\n",
    "        \"tfidf_vector\",\n",
    "        \"question_answer_embedding\",\n",
    "        \"updated_graph_sequence_embedding\",\n",
    "    ]\n",
    "text_features = [\"question_answer\", \"graph_sequence\", \"updated_graph_sequence\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_emb(df, em_type):\n",
    "    \"\"\" split embeddings into individual rows\"\"\"\n",
    "    embeddings = df[em_type].tolist()\n",
    "    emb_dict = {}\n",
    "    for emb in embeddings:\n",
    "        for i, val in enumerate(emb):\n",
    "            curr_key = f'{em_type}_{i}'\n",
    "            if curr_key not in emb_dict:\n",
    "                emb_dict[f'{em_type}_{i}'] = [val]\n",
    "            else:\n",
    "                emb_dict[f'{em_type}_{i}'].append(val)\n",
    "    \n",
    "    return pd.DataFrame(emb_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_processed_emb(df):\n",
    "    \"\"\" add all processed embeddings to df\"\"\"\n",
    "    em_df_list = []\n",
    "    for em in embedding_features:   \n",
    "        em_df_list.append(process_emb(df, em))\n",
    "    \n",
    "    df = pd.concat([df] +  em_df_list, axis=1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "turning embeddings str to arr\n",
      "graph_sequence_embedding\n",
      "tfidf_vector\n",
      "question_answer_embedding\n",
      "updated_graph_sequence_embedding\n",
      "adding processed embeddings to train & test\n"
     ]
    }
   ],
   "source": [
    "if use_embeddings: # splitting embeddings into individual cols\n",
    "    print('turning embeddings str to arr')\n",
    "    for e_f in embedding_features:\n",
    "        print(e_f)\n",
    "        processed_train_df[e_f] = processed_train_df[e_f].apply(str_to_arr)\n",
    "        processed_test_df[e_f] = processed_test_df[e_f].apply(str_to_arr)\n",
    "    \n",
    "    print('adding processed embeddings to train & test')\n",
    "    processed_train_df = add_processed_emb(processed_train_df)\n",
    "    processed_test_df = add_processed_emb(processed_test_df)\n",
    "    \n",
    "    processed_train_df = processed_train_df.dropna()\n",
    "    processed_test_df = processed_test_df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_cols = ['correct', 'question'] \n",
    "\n",
    "# dropping all text and embedding features \n",
    "X_train = processed_train_df.drop(drop_cols + embedding_features + text_features, axis=1)\n",
    "y_train = processed_train_df['correct'].tolist()\n",
    "X_test = processed_test_df.drop(drop_cols + embedding_features + text_features, axis=1)\n",
    "y_test = processed_test_df['correct'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearRegression</label><div class=\"sk-toggleable__content\"><pre>LinearRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "regr = linear_model.LinearRegression()\n",
    "regr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = regr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean squared error: 619240740293742080.00\n"
     ]
    }
   ],
   "source": [
    "print(\"Mean squared error: %.2f\" % mean_squared_error(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset parquet (/root/.cache/huggingface/datasets/hle2000___parquet/hle2000--Mintaka_T5_xl_ssm_outputs-9a78025ce7d9a549/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2748d5fc6104ee4ab59cc03eed8c8f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>target</th>\n",
       "      <th>answer_0</th>\n",
       "      <th>answer_1</th>\n",
       "      <th>answer_2</th>\n",
       "      <th>answer_3</th>\n",
       "      <th>answer_4</th>\n",
       "      <th>answer_5</th>\n",
       "      <th>answer_6</th>\n",
       "      <th>answer_7</th>\n",
       "      <th>...</th>\n",
       "      <th>answer_192</th>\n",
       "      <th>answer_193</th>\n",
       "      <th>answer_194</th>\n",
       "      <th>answer_195</th>\n",
       "      <th>answer_196</th>\n",
       "      <th>answer_197</th>\n",
       "      <th>answer_198</th>\n",
       "      <th>answer_199</th>\n",
       "      <th>target_out_of_vocab</th>\n",
       "      <th>__index_level_0__</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What man was a famous American author and also...</td>\n",
       "      <td>Mark Twain</td>\n",
       "      <td>Mark Twain</td>\n",
       "      <td>Mark Twain</td>\n",
       "      <td>Mark Twain</td>\n",
       "      <td>Mark Twain</td>\n",
       "      <td>Mark Twain</td>\n",
       "      <td>Mark Twain</td>\n",
       "      <td>Mark Twain</td>\n",
       "      <td>Mark Twain</td>\n",
       "      <td>...</td>\n",
       "      <td>Louisa May Alcott</td>\n",
       "      <td>Ambrose Bierce</td>\n",
       "      <td>Ishmael Lehman</td>\n",
       "      <td>Mark Twain, Natchez, Missouri</td>\n",
       "      <td>Mark Twain, Louisa</td>\n",
       "      <td>Ishmael Levy</td>\n",
       "      <td>Ishmael Beam</td>\n",
       "      <td>Mark Twain, Natchez, Mississippi</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>How many Academy Awards has Jake Gyllenhaal be...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>13</td>\n",
       "      <td>12</td>\n",
       "      <td>8</td>\n",
       "      <td>11</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>13</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Who is older, The Weeknd or Drake?</td>\n",
       "      <td>Drake</td>\n",
       "      <td>The Weeknd</td>\n",
       "      <td>The Weeknd</td>\n",
       "      <td>The Weeknd</td>\n",
       "      <td>The Weeknd</td>\n",
       "      <td>The Weeknd</td>\n",
       "      <td>The Weeknd</td>\n",
       "      <td>The Weeknd</td>\n",
       "      <td>The Weeknd</td>\n",
       "      <td>...</td>\n",
       "      <td>The Weeknd (2017)</td>\n",
       "      <td>The Weeknd's oldest</td>\n",
       "      <td>The Weeknd is older than Drake</td>\n",
       "      <td>The Weeknd's</td>\n",
       "      <td>Dierks Bentley</td>\n",
       "      <td>The Weeknd\"</td>\n",
       "      <td>Drake &amp; The Weeknd</td>\n",
       "      <td>The Weeknd's age</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>How many children did Donald Trump have?</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>24</td>\n",
       "      <td>6</td>\n",
       "      <td>76</td>\n",
       "      <td>13</td>\n",
       "      <td>61</td>\n",
       "      <td>108</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Is the main hero in Final Fantasy IX named Kuja?</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>...</td>\n",
       "      <td>Is it a Final Fantasy</td>\n",
       "      <td>Does it include Kuja?</td>\n",
       "      <td>Is it</td>\n",
       "      <td>Is he Kuja</td>\n",
       "      <td>Is it No</td>\n",
       "      <td>Y Yes</td>\n",
       "      <td>Is Kuja</td>\n",
       "      <td>Is he called Kuja</td>\n",
       "      <td>False</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 204 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question      target    answer_0  \\\n",
       "0  What man was a famous American author and also...  Mark Twain  Mark Twain   \n",
       "1  How many Academy Awards has Jake Gyllenhaal be...           1           3   \n",
       "2                 Who is older, The Weeknd or Drake?       Drake  The Weeknd   \n",
       "3           How many children did Donald Trump have?           5           5   \n",
       "4   Is the main hero in Final Fantasy IX named Kuja?          No         Yes   \n",
       "\n",
       "     answer_1    answer_2    answer_3    answer_4    answer_5    answer_6  \\\n",
       "0  Mark Twain  Mark Twain  Mark Twain  Mark Twain  Mark Twain  Mark Twain   \n",
       "1           2           3           2           3           2           3   \n",
       "2  The Weeknd  The Weeknd  The Weeknd  The Weeknd  The Weeknd  The Weeknd   \n",
       "3           5           3           5           3           5           3   \n",
       "4         Yes         Yes         Yes         Yes         Yes         Yes   \n",
       "\n",
       "     answer_7  ...             answer_192             answer_193  \\\n",
       "0  Mark Twain  ...      Louisa May Alcott         Ambrose Bierce   \n",
       "1           2  ...                     13                     12   \n",
       "2  The Weeknd  ...      The Weeknd (2017)    The Weeknd's oldest   \n",
       "3           5  ...                     24                      6   \n",
       "4         Yes  ...  Is it a Final Fantasy  Does it include Kuja?   \n",
       "\n",
       "                       answer_194                     answer_195  \\\n",
       "0                  Ishmael Lehman  Mark Twain, Natchez, Missouri   \n",
       "1                               8                             11   \n",
       "2  The Weeknd is older than Drake                   The Weeknd's   \n",
       "3                              76                             13   \n",
       "4                           Is it                     Is he Kuja   \n",
       "\n",
       "           answer_196    answer_197          answer_198  \\\n",
       "0  Mark Twain, Louisa  Ishmael Levy        Ishmael Beam   \n",
       "1                  10             6                   9   \n",
       "2      Dierks Bentley   The Weeknd\"  Drake & The Weeknd   \n",
       "3                  61           108                   0   \n",
       "4            Is it No         Y Yes             Is Kuja   \n",
       "\n",
       "                         answer_199 target_out_of_vocab __index_level_0__  \n",
       "0  Mark Twain, Natchez, Mississippi               False                 0  \n",
       "1                                13               False                 1  \n",
       "2                  The Weeknd's age               False                 2  \n",
       "3                                 8               False                 3  \n",
       "4                 Is he called Kuja               False                 4  \n",
       "\n",
       "[5 rows x 204 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "test_res_csv = load_dataset(f'hle2000/Mintaka_T5_xl_ssm_outputs', verification_mode='no_checks')['test'].to_pandas()\n",
    "test_res_csv.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4000it [02:13, 29.88it/s] \n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "final_acc, top200_total, top1_total, seq2seq_correct = 0, 0, 0, 0\n",
    "    \n",
    "for idx, group in tqdm(test_res_csv.iterrows()):\n",
    "    curr_question_df = processed_test_df[processed_test_df[\"question\"] == group['question']]\n",
    "    curr_question_df = curr_question_df.drop(embedding_features + text_features + ['question'], axis=1)\n",
    "    \n",
    "    if len(curr_question_df) == 0: # we don't have subgraph for this question, take answer from seq2seq\n",
    "        if group[\"answer_0\"] == group[\"target\"]:\n",
    "            seq2seq_correct += 1\n",
    "        else: # check if answer exist in 200 beams for question with no subgraphs\n",
    "            all_beams = group.tolist()[2:-1] # all 200 beams\n",
    "            all_beams = set(all_beams)\n",
    "            top200_total += 1 if group[\"target\"] in all_beams else 0\n",
    "            \n",
    "    else: # we have subgraph for this question  \n",
    "        all_beams = group.tolist()[2:-1] # all 200 beams\n",
    "        all_beams = set(all_beams)\n",
    "        \n",
    "        if group[\"target\"] not in all_beams: # no correct answer in beam\n",
    "            continue\n",
    "            \n",
    "        # correct answer exist in beam\n",
    "        top1_total += 1 if group[\"answer_0\"] == group[\"target\"] else 0\n",
    "        top200_total += 1\n",
    "        \n",
    "        is_corrects = curr_question_df[\"correct\"].astype(bool).tolist()\n",
    "        curr_question_df = curr_question_df.drop('correct', axis=1)\n",
    "        \n",
    "        preds = regr.predict(curr_question_df)\n",
    "        max_idx = preds.argmax()\n",
    "        \n",
    "        if is_corrects[max_idx] is True:\n",
    "            final_acc += 1\n",
    "        \n",
    "            \n",
    "# final rerankinga, top1 and top200 result\n",
    "reranking_res = (final_acc + seq2seq_correct)/ len(test_res_csv)\n",
    "top200 = (top200_total + seq2seq_correct)/len(test_res_csv)\n",
    "top1 = (top1_total + seq2seq_correct)/ len(test_res_csv)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top1: 0.31725, top200: 0.69025, reranking top1: 0.27025\n"
     ]
    }
   ],
   "source": [
    "print(f'top1: {top1}, top200: {top200}, reranking top1: {reranking_res}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
