{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(\"/workspace/kbqa/\")  # go to parent dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-26 12:54:29.517983: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-07-26 12:54:29.684632: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-07-26 12:54:30.256929: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
      "2023-07-26 12:54:30.257006: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
      "2023-07-26 12:54:30.257013: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import ujson\n",
    "import jsonlines\n",
    "import networkx as nx\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForSequenceClassification,\n",
    "    Trainer,\n",
    "    TrainingArguments,\n",
    ")\n",
    "import torch\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Getting JSONL subgraphs dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_type = 't5-large-ssm'\n",
    "new_test_dataset = False \n",
    "train_bs = 16\n",
    "eval_bs = 32\n",
    "is_special_tok_context = False\n",
    "model_weights = None #f\"/workspace/storage/subgraphs_reranking_results/{dataset_type}/results/mse_subgraph_mpnet_ranking_T5LargeSSM\"\n",
    "model_name = \"roberta-large\"\n",
    "model_save_name = f\"{model_name}_mse_token_context\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaForSequenceClassification: ['lm_head.dense.bias', 'roberta.pooler.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.dense.weight', 'lm_head.bias', 'roberta.pooler.dense.weight', 'lm_head.decoder.weight', 'lm_head.layer_norm.bias']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.out_proj.weight', 'classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "if model_weights: # evaluating\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_weights)\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(model_weights).to(\n",
    "        device\n",
    "    )\n",
    "else: # training from scratch\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    tokenizer.add_special_tokens(\n",
    "        {\"additional_special_tokens\": [\"[unused1]\", \"[unused2]\"]}\n",
    "    )\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=1).to(\n",
    "        device\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 98033/98033 [00:00<00:00, 2507333.96it/s]\n",
      "100%|██████████| 14286/14286 [00:00<00:00, 2281095.89it/s]\n",
      "100%|██████████| 28325/28325 [00:00<00:00, 2292666.03it/s]\n"
     ]
    }
   ],
   "source": [
    "def read_jsonl(path):\n",
    "    jsonl_reader = jsonlines.open(path)\n",
    "    jsonl_reader_list = list(jsonl_reader)\n",
    "    df = []\n",
    "    for line in tqdm(jsonl_reader_list):\n",
    "        df.append(line)\n",
    "    df = pd.DataFrame(df)\n",
    "    return df\n",
    "\n",
    "\n",
    "train_df = read_jsonl(\n",
    "    f\"/workspace/storage/new_subgraph_dataset/{dataset_type}/mintaka_train_labeled.jsonl\"\n",
    ")\n",
    "val_df = read_jsonl(\n",
    "    f\"/workspace/storage/new_subgraph_dataset/{dataset_type}/mintaka_validation_labeled.jsonl\"\n",
    ")\n",
    "test_df = read_jsonl(\n",
    "    f\"/workspace/storage/new_subgraph_dataset/{dataset_type}/mintaka_test_labeled.jsonl\"\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Converting graph to its sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_node_names(subgraph, candidate_start_token=\"[unused1]\", candidate_end_token=\"[unused2]\",):\n",
    "    node_names = [subgraph.nodes[node][\"label\"] for node in subgraph.nodes()]\n",
    "    node_type = [subgraph.nodes[node][\"type\"] for node in subgraph.nodes()]\n",
    "    \n",
    "    if 'ANSWER_CANDIDATE_ENTITY' not in node_type:\n",
    "        return None\n",
    "\n",
    "    if is_special_tok_context:\n",
    "        candidate_idx = node_type.index(\"ANSWER_CANDIDATE_ENTITY\")\n",
    "        node_names[\n",
    "            candidate_idx\n",
    "        ] = f\"{candidate_start_token}{node_names[candidate_idx]}{candidate_end_token}\"\n",
    "    \n",
    "    return node_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def graph_to_sequence(subgraph, node_names):\n",
    "    # getting adjency matrix and weight info\n",
    "    adj_matrix = nx.adjacency_matrix(subgraph).todense().tolist()\n",
    "    edge_data = subgraph.edges.data()\n",
    "\n",
    "    # adding our edge info\n",
    "    for edge in edge_data:\n",
    "        i, j, data = edge\n",
    "        i, j = int(i), int(j)\n",
    "        adj_matrix[i][j] = data[\"label\"]\n",
    "\n",
    "    sequence = []\n",
    "    # for adjency matrix, i, j means node i -> j\n",
    "    for i, row in enumerate(adj_matrix):\n",
    "        from_node = node_names[i]  # from node (node i)\n",
    "        for j, edge_info in enumerate(row):\n",
    "            to_node = node_names[j]\n",
    "            if edge_info != 0:  # no endge from_node -> to_node\n",
    "                sequence.extend([from_node, edge_info, to_node])\n",
    "    \n",
    "    sequence = \",\".join(str(node) for node in sequence)\n",
    "    return sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ast import literal_eval\n",
    "from unidecode import unidecode\n",
    "\n",
    "\n",
    "def try_literal_eval(s):\n",
    "    try:\n",
    "        return literal_eval(s)\n",
    "    except ValueError:\n",
    "        return s\n",
    "\n",
    "\n",
    "def get_sequences(df):\n",
    "    questions = list(df[\"question\"])\n",
    "    graphs = list(df[\"graph\"])\n",
    "    graph_seq = []\n",
    "    for question, graph in tqdm(zip(questions, graphs)):\n",
    "        graph_obj = nx.readwrite.json_graph.node_link_graph(try_literal_eval(graph))\n",
    "        try:\n",
    "            graph_node_names = get_node_names(graph_obj)\n",
    "            if graph_node_names is None:\n",
    "                curr_seq = \"ERROR_NO_CANDIDATE\"\n",
    "            else:     \n",
    "                curr_seq = graph_to_sequence(graph_obj, graph_node_names)\n",
    "                if is_special_tok_context:\n",
    "                    curr_seq = f\"{question}{tokenizer.sep_token}{curr_seq}\"\n",
    "        except KeyError:\n",
    "            curr_seq = \"ERROR_NO_LABEL\"\n",
    "        except nx.NetworkXError:\n",
    "            curr_seq = \"ERROR_EMPTY_GRAPH\"\n",
    "        graph_seq.append(curr_seq)\n",
    "    \n",
    "    return graph_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(df):\n",
    "    # get the sequences\n",
    "    df_sequences = get_sequences(df)\n",
    "    df[\"graph_sequence\"] = df_sequences\n",
    "    \n",
    "    # filter out all invalid graphs\n",
    "    error_df = df[\n",
    "        (df[\"graph_sequence\"] == \"ERROR_EMPTY_GRAPH\")\n",
    "        | (df[\"graph_sequence\"] == \"ERROR_NO_LABEL\")\n",
    "        | (df[\"graph_sequence\"] == \"ERROR_NO_CANDIDATE\")\n",
    "    ]\n",
    "    df = df.drop(error_df.index)\n",
    "    \n",
    "    # turn list of entities into string\n",
    "    df[\"answerEntity\"] = df[\"answerEntity\"].apply(lambda x: \", \".join(x))\n",
    "    df[\"questionEntity\"] = df[\"questionEntity\"].apply(lambda x: \", \".join(x))\n",
    "    df[\"groundTruthAnswerEntity\"] = df[\"groundTruthAnswerEntity\"].apply(\n",
    "        lambda x: \", \".join(x)\n",
    "    )\n",
    "    df[\"correct\"] = df.apply(\n",
    "        lambda x: x[\"answerEntity\"] in x[\"groundTruthAnswerEntity\"], axis=1\n",
    "    )\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get train and test texts & labels\n",
    "concat_train_df = pd.concat([train_df, val_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "112319it [00:25, 4399.01it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>question</th>\n",
       "      <th>answerEntity</th>\n",
       "      <th>questionEntity</th>\n",
       "      <th>groundTruthAnswerEntity</th>\n",
       "      <th>complexityType</th>\n",
       "      <th>graph</th>\n",
       "      <th>graph_sequence</th>\n",
       "      <th>correct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a9011ddf</td>\n",
       "      <td>What is the seventh tallest mountain in North ...</td>\n",
       "      <td>Q194057</td>\n",
       "      <td>Q49</td>\n",
       "      <td>Q1153188</td>\n",
       "      <td>ordinal</td>\n",
       "      <td>{'directed': True, 'multigraph': False, 'graph...</td>\n",
       "      <td>Mount Rainier,continent,North America</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a9011ddf</td>\n",
       "      <td>What is the seventh tallest mountain in North ...</td>\n",
       "      <td>Q5401</td>\n",
       "      <td>Q49</td>\n",
       "      <td>Q1153188</td>\n",
       "      <td>ordinal</td>\n",
       "      <td>{'directed': True, 'multigraph': False, 'graph...</td>\n",
       "      <td>North America,shares border with,Eurasia,Euras...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>a9011ddf</td>\n",
       "      <td>What is the seventh tallest mountain in North ...</td>\n",
       "      <td>Q223</td>\n",
       "      <td>Q49</td>\n",
       "      <td>Q1153188</td>\n",
       "      <td>ordinal</td>\n",
       "      <td>{'directed': True, 'multigraph': False, 'graph...</td>\n",
       "      <td>North America,has part(s),Greenland,Greenland,...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>a9011ddf</td>\n",
       "      <td>What is the seventh tallest mountain in North ...</td>\n",
       "      <td>Q1153188</td>\n",
       "      <td>Q49</td>\n",
       "      <td>Q1153188</td>\n",
       "      <td>ordinal</td>\n",
       "      <td>{'directed': True, 'multigraph': False, 'graph...</td>\n",
       "      <td>Canada,country,Canada,Canada,part of,North Ame...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>a9011ddf</td>\n",
       "      <td>What is the seventh tallest mountain in North ...</td>\n",
       "      <td>Q14946340</td>\n",
       "      <td>Q49</td>\n",
       "      <td>Q1153188</td>\n",
       "      <td>ordinal</td>\n",
       "      <td>{'directed': True, 'multigraph': False, 'graph...</td>\n",
       "      <td>North America,category for people who died her...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id                                           question answerEntity  \\\n",
       "0  a9011ddf  What is the seventh tallest mountain in North ...      Q194057   \n",
       "1  a9011ddf  What is the seventh tallest mountain in North ...        Q5401   \n",
       "2  a9011ddf  What is the seventh tallest mountain in North ...         Q223   \n",
       "3  a9011ddf  What is the seventh tallest mountain in North ...     Q1153188   \n",
       "4  a9011ddf  What is the seventh tallest mountain in North ...    Q14946340   \n",
       "\n",
       "  questionEntity groundTruthAnswerEntity complexityType  \\\n",
       "0            Q49                Q1153188        ordinal   \n",
       "1            Q49                Q1153188        ordinal   \n",
       "2            Q49                Q1153188        ordinal   \n",
       "3            Q49                Q1153188        ordinal   \n",
       "4            Q49                Q1153188        ordinal   \n",
       "\n",
       "                                               graph  \\\n",
       "0  {'directed': True, 'multigraph': False, 'graph...   \n",
       "1  {'directed': True, 'multigraph': False, 'graph...   \n",
       "2  {'directed': True, 'multigraph': False, 'graph...   \n",
       "3  {'directed': True, 'multigraph': False, 'graph...   \n",
       "4  {'directed': True, 'multigraph': False, 'graph...   \n",
       "\n",
       "                                      graph_sequence  correct  \n",
       "0              Mount Rainier,continent,North America    False  \n",
       "1  North America,shares border with,Eurasia,Euras...    False  \n",
       "2  North America,has part(s),Greenland,Greenland,...    False  \n",
       "3  Canada,country,Canada,Canada,part of,North Ame...     True  \n",
       "4  North America,category for people who died her...    False  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concat_train_df = preprocess_data(concat_train_df)\n",
    "concat_train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "28325it [00:06, 4676.07it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>question</th>\n",
       "      <th>answerEntity</th>\n",
       "      <th>questionEntity</th>\n",
       "      <th>groundTruthAnswerEntity</th>\n",
       "      <th>complexityType</th>\n",
       "      <th>graph</th>\n",
       "      <th>graph_sequence</th>\n",
       "      <th>correct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>fae46b21</td>\n",
       "      <td>What man was a famous American author and also...</td>\n",
       "      <td>Q893594</td>\n",
       "      <td>Q1497, Q846570</td>\n",
       "      <td>Q7245</td>\n",
       "      <td>intersection</td>\n",
       "      <td>{'directed': True, 'multigraph': False, 'graph...</td>\n",
       "      <td>United States of America,country,United States...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>fae46b21</td>\n",
       "      <td>What man was a famous American author and also...</td>\n",
       "      <td>Q102513</td>\n",
       "      <td>Q1497, Q846570</td>\n",
       "      <td>Q7245</td>\n",
       "      <td>intersection</td>\n",
       "      <td>{'directed': True, 'multigraph': False, 'graph...</td>\n",
       "      <td>United States of America,described by source,S...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>fae46b21</td>\n",
       "      <td>What man was a famous American author and also...</td>\n",
       "      <td>Q7245</td>\n",
       "      <td>Q1497, Q846570</td>\n",
       "      <td>Q7245</td>\n",
       "      <td>intersection</td>\n",
       "      <td>{'directed': True, 'multigraph': False, 'graph...</td>\n",
       "      <td>Mississippi River,described by source,Small Br...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>fae46b21</td>\n",
       "      <td>What man was a famous American author and also...</td>\n",
       "      <td>Q34652890</td>\n",
       "      <td>Q1497, Q846570</td>\n",
       "      <td>Q7245</td>\n",
       "      <td>intersection</td>\n",
       "      <td>{'directed': True, 'multigraph': False, 'graph...</td>\n",
       "      <td>United States of America,country,United States...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>fae46b21</td>\n",
       "      <td>What man was a famous American author and also...</td>\n",
       "      <td>Q5686</td>\n",
       "      <td>Q1497, Q846570</td>\n",
       "      <td>Q7245</td>\n",
       "      <td>intersection</td>\n",
       "      <td>{'directed': True, 'multigraph': False, 'graph...</td>\n",
       "      <td>Mississippi River,described by source,Small Br...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id                                           question answerEntity  \\\n",
       "0  fae46b21  What man was a famous American author and also...      Q893594   \n",
       "1  fae46b21  What man was a famous American author and also...      Q102513   \n",
       "2  fae46b21  What man was a famous American author and also...        Q7245   \n",
       "3  fae46b21  What man was a famous American author and also...    Q34652890   \n",
       "4  fae46b21  What man was a famous American author and also...        Q5686   \n",
       "\n",
       "   questionEntity groundTruthAnswerEntity complexityType  \\\n",
       "0  Q1497, Q846570                   Q7245   intersection   \n",
       "1  Q1497, Q846570                   Q7245   intersection   \n",
       "2  Q1497, Q846570                   Q7245   intersection   \n",
       "3  Q1497, Q846570                   Q7245   intersection   \n",
       "4  Q1497, Q846570                   Q7245   intersection   \n",
       "\n",
       "                                               graph  \\\n",
       "0  {'directed': True, 'multigraph': False, 'graph...   \n",
       "1  {'directed': True, 'multigraph': False, 'graph...   \n",
       "2  {'directed': True, 'multigraph': False, 'graph...   \n",
       "3  {'directed': True, 'multigraph': False, 'graph...   \n",
       "4  {'directed': True, 'multigraph': False, 'graph...   \n",
       "\n",
       "                                      graph_sequence  correct  \n",
       "0  United States of America,country,United States...    False  \n",
       "1  United States of America,described by source,S...    False  \n",
       "2  Mississippi River,described by source,Small Br...     True  \n",
       "3  United States of America,country,United States...    False  \n",
       "4  Mississippi River,described by source,Small Br...    False  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = preprocess_data(test_df)\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Building our dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_texts = concat_train_df[\"graph_sequence\"].tolist()\n",
    "train_labels = concat_train_df[\"correct\"].astype(int).tolist()  # convert true false to 1 0\n",
    "\n",
    "test_texts = test_df[\"graph_sequence\"].tolist()\n",
    "test_labels = test_df[\"correct\"].astype(int).tolist()  # convert true false to 1 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get our encodings\n",
    "train_encodings = tokenizer(train_texts, truncation=True, padding=True)\n",
    "test_encodings = tokenizer(test_texts, truncation=True, padding=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SequenceDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item[\"labels\"] = torch.tensor(self.labels[idx], dtype=torch.float)\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "\n",
    "train_dataset = SequenceDataset(train_encodings, train_labels)\n",
    "test_dataset = SequenceDataset(test_encodings, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import evaluate\n",
    "\n",
    "threshold = 0.5\n",
    "metric_classifier = evaluate.combine([\"accuracy\", \"f1\", \"precision\", \"recall\", \"hyperml/balanced_accuracy\",])\n",
    "metric_regression = evaluate.combine([\"mae\"])\n",
    "\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    results = metric_regression.compute(predictions=predictions, references=labels)\n",
    "\n",
    "    predictions = predictions > threshold\n",
    "    results.update(\n",
    "        metric_classifier.compute(predictions=predictions, references=labels)\n",
    "    )\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specifiy the arguments for the trainer\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=f\"/workspace/storage/subgraphs_reranking_results/t5-xl-ssm/results/{model_save_name}\",  # output directory\n",
    "    num_train_epochs=5,  # total number of training epochs\n",
    "    per_device_train_batch_size=train_bs,  # batch size per device during training\n",
    "    per_device_eval_batch_size=eval_bs,  # batch size for evaluation\n",
    "    warmup_steps=500,  # number of warmup steps for learning rate scheduler\n",
    "    weight_decay=0.01,  # strength of weight decay\n",
    "    logging_dir=f\"/workspace/storage/subgraphs_reranking_results/t5-xl-ssm/logs/{model_save_name}\",  # directory for storing logs\n",
    "    load_best_model_at_end=True,  # load the best model when finished training (default metric is loss)\n",
    "    metric_for_best_model=\"balanced_accuracy\",  # select the base metrics\n",
    "    logging_steps=500,  # log & save weights each logging_steps\n",
    "    save_steps=500,\n",
    "    evaluation_strategy=\"steps\",  # evaluate each `logging_steps`\n",
    "    #report_to='wandb',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data.sampler import WeightedRandomSampler\n",
    "import numpy as np\n",
    "\n",
    "def create_sampler(target):\n",
    "    class_sample_count = np.array(\n",
    "        [len(np.where(target == t)[0]) for t in np.unique(target)]\n",
    "    )\n",
    "    weight = 1.0 / class_sample_count\n",
    "    samples_weight = np.array([weight[t] for t in target])\n",
    "\n",
    "    samples_weight = torch.from_numpy(samples_weight)\n",
    "    samples_weigth = samples_weight.double()\n",
    "    sampler = WeightedRandomSampler(samples_weight, len(samples_weight))\n",
    "\n",
    "    return sampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomTrainer(Trainer):    \n",
    "    def get_train_dataloader(self) -> torch.utils.data.DataLoader:\n",
    "        train_sampler = create_sampler(concat_train_df[\"correct\"].astype(int).ravel())\n",
    "        train_loader = torch.utils.data.DataLoader(\n",
    "            train_dataset, batch_size=train_bs, sampler=train_sampler\n",
    "        )\n",
    "        return train_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "# Call the Trainer\n",
    "trainer = CustomTrainer(\n",
    "    model=model,  # the instantiated Transformers model to be trained\n",
    "    args=training_args,  # training arguments, defined above\n",
    "    train_dataset=train_dataset,  # training dataset\n",
    "    eval_dataset=test_dataset,  # evaluation dataset\n",
    "    compute_metrics=compute_metrics,  # the callback that computes metrics of interest\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "if not model_weights: # training\n",
    "    trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 28325\n",
      "  Batch size = 32\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='886' max='886' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [886/886 03:36]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mhle2000\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.15.7 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/workspace/kbqa/experiments/subgraphs_reranking/deterministic_sequence/wandb/run-20230726_102626-gqttnr3z</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/hle2000/huggingface/runs/gqttnr3z' target=\"_blank\">/workspace/storage/subgraphs_reranking_results/t5-xl-ssm/results/mse_subgraph_mpnet_ranking_T5LargeSSM</a></strong> to <a href='https://wandb.ai/hle2000/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/hle2000/huggingface' target=\"_blank\">https://wandb.ai/hle2000/huggingface</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/hle2000/huggingface/runs/gqttnr3z' target=\"_blank\">https://wandb.ai/hle2000/huggingface/runs/gqttnr3z</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.12268020957708359,\n",
       " 'eval_mae': 0.18467992317326046,\n",
       " 'eval_accuracy': 0.823936451897617,\n",
       " 'eval_f1': 0.599855572494584,\n",
       " 'eval_precision': 0.45036144578313253,\n",
       " 'eval_recall': 0.8979101609416287,\n",
       " 'eval_balanced_accuracy': 0.8545506437519996,\n",
       " 'eval_runtime': 218.3198,\n",
       " 'eval_samples_per_second': 129.741,\n",
       " 'eval_steps_per_second': 4.058}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_res = trainer.evaluate()\n",
    "evaluate_res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Final Re-ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2811it [02:31, 18.51it/s]\n"
     ]
    }
   ],
   "source": [
    "if not new_test_dataset:\n",
    "    res_csv = pd.read_csv(\n",
    "        f\"/workspace/storage/mintaka_seq2seq/{dataset_type}/test/results_filtered.csv\"\n",
    "    )\n",
    "    final_acc, top200_total, top1_total = 0, 0, 0\n",
    "    \n",
    "    for idx, group in tqdm(res_csv.iterrows()):\n",
    "        curr_question_df = test_df[test_df[\"question\"] == group['question']]\n",
    "        all_beams = group.tolist()[2:-1] # all 200 beams\n",
    "        all_beams = list(set(all_beams))\n",
    "        \n",
    "        if group[\"target\"] not in all_beams:  # no correct answer in beam\n",
    "            continue\n",
    "\n",
    "        top200_total += 1\n",
    "        top1_total += 1 if group[\"answer_0\"] in group[\"target\"] else 0\n",
    "        \n",
    "        # reranking\n",
    "        seqs = curr_question_df[\"graph_sequence\"].tolist()\n",
    "        is_corrects = curr_question_df[\"correct\"].tolist()\n",
    "        \n",
    "        tok_seq = tokenizer(seqs, padding=\"max_length\",\n",
    "                            max_length=512,\n",
    "                            truncation=True,\n",
    "                            return_tensors=\"pt\",\n",
    "                            )\n",
    "        mask = tok_seq[\"attention_mask\"].to(device)\n",
    "        input_id = tok_seq[\"input_ids\"].squeeze(1).to(device)\n",
    "        output = model(input_id, mask).logits\n",
    "        output = torch.flatten(output)\n",
    "\n",
    "        max_idx = output.argmax(dim=0).item()\n",
    "\n",
    "        if is_corrects[max_idx] is True:\n",
    "            final_acc += 1\n",
    "    \n",
    "    # final rerankinga, top1 and top200 result\n",
    "    reranking_res = final_acc / len(res_csv)\n",
    "    top200 = top200_total/len(res_csv)\n",
    "    top1 = top1_total / len(res_csv)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "if new_test_dataset: #new_test_dataset: # reranking for new test dataset format\n",
    "    test_dataset_path = '/workspace/storage/new_subgraph_dataset/t5-xl-ssm/mintaka_test_labeled_new.jsonl'\n",
    "    new_test_df = read_jsonl(test_dataset_path)\n",
    "    new_test_df = preprocess_data(new_test_df)\n",
    "    new_test_df_group = new_test_df.groupby('question')\n",
    "    final_acc, top200_total = 0, 0\n",
    "\n",
    "    for question, row in new_test_df_group:\n",
    "        answers = row['answerEntity'].tolist()\n",
    "        ground_truth = row['groundTruthAnswerEntity'].tolist()[0]\n",
    "        if ground_truth in answers:\n",
    "            top200_total += 1\n",
    "        # reranking\n",
    "        seqs = row[\"graph_sequence\"].tolist()\n",
    "        is_corrects = row[\"correct\"].tolist()\n",
    "        \n",
    "        tok_seq = tokenizer(seqs, padding=\"max_length\",\n",
    "                            max_length=512,\n",
    "                            truncation=True,\n",
    "                            return_tensors=\"pt\",\n",
    "                            )\n",
    "        mask = tok_seq[\"attention_mask\"].to(device)\n",
    "        input_id = tok_seq[\"input_ids\"].squeeze(1).to(device)\n",
    "        output = model(input_id, mask).logits\n",
    "        output = torch.flatten(output)\n",
    "\n",
    "        max_idx = output.argmax(dim=0).item()\n",
    "\n",
    "        if is_corrects[max_idx] is True:\n",
    "            final_acc += 1   \n",
    "    \n",
    "    # final rerankinga, top1 and top200 result\n",
    "    reranking_res = final_acc / len(new_test_df_group)\n",
    "    top200 = top200_total/len(new_test_df_group)\n",
    "    top1 = 'Not available for new test dataset'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving the final result to txt file\n",
    "with open(\n",
    "    f\"/workspace/storage/subgraphs_reranking_results/{dataset_type}/results/{model_save_name}/final_results.txt\",\n",
    "    \"w+\",\n",
    ") as f:\n",
    "    f.write(f'original top1: {top1}, top200: {top200}\\n')\n",
    "    f.write(f\"Final reranking accuracy: {reranking_res}\\n\")\n",
    "    f.write(\"\\n\")\n",
    "    f.write(\"trainer.evaluate() result:\\n\")\n",
    "    for k, v in evaluate_res.items():\n",
    "        f.write(f\"{k}:{v}\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
