{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(\"/workspace/kbqa/\")  # go to parent dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-26 16:44:37.554549: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-07-26 16:44:37.794545: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-07-26 16:44:38.625625: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
      "2023-07-26 16:44:38.625704: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
      "2023-07-26 16:44:38.625711: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import ujson\n",
    "import jsonlines\n",
    "import networkx as nx\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForSequenceClassification,\n",
    "    Trainer,\n",
    "    TrainingArguments,\n",
    ")\n",
    "import torch\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Getting JSONL subgraphs dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_type = 't5-xl-ssm'\n",
    "new_test_dataset = False \n",
    "train_bs = 16\n",
    "eval_bs = 32\n",
    "is_special_tok_context = True\n",
    "model_weights = f\"/workspace/storage/subgraphs_reranking_results/{dataset_type}/results/mse_subgraph_mpnet_ranking_T5XLSSMNQ\"\n",
    "model_name = \"roberta-large\"\n",
    "model_save_name = f\"{model_name}_mse_token_context\" if not model_weights else model_weights.split('/')[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "if model_weights: # evaluating\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_weights)\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(model_weights).to(\n",
    "        device\n",
    "    )\n",
    "else: # training from scratch\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    tokenizer.add_special_tokens(\n",
    "        {\"additional_special_tokens\": [\"[unused1]\", \"[unused2]\"]}\n",
    "    )\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=1).to(\n",
    "        device\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_type = 't5-large-ssm'\n",
    "new_test_dataset = False \n",
    "train_bs = 16\n",
    "eval_bs = 32\n",
    "is_special_tok_context = True\n",
    "model_weights = f\"/workspace/storage/subgraphs_reranking_results/{dataset_type}/results/mse_subgraph_bert_ranking_T5LargeSSM\"\n",
    "model_name = \"roberta-large\"\n",
    "model_save_name = f\"{model_name}_mse_token_context\" if not model_weights else model_weights.split('/')[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "if model_weights: # evaluating\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_weights)\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(model_weights).to(\n",
    "        device\n",
    "    )\n",
    "else: # training from scratch\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    tokenizer.add_special_tokens(\n",
    "        {\"additional_special_tokens\": [\"[unused1]\", \"[unused2]\"]}\n",
    "    )\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=1).to(\n",
    "        device\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 94690/94690 [00:00<00:00, 1465519.24it/s]\n",
      "100%|██████████| 13646/13646 [00:00<00:00, 1798782.88it/s]\n",
      "100%|██████████| 27094/27094 [00:00<00:00, 676113.45it/s]\n"
     ]
    }
   ],
   "source": [
    "def read_jsonl(path):\n",
    "    jsonl_reader = jsonlines.open(path)\n",
    "    jsonl_reader_list = list(jsonl_reader)\n",
    "    df = []\n",
    "    for line in tqdm(jsonl_reader_list):\n",
    "        df.append(line)\n",
    "    df = pd.DataFrame(df)\n",
    "    return df\n",
    "\n",
    "\n",
    "train_df = read_jsonl(\n",
    "    f\"/workspace/storage/new_subgraph_dataset/{dataset_type}/mintaka_train_labeled.jsonl\"\n",
    ")\n",
    "val_df = read_jsonl(\n",
    "    f\"/workspace/storage/new_subgraph_dataset/{dataset_type}/mintaka_validation_labeled.jsonl\"\n",
    ")\n",
    "test_df = read_jsonl(\n",
    "    f\"/workspace/storage/new_subgraph_dataset/{dataset_type}/mintaka_test_labeled.jsonl\"\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Converting graph to its sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_node_names(subgraph, candidate_start_token=\"[unused1]\", candidate_end_token=\"[unused2]\",):\n",
    "    node_names = [subgraph.nodes[node][\"label\"] for node in subgraph.nodes()]\n",
    "    node_type = [subgraph.nodes[node][\"type\"] for node in subgraph.nodes()]\n",
    "    \n",
    "    if 'ANSWER_CANDIDATE_ENTITY' not in node_type:\n",
    "        return None\n",
    "\n",
    "    if is_special_tok_context:\n",
    "        candidate_idx = node_type.index(\"ANSWER_CANDIDATE_ENTITY\")\n",
    "        node_names[\n",
    "            candidate_idx\n",
    "        ] = f\"{candidate_start_token}{node_names[candidate_idx]}{candidate_end_token}\"\n",
    "    \n",
    "    return node_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def graph_to_sequence(subgraph, node_names):\n",
    "    # getting adjency matrix and weight info\n",
    "    adj_matrix = nx.adjacency_matrix(subgraph).todense().tolist()\n",
    "    edge_data = subgraph.edges.data()\n",
    "\n",
    "    # adding our edge info\n",
    "    for edge in edge_data:\n",
    "        i, j, data = edge\n",
    "        i, j = int(i), int(j)\n",
    "        adj_matrix[i][j] = data[\"label\"]\n",
    "\n",
    "    sequence = []\n",
    "    # for adjency matrix, i, j means node i -> j\n",
    "    for i, row in enumerate(adj_matrix):\n",
    "        from_node = node_names[i]  # from node (node i)\n",
    "        for j, edge_info in enumerate(row):\n",
    "            to_node = node_names[j]\n",
    "            if edge_info != 0:  # no endge from_node -> to_node\n",
    "                sequence.extend([from_node, edge_info, to_node])\n",
    "    \n",
    "    sequence = \",\".join(str(node) for node in sequence)\n",
    "    return sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ast import literal_eval\n",
    "from unidecode import unidecode\n",
    "\n",
    "\n",
    "def try_literal_eval(s):\n",
    "    try:\n",
    "        return literal_eval(s)\n",
    "    except ValueError:\n",
    "        return s\n",
    "\n",
    "\n",
    "def get_sequences(df):\n",
    "    questions = list(df[\"question\"])\n",
    "    graphs = list(df[\"graph\"])\n",
    "    graph_seq = []\n",
    "    for question, graph in tqdm(zip(questions, graphs)):\n",
    "        graph_obj = nx.readwrite.json_graph.node_link_graph(try_literal_eval(graph))\n",
    "        try:\n",
    "            graph_node_names = get_node_names(graph_obj)\n",
    "            if graph_node_names is None:\n",
    "                curr_seq = \"ERROR_NO_CANDIDATE\"\n",
    "            else:     \n",
    "                curr_seq = graph_to_sequence(graph_obj, graph_node_names)\n",
    "                if is_special_tok_context:\n",
    "                    curr_seq = f\"{question}{tokenizer.sep_token}{curr_seq}\"\n",
    "        except KeyError:\n",
    "            curr_seq = \"ERROR_NO_LABEL\"\n",
    "        except nx.NetworkXError:\n",
    "            curr_seq = \"ERROR_EMPTY_GRAPH\"\n",
    "        graph_seq.append(curr_seq)\n",
    "    \n",
    "    return graph_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(df):\n",
    "    # get the sequences\n",
    "    df_sequences = get_sequences(df)\n",
    "    df[\"graph_sequence\"] = df_sequences\n",
    "    \n",
    "    # filter out all invalid graphs\n",
    "    error_df = df[\n",
    "        (df[\"graph_sequence\"] == \"ERROR_EMPTY_GRAPH\")\n",
    "        | (df[\"graph_sequence\"] == \"ERROR_NO_LABEL\")\n",
    "        | (df[\"graph_sequence\"] == \"ERROR_NO_CANDIDATE\")\n",
    "    ]\n",
    "    df = df.drop(error_df.index)\n",
    "    \n",
    "    # turn list of entities into string\n",
    "    df[\"answerEntity\"] = df[\"answerEntity\"].apply(lambda x: \", \".join(x))\n",
    "    df[\"questionEntity\"] = df[\"questionEntity\"].apply(lambda x: \", \".join(x))\n",
    "    df[\"groundTruthAnswerEntity\"] = df[\"groundTruthAnswerEntity\"].apply(\n",
    "        lambda x: \", \".join(x)\n",
    "    )\n",
    "    df[\"correct\"] = df.apply(\n",
    "        lambda x: x[\"answerEntity\"] in x[\"groundTruthAnswerEntity\"], axis=1\n",
    "    )\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get train and test texts & labels\n",
    "concat_train_df = pd.concat([train_df, val_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "108336it [00:27, 3937.33it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>question</th>\n",
       "      <th>answerEntity</th>\n",
       "      <th>questionEntity</th>\n",
       "      <th>groundTruthAnswerEntity</th>\n",
       "      <th>complexityType</th>\n",
       "      <th>graph</th>\n",
       "      <th>graph_sequence</th>\n",
       "      <th>correct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2723bb1b</td>\n",
       "      <td>Which actor was the star of Titanic and was bo...</td>\n",
       "      <td>Q100711983</td>\n",
       "      <td>Q44578, Q65</td>\n",
       "      <td>Q38111</td>\n",
       "      <td>intersection</td>\n",
       "      <td>{'directed': True, 'multigraph': False, 'graph...</td>\n",
       "      <td>Which actor was the star of Titanic and was bo...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a9011ddf</td>\n",
       "      <td>What is the seventh tallest mountain in North ...</td>\n",
       "      <td>Q130018</td>\n",
       "      <td>Q49</td>\n",
       "      <td>Q1153188</td>\n",
       "      <td>ordinal</td>\n",
       "      <td>{'directed': True, 'multigraph': False, 'graph...</td>\n",
       "      <td>What is the seventh tallest mountain in North ...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>982450cf</td>\n",
       "      <td>Who is the youngest current US governor?</td>\n",
       "      <td>Q11673</td>\n",
       "      <td>Q889821</td>\n",
       "      <td>Q3105215</td>\n",
       "      <td>superlative</td>\n",
       "      <td>{'directed': True, 'multigraph': False, 'graph...</td>\n",
       "      <td>Who is the youngest current US governor?&lt;/s&gt;Un...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>982450cf</td>\n",
       "      <td>Who is the youngest current US governor?</td>\n",
       "      <td>Q30</td>\n",
       "      <td>Q889821</td>\n",
       "      <td>Q3105215</td>\n",
       "      <td>superlative</td>\n",
       "      <td>{'directed': True, 'multigraph': False, 'graph...</td>\n",
       "      <td>Who is the youngest current US governor?&lt;/s&gt;[u...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>982450cf</td>\n",
       "      <td>Who is the youngest current US governor?</td>\n",
       "      <td>Q132050</td>\n",
       "      <td>Q889821</td>\n",
       "      <td>Q3105215</td>\n",
       "      <td>superlative</td>\n",
       "      <td>{'directed': True, 'multigraph': False, 'graph...</td>\n",
       "      <td>Who is the youngest current US governor?&lt;/s&gt;go...</td>\n",
       "    </tr>\n"
      ],
      "text/plain": [
       "         id                                           question answerEntity  \\\n",
       "0  2723bb1b  Which actor was the star of Titanic and was bo...   Q100711983   \n",
       "1  a9011ddf  What is the seventh tallest mountain in North ...      Q130018   \n",
       "2  982450cf           Who is the youngest current US governor?       Q11673   \n",
       "3  982450cf           Who is the youngest current US governor?          Q30   \n",
       "4  982450cf           Who is the youngest current US governor?      Q132050   \n",
       "\n",
       "  questionEntity groundTruthAnswerEntity complexityType  \\\n",
       "0    Q44578, Q65                  Q38111   intersection   \n",
       "1            Q49                Q1153188        ordinal   \n",
       "2        Q889821                Q3105215    superlative   \n",
       "3        Q889821                Q3105215    superlative   \n",
       "4        Q889821                Q3105215    superlative   \n",
       "\n",
       "                                               graph  \\\n",
       "0  {'directed': True, 'multigraph': False, 'graph...   \n",
       "1  {'directed': True, 'multigraph': False, 'graph...   \n",
       "2  {'directed': True, 'multigraph': False, 'graph...   \n",
       "3  {'directed': True, 'multigraph': False, 'graph...   \n",
       "4  {'directed': True, 'multigraph': False, 'graph...   \n",
       "\n",
       "                                      graph_sequence  correct  \n",
       "0  Which actor was the star of Titanic and was bo...    False  \n",
       "1  What is the seventh tallest mountain in North ...    False  \n",
       "2  Who is the youngest current US governor?</s>Un...    False  \n",
       "3  Who is the youngest current US governor?</s>[u...    False  \n",
       "4  Who is the youngest current US governor?</s>go...    False  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concat_train_df = preprocess_data(concat_train_df)\n",
    "concat_train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "27094it [00:06, 4114.62it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>question</th>\n",
       "      <th>answerEntity</th>\n",
       "      <th>questionEntity</th>\n",
       "      <th>groundTruthAnswerEntity</th>\n",
       "      <th>complexityType</th>\n",
       "      <th>graph</th>\n",
       "      <th>graph_sequence</th>\n",
       "      <th>correct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>fae46b21</td>\n",
       "      <td>What man was a famous American author and also...</td>\n",
       "      <td>Q191050</td>\n",
       "      <td>Q1497, Q846570</td>\n",
       "      <td>Q7245</td>\n",
       "      <td>intersection</td>\n",
       "      <td>{'directed': True, 'multigraph': False, 'graph...</td>\n",
       "      <td>What man was a famous American author and also...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>fae46b21</td>\n",
       "      <td>What man was a famous American author and also...</td>\n",
       "      <td>Q3259878</td>\n",
       "      <td>Q1497, Q846570</td>\n",
       "      <td>Q7245</td>\n",
       "      <td>intersection</td>\n",
       "      <td>{'directed': True, 'multigraph': False, 'graph...</td>\n",
       "      <td>What man was a famous American author and also...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>fae46b21</td>\n",
       "      <td>What man was a famous American author and also...</td>\n",
       "      <td>Q7245</td>\n",
       "      <td>Q1497, Q846570</td>\n",
       "      <td>Q7245</td>\n",
       "      <td>intersection</td>\n",
       "      <td>{'directed': True, 'multigraph': False, 'graph...</td>\n",
       "      <td>What man was a famous American author and also...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>fae46b21</td>\n",
       "      <td>What man was a famous American author and also...</td>\n",
       "      <td>Q1074614</td>\n",
       "      <td>Q1497, Q846570</td>\n",
       "      <td>Q7245</td>\n",
       "      <td>intersection</td>\n",
       "      <td>{'directed': True, 'multigraph': False, 'graph...</td>\n",
       "      <td>What man was a famous American author and also...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>fae46b21</td>\n",
       "      <td>What man was a famous American author and also...</td>\n",
       "      <td>Q15133865</td>\n",
       "      <td>Q1497, Q846570</td>\n",
       "      <td>Q7245</td>\n",
       "      <td>intersection</td>\n",
       "      <td>{'directed': True, 'multigraph': False, 'graph...</td>\n",
       "      <td>What man was a famous American author and also...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id                                           question answerEntity  \\\n",
       "0  fae46b21  What man was a famous American author and also...      Q191050   \n",
       "1  fae46b21  What man was a famous American author and also...     Q3259878   \n",
       "2  fae46b21  What man was a famous American author and also...        Q7245   \n",
       "3  fae46b21  What man was a famous American author and also...     Q1074614   \n",
       "4  fae46b21  What man was a famous American author and also...    Q15133865   \n",
       "\n",
       "   questionEntity groundTruthAnswerEntity complexityType  \\\n",
       "0  Q1497, Q846570                   Q7245   intersection   \n",
       "1  Q1497, Q846570                   Q7245   intersection   \n",
       "2  Q1497, Q846570                   Q7245   intersection   \n",
       "3  Q1497, Q846570                   Q7245   intersection   \n",
       "4  Q1497, Q846570                   Q7245   intersection   \n",
       "\n",
       "                                               graph  \\\n",
       "0  {'directed': True, 'multigraph': False, 'graph...   \n",
       "1  {'directed': True, 'multigraph': False, 'graph...   \n",
       "2  {'directed': True, 'multigraph': False, 'graph...   \n",
       "3  {'directed': True, 'multigraph': False, 'graph...   \n",
       "4  {'directed': True, 'multigraph': False, 'graph...   \n",
       "\n",
       "                                      graph_sequence  correct  \n",
       "0  What man was a famous American author and also...    False  \n",
       "1  What man was a famous American author and also...    False  \n",
       "2  What man was a famous American author and also...     True  \n",
       "3  What man was a famous American author and also...    False  \n",
       "4  What man was a famous American author and also...    False  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = preprocess_data(test_df)\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Building our dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_texts = concat_train_df[\"graph_sequence\"].tolist()\n",
    "train_labels = concat_train_df[\"correct\"].astype(int).tolist()  # convert true false to 1 0\n",
    "\n",
    "test_texts = test_df[\"graph_sequence\"].tolist()\n",
    "test_labels = test_df[\"correct\"].astype(int).tolist()  # convert true false to 1 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get our encodings\n",
    "train_encodings = tokenizer(train_texts, truncation=True, padding=True)\n",
    "test_encodings = tokenizer(test_texts, truncation=True, padding=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SequenceDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item[\"labels\"] = torch.tensor(self.labels[idx], dtype=torch.float)\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "\n",
    "train_dataset = SequenceDataset(train_encodings, train_labels)\n",
    "test_dataset = SequenceDataset(test_encodings, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import evaluate\n",
    "\n",
    "threshold = 0.5\n",
    "metric_classifier = evaluate.combine([\"accuracy\", \"f1\", \"precision\", \"recall\", \"hyperml/balanced_accuracy\",])\n",
    "metric_regression = evaluate.combine([\"mae\"])\n",
    "\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    results = metric_regression.compute(predictions=predictions, references=labels)\n",
    "\n",
    "    predictions = predictions > threshold\n",
    "    results.update(\n",
    "        metric_classifier.compute(predictions=predictions, references=labels)\n",
    "    )\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specifiy the arguments for the trainer\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=f\"/workspace/storage/subgraphs_reranking_results/t5-xl-ssm/results/{model_save_name}\",  # output directory\n",
    "    num_train_epochs=5,  # total number of training epochs\n",
    "    per_device_train_batch_size=train_bs,  # batch size per device during training\n",
    "    per_device_eval_batch_size=eval_bs,  # batch size for evaluation\n",
    "    warmup_steps=500,  # number of warmup steps for learning rate scheduler\n",
    "    weight_decay=0.01,  # strength of weight decay\n",
    "    logging_dir=f\"/workspace/storage/subgraphs_reranking_results/t5-xl-ssm/logs/{model_save_name}\",  # directory for storing logs\n",
    "    load_best_model_at_end=True,  # load the best model when finished training (default metric is loss)\n",
    "    metric_for_best_model=\"balanced_accuracy\",  # select the base metrics\n",
    "    logging_steps=500,  # log & save weights each logging_steps\n",
    "    save_steps=500,\n",
    "    evaluation_strategy=\"steps\",  # evaluate each `logging_steps`\n",
    "    #report_to='wandb',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data.sampler import WeightedRandomSampler\n",
    "import numpy as np\n",
    "\n",
    "def create_sampler(target):\n",
    "    class_sample_count = np.array(\n",
    "        [len(np.where(target == t)[0]) for t in np.unique(target)]\n",
    "    )\n",
    "    weight = 1.0 / class_sample_count\n",
    "    samples_weight = np.array([weight[t] for t in target])\n",
    "\n",
    "    samples_weight = torch.from_numpy(samples_weight)\n",
    "    samples_weigth = samples_weight.double()\n",
    "    sampler = WeightedRandomSampler(samples_weight, len(samples_weight))\n",
    "\n",
    "    return sampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomTrainer(Trainer):    \n",
    "    def get_train_dataloader(self) -> torch.utils.data.DataLoader:\n",
    "        train_sampler = create_sampler(concat_train_df[\"correct\"].astype(int).ravel())\n",
    "        train_loader = torch.utils.data.DataLoader(\n",
    "            train_dataset, batch_size=train_bs, sampler=train_sampler\n",
    "        )\n",
    "        return train_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "# Call the Trainer\n",
    "trainer = CustomTrainer(\n",
    "    model=model,  # the instantiated Transformers model to be trained\n",
    "    args=training_args,  # training arguments, defined above\n",
    "    train_dataset=train_dataset,  # training dataset\n",
    "    eval_dataset=test_dataset,  # evaluation dataset\n",
    "    compute_metrics=compute_metrics,  # the callback that computes metrics of interest\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "if not model_weights: # training\n",
    "    trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 26759\n",
      "  Batch size = 32\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='837' max='837' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [837/837 03:38]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mhle2000\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.15.7 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/workspace/kbqa/experiments/subgraphs_reranking/deterministic_sequence/wandb/run-20230726_172520-qosrpuog</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/hle2000/huggingface/runs/qosrpuog' target=\"_blank\">/workspace/storage/subgraphs_reranking_results/t5-xl-ssm/results/mse_subgraph_mpnet_ranking_T5XLSSMNQ</a></strong> to <a href='https://wandb.ai/hle2000/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/hle2000/huggingface' target=\"_blank\">https://wandb.ai/hle2000/huggingface</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/hle2000/huggingface/runs/qosrpuog' target=\"_blank\">https://wandb.ai/hle2000/huggingface/runs/qosrpuog</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.13944019377231598,\n",
       " 'eval_mae': 0.21075966312410827,\n",
       " 'eval_accuracy': 0.8092230651369633,\n",
       " 'eval_f1': 0.5954513035898249,\n",
       " 'eval_precision': 0.4442999053926206,\n",
       " 'eval_recall': 0.9024741772760029,\n",
       " 'eval_balanced_accuracy': 0.847258508358306,\n",
       " 'eval_runtime': 220.7764,\n",
       " 'eval_samples_per_second': 121.204,\n",
       " 'eval_steps_per_second': 3.791}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_res = trainer.evaluate()\n",
    "evaluate_res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Final Re-ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4000it [02:56, 22.63it/s] \n"
     ]
    }
   ],
   "source": [
    "if not new_test_dataset:\n",
    "    res_csv = pd.read_csv(\n",
    "        f\"/workspace/storage/mintaka_seq2seq/{dataset_type}/test/results.csv\"\n",
    "    )\n",
    "    final_acc, top200_total, top1_total, seq2seq_correct = 0, 0, 0, 0\n",
    "    \n",
    "    for idx, group in tqdm(res_csv.iterrows()):\n",
    "        curr_question_df = test_df[test_df[\"question\"] == group['question']]\n",
    "        if len(curr_question_df) == 0: # we don't have subgraph for this question, take answer from seq2seq\n",
    "            if group[\"answer_0\"] == group[\"target\"]:\n",
    "                seq2seq_correct += 1\n",
    "            else: # check if answer exist in 200 beams for question with no subgraphs\n",
    "                all_beams = group.tolist()[2:-1] # all 200 beams\n",
    "                all_beams = list(set(all_beams))\n",
    "                top200_total += 1 if group[\"target\"] in all_beams else 0\n",
    "                \n",
    "        else: # we have subgraph for this question\n",
    "            all_beams = group.tolist()[2:-1] # all 200 beams\n",
    "            all_beams = list(set(all_beams))\n",
    "            \n",
    "            if group[\"target\"] not in all_beams: # no correct answer in beam\n",
    "                continue\n",
    "            \n",
    "            # correct answer exist in beam\n",
    "            top1_total += 1 if group[\"answer_0\"] == group[\"target\"] else 0\n",
    "            top200_total += 1\n",
    "            \n",
    "            # reranking\n",
    "            seqs = curr_question_df[\"graph_sequence\"].tolist()\n",
    "            is_corrects = curr_question_df[\"correct\"].tolist()\n",
    "            \n",
    "            tok_seq = tokenizer(seqs, padding=\"max_length\",\n",
    "                                max_length=512,\n",
    "                                truncation=True,\n",
    "                                return_tensors=\"pt\",\n",
    "                                )\n",
    "            mask = tok_seq[\"attention_mask\"].to(device)\n",
    "            input_id = tok_seq[\"input_ids\"].squeeze(1).to(device)\n",
    "            output = model(input_id, mask).logits\n",
    "            output = torch.flatten(output)\n",
    "\n",
    "            max_idx = output.argmax(dim=0).item()\n",
    "\n",
    "            if is_corrects[max_idx] is True:\n",
    "                final_acc += 1\n",
    "    \n",
    "    # final rerankinga, top1 and top200 result\n",
    "    reranking_res = (final_acc + seq2seq_correct)/ len(res_csv)\n",
    "    top200 = (top200_total + seq2seq_correct)/len(res_csv)\n",
    "    top1 = (top1_total + seq2seq_correct)/ len(res_csv)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "if new_test_dataset: # new_test_dataset: # reranking for new test dataset format\n",
    "    test_dataset_path = '/workspace/storage/new_subgraph_dataset/t5-xl-ssm/mintaka_test_labeled_new.jsonl'\n",
    "    new_test_df = read_jsonl(test_dataset_path)\n",
    "    new_test_df = preprocess_data(new_test_df)\n",
    "    new_test_df_group = new_test_df.groupby('question')\n",
    "    final_acc, top200_total = 0, 0\n",
    "\n",
    "    for question, row in new_test_df_group:\n",
    "        answers = row['answerEntity'].tolist()\n",
    "        ground_truth = row['groundTruthAnswerEntity'].tolist()[0]\n",
    "        if ground_truth in answers:\n",
    "            top200_total += 1\n",
    "        # reranking\n",
    "        seqs = row[\"graph_sequence\"].tolist()\n",
    "        is_corrects = row[\"correct\"].tolist()\n",
    "        \n",
    "        tok_seq = tokenizer(seqs, padding=\"max_length\",\n",
    "                            max_length=512,\n",
    "                            truncation=True,\n",
    "                            return_tensors=\"pt\",\n",
    "                            )\n",
    "        mask = tok_seq[\"attention_mask\"].to(device)\n",
    "        input_id = tok_seq[\"input_ids\"].squeeze(1).to(device)\n",
    "        output = model(input_id, mask).logits\n",
    "        output = torch.flatten(output)\n",
    "\n",
    "        max_idx = output.argmax(dim=0).item()\n",
    "\n",
    "        if is_corrects[max_idx] is True:\n",
    "            final_acc += 1   \n",
    "    \n",
    "    # final rerankinga, top1 and top200 result\n",
    "    reranking_res = final_acc / len(new_test_df_group)\n",
    "    top200 = top200_total/len(new_test_df_group)\n",
    "    top1 = 'Not available for new test dataset'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving the final result to txt file\n",
    "with open(\n",
    "    f\"/workspace/storage/subgraphs_reranking_results/{dataset_type}/results/{model_save_name}/final_results_seq2seq.txt\",\n",
    "    \"w+\",\n",
    ") as f:\n",
    "    f.write(f'original top1: {top1}, top200: {top200}\\n')\n",
    "    f.write(f\"Final reranking accuracy: {reranking_res}\\n\")\n",
    "    f.write(\"\\n\")\n",
    "    f.write(\"trainer.evaluate() result:\\n\")\n",
    "    for k, v in evaluate_res.items():\n",
    "        f.write(f\"{k}:{v}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
