{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(\"/workspace/kbqa/\")  # go to parent dir"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting our dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ujson\n",
    "import jsonlines\n",
    "import networkx as nx\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with_candidate = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = \"MINTAKA\"\n",
    "dataset_type = \"mintaka_test_labeled\"\n",
    "subgraph_path = (\n",
    "    f\"/workspace/storage/new_subgraph_dataset/{dataset}/{dataset_type}.jsonl\"\n",
    ")\n",
    "dataset_dir_path = f\"./subgraph_classify_dataset/{dataset}/candidates_{with_candidate}\"\n",
    "# Path(dataset_dir_path).mkdir(parents=True, exist_ok=True)\n",
    "dataset_path = f\"{dataset_dir_path}/{dataset_type}.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./subgraph_classify_dataset/MINTAKA/candidates_True/mintaka_test_labeled.csv'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "28325it [00:00, 1987647.20it/s]\n"
     ]
    }
   ],
   "source": [
    "jsonl_reader = jsonlines.open(subgraph_path)\n",
    "jsonl_reader_list = list(jsonl_reader)\n",
    "nx_graphs = []\n",
    "df = []\n",
    "for idx, line in tqdm(enumerate(jsonl_reader_list)):\n",
    "    df.append(line)\n",
    "df = pd.DataFrame(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_node_names(subgraph):\n",
    "    node_names = [subgraph.nodes[node][\"label\"] for node in subgraph.nodes()]\n",
    "    return node_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def graph_to_sequence(subgraph, node_names):\n",
    "    # getting adjency matrix and weight info\n",
    "    adj_matrix = nx.adjacency_matrix(subgraph).todense().tolist()\n",
    "    edge_data = subgraph.edges.data()\n",
    "\n",
    "    # adding our edge info\n",
    "    for edge in edge_data:\n",
    "        i, j, data = edge\n",
    "        i, j = int(i), int(j)\n",
    "        adj_matrix[i][j] = data[\"label\"]\n",
    "\n",
    "    sequence = []\n",
    "    # for adjency matrix, i, j means node i -> j\n",
    "    for i, row in enumerate(adj_matrix):\n",
    "        from_node = node_names[i]  # from node (node i)\n",
    "        for j, edge_info in enumerate(row):\n",
    "            to_node = node_names[j]\n",
    "            if edge_info == 0:  # no endge from_node -> to_node\n",
    "                # sequence.extend([from_node, \"None\", to_node])\n",
    "                pass\n",
    "            else:\n",
    "                sequence.extend([from_node, edge_info, to_node])\n",
    "    sequence = \",\".join(str(node) for node in sequence)\n",
    "    return sequence"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Getting our subgraphs sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 1339/14286 [00:00<00:02, 4681.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR EMPTY GRAPHS!\n",
      "ERROR EMPTY GRAPHS!\n",
      "ERROR EMPTY GRAPHS!\n",
      "ERROR EMPTY GRAPHS!\n",
      "ERROR EMPTY GRAPHS!\n",
      "ERROR EMPTY GRAPHS!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 3853/14286 [00:00<00:02, 5006.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR EMPTY GRAPHS!\n",
      "ERROR EMPTY GRAPHS!\n",
      "ERROR EMPTY GRAPHS!\n",
      "ERROR EMPTY GRAPHS!\n",
      "ERROR EMPTY GRAPHS!\n",
      "ERROR EMPTY GRAPHS!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 10013/14286 [00:02<00:00, 5110.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR EMPTY GRAPHS!\n",
      "ERROR EMPTY GRAPHS!\n",
      "ERROR EMPTY GRAPHS!\n",
      "ERROR EMPTY GRAPHS!\n",
      "ERROR EMPTY GRAPHS!\n",
      "ERROR EMPTY GRAPHS!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▏| 13201/14286 [00:02<00:00, 5320.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR EMPTY GRAPHS!\n",
      "ERROR EMPTY GRAPHS!\n",
      "ERROR EMPTY GRAPHS!\n",
      "ERROR EMPTY GRAPHS!\n",
      "ERROR EMPTY GRAPHS!\n",
      "ERROR EMPTY GRAPHS!\n",
      "ERROR EMPTY GRAPHS!\n",
      "ERROR EMPTY GRAPHS!\n",
      "ERROR EMPTY GRAPHS!\n",
      "ERROR EMPTY GRAPHS!\n",
      "ERROR EMPTY GRAPHS!\n",
      "ERROR EMPTY GRAPHS!\n",
      "ERROR EMPTY GRAPHS!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14286/14286 [00:02<00:00, 5060.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR EMPTY GRAPHS!\n",
      "ERROR EMPTY GRAPHS!\n",
      "ERROR EMPTY GRAPHS!\n",
      "ERROR EMPTY GRAPHS!\n",
      "ERROR EMPTY GRAPHS!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "graphs = list(df[\"graph\"])\n",
    "graph_seq = []\n",
    "for graph in tqdm(graphs):\n",
    "    graph_obj = nx.readwrite.json_graph.node_link_graph(graph)\n",
    "    try:\n",
    "        graph_node_names = get_node_names(graph_obj)\n",
    "        curr_seq = graph_to_sequence(graph_obj, graph_node_names)\n",
    "    except KeyError:\n",
    "        print(\"ERROR NO LABEL!\")\n",
    "        curr_seq = \"ERROR_NO_LABEL\"\n",
    "    except nx.NetworkXError:\n",
    "        print(\"ERROR EMPTY GRAPHS!\")\n",
    "        curr_seq = \"ERROR_EMPTY_GRAPH\"\n",
    "    graph_seq.append(curr_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>question</th>\n",
       "      <th>answerEntity</th>\n",
       "      <th>questionEntity</th>\n",
       "      <th>groundTruthAnswerEntity</th>\n",
       "      <th>complexityType</th>\n",
       "      <th>graph</th>\n",
       "      <th>graph_sequence</th>\n",
       "      <th>correct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9ace9041</td>\n",
       "      <td>What is the fourth book in the Twilight series?</td>\n",
       "      <td>[Q189378]</td>\n",
       "      <td>[Q44523]</td>\n",
       "      <td>[Q53945]</td>\n",
       "      <td>ordinal</td>\n",
       "      <td>{'directed': True, 'multigraph': False, 'graph...</td>\n",
       "      <td>Twilight,has part(s),Twilight,Twilight,part of...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9ace9041</td>\n",
       "      <td>What is the fourth book in the Twilight series?</td>\n",
       "      <td>[Q19765983]</td>\n",
       "      <td>[Q44523]</td>\n",
       "      <td>[Q53945]</td>\n",
       "      <td>ordinal</td>\n",
       "      <td>{'directed': True, 'multigraph': False, 'graph...</td>\n",
       "      <td>Twilight,genre,romantic fiction</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9ace9041</td>\n",
       "      <td>What is the fourth book in the Twilight series?</td>\n",
       "      <td>[Q111019576]</td>\n",
       "      <td>[Q44523]</td>\n",
       "      <td>[Q53945]</td>\n",
       "      <td>ordinal</td>\n",
       "      <td>{'directed': True, 'multigraph': False, 'graph...</td>\n",
       "      <td>Twilight,genre,vampire fiction</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9ace9041</td>\n",
       "      <td>What is the fourth book in the Twilight series?</td>\n",
       "      <td>[Q849907]</td>\n",
       "      <td>[Q44523]</td>\n",
       "      <td>[Q53945]</td>\n",
       "      <td>ordinal</td>\n",
       "      <td>{'directed': True, 'multigraph': False, 'graph...</td>\n",
       "      <td>Twilight,has part(s),The Short Second Life of ...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9ace9041</td>\n",
       "      <td>What is the fourth book in the Twilight series?</td>\n",
       "      <td>[Q53945]</td>\n",
       "      <td>[Q44523]</td>\n",
       "      <td>[Q53945]</td>\n",
       "      <td>ordinal</td>\n",
       "      <td>{'directed': True, 'multigraph': False, 'graph...</td>\n",
       "      <td>Twilight,has part(s),Breaking Dawn,Breaking Da...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id                                         question  answerEntity  \\\n",
       "0  9ace9041  What is the fourth book in the Twilight series?     [Q189378]   \n",
       "1  9ace9041  What is the fourth book in the Twilight series?   [Q19765983]   \n",
       "2  9ace9041  What is the fourth book in the Twilight series?  [Q111019576]   \n",
       "3  9ace9041  What is the fourth book in the Twilight series?     [Q849907]   \n",
       "4  9ace9041  What is the fourth book in the Twilight series?      [Q53945]   \n",
       "\n",
       "  questionEntity groundTruthAnswerEntity complexityType  \\\n",
       "0       [Q44523]                [Q53945]        ordinal   \n",
       "1       [Q44523]                [Q53945]        ordinal   \n",
       "2       [Q44523]                [Q53945]        ordinal   \n",
       "3       [Q44523]                [Q53945]        ordinal   \n",
       "4       [Q44523]                [Q53945]        ordinal   \n",
       "\n",
       "                                               graph  \\\n",
       "0  {'directed': True, 'multigraph': False, 'graph...   \n",
       "1  {'directed': True, 'multigraph': False, 'graph...   \n",
       "2  {'directed': True, 'multigraph': False, 'graph...   \n",
       "3  {'directed': True, 'multigraph': False, 'graph...   \n",
       "4  {'directed': True, 'multigraph': False, 'graph...   \n",
       "\n",
       "                                      graph_sequence  correct  \n",
       "0  Twilight,has part(s),Twilight,Twilight,part of...    False  \n",
       "1                    Twilight,genre,romantic fiction    False  \n",
       "2                     Twilight,genre,vampire fiction    False  \n",
       "3  Twilight,has part(s),The Short Second Life of ...    False  \n",
       "4  Twilight,has part(s),Breaking Dawn,Breaking Da...     True  "
      ]
     },
     "execution_count": 307,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# add graph sequence and correct label to our df\n",
    "df[\"graph_sequence\"] = graph_seq\n",
    "df[\"correct\"] = df[\"groundTruthAnswerEntity\"] == df[\"answerEntity\"]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting the error df and save it\n",
    "error_df = df[\n",
    "    (df[\"graph_sequence\"] == \"ERROR_EMPTY_GRAPH\")\n",
    "    | (df[\"graph_sequence\"] == \"ERROR_NO_LABEL\")\n",
    "]\n",
    "error_df_path = \".\".join(dataset_path.split(\".\")[:-1])\n",
    "error_df.to_csv(f\"{error_df_path}_ERROR.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>question</th>\n",
       "      <th>answerEntity</th>\n",
       "      <th>questionEntity</th>\n",
       "      <th>groundTruthAnswerEntity</th>\n",
       "      <th>complexityType</th>\n",
       "      <th>graph</th>\n",
       "      <th>graph_sequence</th>\n",
       "      <th>correct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9ace9041</td>\n",
       "      <td>What is the fourth book in the Twilight series?</td>\n",
       "      <td>[Q189378]</td>\n",
       "      <td>[Q44523]</td>\n",
       "      <td>[Q53945]</td>\n",
       "      <td>ordinal</td>\n",
       "      <td>{'directed': True, 'multigraph': False, 'graph...</td>\n",
       "      <td>Twilight,has part(s),Twilight,Twilight,part of...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9ace9041</td>\n",
       "      <td>What is the fourth book in the Twilight series?</td>\n",
       "      <td>[Q19765983]</td>\n",
       "      <td>[Q44523]</td>\n",
       "      <td>[Q53945]</td>\n",
       "      <td>ordinal</td>\n",
       "      <td>{'directed': True, 'multigraph': False, 'graph...</td>\n",
       "      <td>Twilight,genre,romantic fiction</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9ace9041</td>\n",
       "      <td>What is the fourth book in the Twilight series?</td>\n",
       "      <td>[Q111019576]</td>\n",
       "      <td>[Q44523]</td>\n",
       "      <td>[Q53945]</td>\n",
       "      <td>ordinal</td>\n",
       "      <td>{'directed': True, 'multigraph': False, 'graph...</td>\n",
       "      <td>Twilight,genre,vampire fiction</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9ace9041</td>\n",
       "      <td>What is the fourth book in the Twilight series?</td>\n",
       "      <td>[Q849907]</td>\n",
       "      <td>[Q44523]</td>\n",
       "      <td>[Q53945]</td>\n",
       "      <td>ordinal</td>\n",
       "      <td>{'directed': True, 'multigraph': False, 'graph...</td>\n",
       "      <td>Twilight,has part(s),The Short Second Life of ...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9ace9041</td>\n",
       "      <td>What is the fourth book in the Twilight series?</td>\n",
       "      <td>[Q53945]</td>\n",
       "      <td>[Q44523]</td>\n",
       "      <td>[Q53945]</td>\n",
       "      <td>ordinal</td>\n",
       "      <td>{'directed': True, 'multigraph': False, 'graph...</td>\n",
       "      <td>Twilight,has part(s),Breaking Dawn,Breaking Da...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14281</th>\n",
       "      <td>3e711adc</td>\n",
       "      <td>What is the first Discworld book about the Cit...</td>\n",
       "      <td>[Q178869]</td>\n",
       "      <td>[Q3320632, Q253295]</td>\n",
       "      <td>[Q2078564]</td>\n",
       "      <td>ordinal</td>\n",
       "      <td>{'directed': True, 'multigraph': False, 'graph...</td>\n",
       "      <td>Mort,instance of,literary work,Mort,narrative ...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14282</th>\n",
       "      <td>2652ec2b</td>\n",
       "      <td>Which award did the first puzzle game by Firep...</td>\n",
       "      <td>[Q78762377]</td>\n",
       "      <td>[Q546692, Q15070334]</td>\n",
       "      <td>[Q16969671]</td>\n",
       "      <td>multihop</td>\n",
       "      <td>{'directed': True, 'multigraph': False, 'graph...</td>\n",
       "      <td>United States of America,country,United States...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14283</th>\n",
       "      <td>650ed632</td>\n",
       "      <td>Who was the last prime minister during Queen V...</td>\n",
       "      <td>[Q8016]</td>\n",
       "      <td>[Q9439]</td>\n",
       "      <td>[Q243705]</td>\n",
       "      <td>ordinal</td>\n",
       "      <td>{'directed': True, 'multigraph': False, 'graph...</td>\n",
       "      <td>Victoria,on focus list of Wikimedia project,Wi...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14284</th>\n",
       "      <td>3e711adc</td>\n",
       "      <td>What is the first Discworld book about the Cit...</td>\n",
       "      <td>[Q2383911]</td>\n",
       "      <td>[Q3320632, Q253295]</td>\n",
       "      <td>[Q2078564]</td>\n",
       "      <td>ordinal</td>\n",
       "      <td>{'directed': True, 'multigraph': False, 'graph...</td>\n",
       "      <td>Discworld,creator,Terry Pratchett,Thud!,author...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14285</th>\n",
       "      <td>3e711adc</td>\n",
       "      <td>What is the first Discworld book about the Cit...</td>\n",
       "      <td>[Q150901]</td>\n",
       "      <td>[Q3320632, Q253295]</td>\n",
       "      <td>[Q2078564]</td>\n",
       "      <td>ordinal</td>\n",
       "      <td>{'directed': True, 'multigraph': False, 'graph...</td>\n",
       "      <td>The Dark Side of the Moon,language of work or ...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14250 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             id                                           question  \\\n",
       "0      9ace9041    What is the fourth book in the Twilight series?   \n",
       "1      9ace9041    What is the fourth book in the Twilight series?   \n",
       "2      9ace9041    What is the fourth book in the Twilight series?   \n",
       "3      9ace9041    What is the fourth book in the Twilight series?   \n",
       "4      9ace9041    What is the fourth book in the Twilight series?   \n",
       "...         ...                                                ...   \n",
       "14281  3e711adc  What is the first Discworld book about the Cit...   \n",
       "14282  2652ec2b  Which award did the first puzzle game by Firep...   \n",
       "14283  650ed632  Who was the last prime minister during Queen V...   \n",
       "14284  3e711adc  What is the first Discworld book about the Cit...   \n",
       "14285  3e711adc  What is the first Discworld book about the Cit...   \n",
       "\n",
       "       answerEntity        questionEntity groundTruthAnswerEntity  \\\n",
       "0         [Q189378]              [Q44523]                [Q53945]   \n",
       "1       [Q19765983]              [Q44523]                [Q53945]   \n",
       "2      [Q111019576]              [Q44523]                [Q53945]   \n",
       "3         [Q849907]              [Q44523]                [Q53945]   \n",
       "4          [Q53945]              [Q44523]                [Q53945]   \n",
       "...             ...                   ...                     ...   \n",
       "14281     [Q178869]   [Q3320632, Q253295]              [Q2078564]   \n",
       "14282   [Q78762377]  [Q546692, Q15070334]             [Q16969671]   \n",
       "14283       [Q8016]               [Q9439]               [Q243705]   \n",
       "14284    [Q2383911]   [Q3320632, Q253295]              [Q2078564]   \n",
       "14285     [Q150901]   [Q3320632, Q253295]              [Q2078564]   \n",
       "\n",
       "      complexityType                                              graph  \\\n",
       "0            ordinal  {'directed': True, 'multigraph': False, 'graph...   \n",
       "1            ordinal  {'directed': True, 'multigraph': False, 'graph...   \n",
       "2            ordinal  {'directed': True, 'multigraph': False, 'graph...   \n",
       "3            ordinal  {'directed': True, 'multigraph': False, 'graph...   \n",
       "4            ordinal  {'directed': True, 'multigraph': False, 'graph...   \n",
       "...              ...                                                ...   \n",
       "14281        ordinal  {'directed': True, 'multigraph': False, 'graph...   \n",
       "14282       multihop  {'directed': True, 'multigraph': False, 'graph...   \n",
       "14283        ordinal  {'directed': True, 'multigraph': False, 'graph...   \n",
       "14284        ordinal  {'directed': True, 'multigraph': False, 'graph...   \n",
       "14285        ordinal  {'directed': True, 'multigraph': False, 'graph...   \n",
       "\n",
       "                                          graph_sequence  correct  \n",
       "0      Twilight,has part(s),Twilight,Twilight,part of...    False  \n",
       "1                        Twilight,genre,romantic fiction    False  \n",
       "2                         Twilight,genre,vampire fiction    False  \n",
       "3      Twilight,has part(s),The Short Second Life of ...    False  \n",
       "4      Twilight,has part(s),Breaking Dawn,Breaking Da...     True  \n",
       "...                                                  ...      ...  \n",
       "14281  Mort,instance of,literary work,Mort,narrative ...    False  \n",
       "14282  United States of America,country,United States...    False  \n",
       "14283  Victoria,on focus list of Wikimedia project,Wi...    False  \n",
       "14284  Discworld,creator,Terry Pratchett,Thud!,author...    False  \n",
       "14285  The Dark Side of the Moon,language of work or ...    False  \n",
       "\n",
       "[14250 rows x 9 columns]"
      ]
     },
     "execution_count": 309,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# deleting our error from main data\n",
    "df = df.drop(error_df.index)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving our final dataframe\n",
    "df.to_csv(dataset_path, index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building out Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import numpy as np\n",
    "from transformers import RobertaTokenizer, BertTokenizer, BertModel, RobertaModel\n",
    "from torch import nn\n",
    "from torch.optim import Adam\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_type = \"roberta-base\"\n",
    "bs = 16 if model_type == \"roberta-base\" or model_type == \"bert-base-cased\" else 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"/workspace/storage/subgraph_classify_dataset/SQWD/candidates_True\"\n",
    "dataset_type = \"sqwd\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(f\"{data_path}/{dataset_type}_train_labeled.csv\")\n",
    "val_df = pd.read_csv(f\"{data_path}/{dataset_type}_validation_labeled.csv\")\n",
    "test_df = pd.read_csv(f\"{data_path}/{dataset_type}_test_labeled.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "49953"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = RobertaTokenizer.from_pretrained(model_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preproc_text(graph_seqs, graph_labels):\n",
    "    \"tokenize our graph sequnces, skip if empty graph\"\n",
    "    labels_dict = {True: 1, False: 0}\n",
    "    labels = []\n",
    "    texts = []\n",
    "\n",
    "    for text, label in tqdm(zip(graph_seqs, graph_labels)):\n",
    "        if pd.isna(text):  # empty graph\n",
    "            continue\n",
    "        texts.append(\n",
    "            tokenizer(\n",
    "                text,\n",
    "                padding=\"max_length\",\n",
    "                max_length=512,\n",
    "                truncation=True,\n",
    "                return_tensors=\"pt\",\n",
    "            )\n",
    "        )\n",
    "        labels.append(labels_dict[label])\n",
    "    return texts, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "107299it [00:35, 3064.88it/s]\n",
      "24520it [00:07, 3170.37it/s]\n",
      "49953it [00:16, 3062.74it/s]\n"
     ]
    }
   ],
   "source": [
    "# preprocessing out texts and label\n",
    "train_text, train_label = preproc_text(\n",
    "    train_df[\"graph_sequence\"].tolist(), train_df[\"correct\"].tolist()\n",
    ")\n",
    "val_text, val_label = preproc_text(\n",
    "    val_df[\"graph_sequence\"].tolist(), val_df[\"correct\"].tolist()\n",
    ")\n",
    "test_text, test_label = preproc_text(\n",
    "    test_df[\"graph_sequence\"].tolist(), test_df[\"correct\"].tolist()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data.sampler import WeightedRandomSampler\n",
    "\n",
    "\n",
    "def create_sampler(target):\n",
    "    class_sample_count = np.array(\n",
    "        [len(np.where(target == t)[0]) for t in np.unique(target)]\n",
    "    )\n",
    "    weight = 1.0 / class_sample_count\n",
    "    samples_weight = np.array([weight[t] for t in target])\n",
    "\n",
    "    samples_weight = torch.from_numpy(samples_weight)\n",
    "    samples_weigth = samples_weight.double()\n",
    "    sampler = WeightedRandomSampler(samples_weight, len(samples_weight))\n",
    "\n",
    "    return sampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, labels, texts):\n",
    "        self.labels = labels\n",
    "        self.texts = texts\n",
    "\n",
    "    def classes(self):\n",
    "        return self.labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def get_batch_labels(self, idx):\n",
    "        # Fetch a batch of labels\n",
    "        return self.labels[idx]\n",
    "\n",
    "    def get_batch_texts(self, idx):\n",
    "        # Fetch a batch of inputs\n",
    "        return self.texts[idx]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        batch_texts = self.get_batch_texts(idx)\n",
    "        batch_y = self.get_batch_labels(idx)\n",
    "\n",
    "        return batch_texts, batch_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating our sampler for train, val and test\n",
    "train_sampler = create_sampler(train_label)\n",
    "val_sampler = create_sampler(val_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating our loaders\n",
    "train_dataset = Dataset(train_text, train_label)\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_dataset, batch_size=bs, sampler=train_sampler\n",
    ")\n",
    "\n",
    "val_dataset = Dataset(val_text, val_label)\n",
    "val_loader = torch.utils.data.DataLoader(\n",
    "    val_dataset, batch_size=bs, sampler=val_sampler\n",
    ")\n",
    "\n",
    "test_dataset = Dataset(test_text, test_label)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=bs)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model & Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BertClassifier(nn.Module):\n",
    "    def __init__(self, dropout=0.5):\n",
    "        super(BertClassifier, self).__init__()\n",
    "        if model_type == \"roberta-large\" or model_type == \"roberta-case\":\n",
    "            self.model = RobertaModel.from_pretrained(model_type)\n",
    "        else:\n",
    "            self.model = BertModel.from_pretrained(model_type)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        if model_type == \"bert-large-cased\" or model_type == \"roberta-large\":\n",
    "            dim = 1024\n",
    "        else:\n",
    "            dim = 768\n",
    "        self.linear = nn.Linear(dim, 2)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, input_id, mask):\n",
    "        _, pooled_output = self.model(\n",
    "            input_ids=input_id, attention_mask=mask, return_dict=False\n",
    "        )\n",
    "        dropout_output = self.dropout(pooled_output)\n",
    "        linear_output = self.linear(dropout_output)\n",
    "        final_layer = self.relu(linear_output)\n",
    "\n",
    "        return final_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-large were not used when initializing RobertaModel: ['lm_head.bias', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = BertClassifier().to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = Adam(model.parameters(), lr=1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def epoch_train(model, train_dataloader, criterion, optimizer):\n",
    "    total_acc_train = 0\n",
    "    total_loss_train = 0\n",
    "    for train_label, train_input in tqdm(train_dataloader):\n",
    "        train_label = train_label.to(device)\n",
    "        mask = train_input[\"attention_mask\"].to(device)\n",
    "        input_id = train_input[\"input_ids\"].squeeze(1).to(device)\n",
    "\n",
    "        output = model(input_id, mask)\n",
    "\n",
    "        batch_loss = criterion(output, train_label.long())\n",
    "        total_loss_train += batch_loss.item()\n",
    "\n",
    "        acc = (output.argmax(dim=1) == train_label).sum().item()\n",
    "        total_acc_train += acc\n",
    "\n",
    "        model.zero_grad()\n",
    "        batch_loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    return total_acc_train, total_loss_train\n",
    "\n",
    "\n",
    "def epoch_val(model, val_dataloader, criterion):\n",
    "    total_acc_val = 0\n",
    "    total_loss_val = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for val_label, val_input in tqdm(val_dataloader):\n",
    "            val_label = val_label.to(device)\n",
    "            mask = val_input[\"attention_mask\"].to(device)\n",
    "            input_id = val_input[\"input_ids\"].squeeze(1).to(device)\n",
    "\n",
    "            output = model(input_id, mask)\n",
    "\n",
    "            batch_loss = criterion(output, val_label.long())\n",
    "            total_loss_val += batch_loss.item()\n",
    "\n",
    "            acc = (output.argmax(dim=1) == val_label).sum().item()\n",
    "            total_acc_val += acc\n",
    "\n",
    "    return total_acc_val, total_loss_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(\n",
    "    model, train_dataloader, val_dataloader, criterion, optimizer, epochs, model_path\n",
    "):\n",
    "    best_acc = 0\n",
    "    for epoch_num in range(epochs):\n",
    "        total_acc_train = 0\n",
    "        total_loss_train = 0\n",
    "\n",
    "        (\n",
    "            total_acc_train,\n",
    "            total_loss_train,\n",
    "        ) = epoch_train(model, train_dataloader, criterion, optimizer)\n",
    "        total_acc_val, total_loss_val = epoch_val(model, val_dataloader, criterion)\n",
    "\n",
    "        train_loss = total_loss_train / len(train_dataloader.dataset)\n",
    "        train_acc = total_acc_train / len(train_dataloader.dataset)\n",
    "        val_loss = total_loss_val / len(val_dataloader.dataset)\n",
    "        val_acc = total_acc_val / len(val_dataloader.dataset)\n",
    "        print(\n",
    "            f\"Epochs: {epoch_num + 1} | Train Loss: {train_loss: .3f} | Train Accuracy: {train_acc: .3f} \\\n",
    "                | Val Loss: {val_loss: .3f} | Val Accuracy: {val_acc: .3f}\"\n",
    "        )\n",
    "\n",
    "        if val_acc > best_acc:\n",
    "            torch.save(\n",
    "                model,\n",
    "                model_path\n",
    "                + f\"{model.__class__.__name__ }_{dataset_type}_{model_type}_sampler.pt\",\n",
    "            )\n",
    "            best_acc = val_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "with_candidate = True\n",
    "model_path = f\"/workspace/storage/subgraph_classify_models/{dataset_type}/candidates_{with_candidate}/\"\n",
    "Path(model_path).mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "49850"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_loader.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13390/13390 [1:34:28<00:00,  2.36it/s]\n",
      "100%|██████████| 3060/3060 [07:08<00:00,  7.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 1 | Train Loss:  0.043 | Train Accuracy:  0.851                 | Val Loss:  0.042 | Val Accuracy:  0.864\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13390/13390 [1:34:49<00:00,  2.35it/s]\n",
      "100%|██████████| 3060/3060 [07:08<00:00,  7.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 2 | Train Loss:  0.033 | Train Accuracy:  0.894                 | Val Loss:  0.047 | Val Accuracy:  0.855\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 512/13390 [03:37<1:31:14,  2.35it/s]"
     ]
    }
   ],
   "source": [
    "train(model, train_loader, val_loader, criterion, optimizer, 5, model_path)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import balanced_accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load(\n",
    "    \"/workspace/storage/subgraph_classify_models/sqwd/candidates_True/BertClassifier_sqwd_roberta-base_sampler.pt\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(model, test_dataloader):\n",
    "    total_acc_val = 0\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for val_label, val_input in tqdm(test_dataloader):\n",
    "            val_label = val_label.to(device)\n",
    "            y_true.extend(val_label.tolist())\n",
    "            mask = val_input[\"attention_mask\"].to(device)\n",
    "            input_id = val_input[\"input_ids\"].squeeze(1).to(device)\n",
    "\n",
    "            output = model(input_id, mask)\n",
    "            y_pred.extend(output.argmax(dim=1).tolist())\n",
    "\n",
    "            acc = (output.argmax(dim=1) == val_label).sum().item()\n",
    "            total_acc_val += acc\n",
    "\n",
    "    final_acc = total_acc_val / len(test_dataloader.dataset)\n",
    "    balanced_acc = balanced_accuracy_score(y_true, y_pred)\n",
    "    return final_acc, balanced_acc, y_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3116/3116 [09:53<00:00,  5.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Accuracy: 0.79518555667001, balanced accuracy: 0.8637087858949936\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "final_acc, balanced_acc, y_true = test_model(model, test_loader)\n",
    "print(f\"Final Accuracy: {final_acc}, balanced accuracy: {balanced_acc}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy if we predict 0 for all questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8960280842527583\n"
     ]
    }
   ],
   "source": [
    "tmp = [0] * len(y_true)\n",
    "counter = 0\n",
    "for i, j in zip(tmp, y_true):\n",
    "    if i == j:\n",
    "        counter += 1\n",
    "print(counter / len(y_true))\n",
    "# print(acc/len(acc))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
