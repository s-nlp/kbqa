{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-25 08:22:56.338598: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-04-25 08:22:56.555585: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-04-25 08:22:57.172729: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
      "2024-04-25 08:22:57.172807: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
      "2024-04-25 08:22:57.172816: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from datasets import load_dataset, Dataset\n",
    "import random\n",
    "import json\n",
    "\n",
    "import numpy as np\n",
    "from transformers import set_seed\n",
    "import torch\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "from ranking_model import (\n",
    "    LogisticRegressionRanker,\n",
    "    LinearRegressionRanker,\n",
    "    MPNetRanker,\n",
    "    FullRandomRanker,\n",
    "    NORanker,\n",
    ")\n",
    "from ranking_data_utils import prepare_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "torch.cuda.manual_seed_all(42)\n",
    "set_seed(42)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d80721db5204be9b34c17ce19682566",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading readme:   0%|          | 0.00/1.81k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset None/None to /root/.cache/huggingface/datasets/hle2000___parquet/hle2000--KGQA_T5-xl-ssm-1744d8040d58562f/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "631fd899ce0c412d98b125b97311999f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af3a273f9d1047039a09d21f3a4346a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/409M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19d495f2d903464fab32daf482eb5ead",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/408M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab56da2efe2e455cb86949247ee571dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/409M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "000f223cba2c4f52bd661024c01a5db3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/408M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b238668712945f2adddf2b201e88e4a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/409M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52f2ff258bcf4590a87b005c3c13c5bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/408M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab325c299eb84307939ace4ed37f0f37",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/409M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f864d5976f014b3e83bf318c0965e39d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/408M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b47bc8734ce64146b6432be31ee2c2c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/408M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "82c549fe448e4ac8995cf4d5042cd7c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8e618d6cfcb4f7e95a2f95a949643d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/61833 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27a4a62459ab47518100a5b2ac795a21",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/61833 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54cca1e3293c4ca3a77ae8ffdce4d5c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/15577 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset parquet downloaded and prepared to /root/.cache/huggingface/datasets/hle2000___parquet/hle2000--KGQA_T5-xl-ssm-1744d8040d58562f/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0fb11274cad4f4ab3566816a6796dd4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "799e5252ef11442a92be4c2bf7230df4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading readme:   0%|          | 0.00/8.28k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset None/None to /root/.cache/huggingface/datasets/s-nlp___parquet/s-nlp--Mintaka_T5_xl_ssm_outputs-793d477384060fe7/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9deec7f55564017abc1342047c25e32",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "143e2b416a8243b682ac7b3dff3433fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/5.72M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13beeb42589f450380098364d21d3753",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/77.7M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8abe5e16baa5486692a305b8c6f0d031",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/10.9M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "083a9d064d8042aaa3787b882b6038f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be84babd29a74547bdabd8585a9e3251",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/2000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f422cbe12e448a49e4a6a32b6f4ecdd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/32000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20bb2c6f4a964ab7966bd857effb4099",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/4000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset parquet downloaded and prepared to /root/.cache/huggingface/datasets/s-nlp___parquet/s-nlp--Mintaka_T5_xl_ssm_outputs-793d477384060fe7/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4caf73f05c054ae8b3e30a7892b1eeeb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No config specified, defaulting to: mintaka/en\n",
      "Found cached dataset mintaka (/root/.cache/huggingface/datasets/AmazonScience___mintaka/en/1.0.0/bb35d95f07aed78fa590601245009c5f585efe909dbd4a8f2a4025ccf65bb11d)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3258e66aee54491a31aa31ee26ccaac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>target_out_of_vocab</th>\n",
       "      <th>answerEntity</th>\n",
       "      <th>questionEntity</th>\n",
       "      <th>groundTruthAnswerEntity</th>\n",
       "      <th>complexityType</th>\n",
       "      <th>graph</th>\n",
       "      <th>correct</th>\n",
       "      <th>t5_sequence</th>\n",
       "      <th>gap_sequence</th>\n",
       "      <th>...</th>\n",
       "      <th>gap_sequence_embedding</th>\n",
       "      <th>t5_sequence_embedding</th>\n",
       "      <th>question_answer_embedding</th>\n",
       "      <th>highlighted_determ_sequence</th>\n",
       "      <th>no_highlighted_determ_sequence</th>\n",
       "      <th>highlighted_t5_sequence</th>\n",
       "      <th>no_highlighted_t5_sequence</th>\n",
       "      <th>highlighted_gap_sequence</th>\n",
       "      <th>no_highlighted_gap_sequence</th>\n",
       "      <th>model_answers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>4000.000000</td>\n",
       "      <td>4000.000000</td>\n",
       "      <td>4000.000000</td>\n",
       "      <td>4000.000000</td>\n",
       "      <td>4000.000000</td>\n",
       "      <td>4000.000000</td>\n",
       "      <td>4000.000000</td>\n",
       "      <td>4000.000000</td>\n",
       "      <td>4000.000000</td>\n",
       "      <td>4000.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>4000.000000</td>\n",
       "      <td>4000.000000</td>\n",
       "      <td>4000.000000</td>\n",
       "      <td>4000.000000</td>\n",
       "      <td>4000.000000</td>\n",
       "      <td>4000.000000</td>\n",
       "      <td>4000.000000</td>\n",
       "      <td>4000.000000</td>\n",
       "      <td>4000.000000</td>\n",
       "      <td>4000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>4.286750</td>\n",
       "      <td>4.286750</td>\n",
       "      <td>3.894250</td>\n",
       "      <td>3.894250</td>\n",
       "      <td>3.894250</td>\n",
       "      <td>3.894250</td>\n",
       "      <td>3.894250</td>\n",
       "      <td>3.894250</td>\n",
       "      <td>3.894250</td>\n",
       "      <td>3.894250</td>\n",
       "      <td>...</td>\n",
       "      <td>3.894250</td>\n",
       "      <td>3.894250</td>\n",
       "      <td>3.894250</td>\n",
       "      <td>3.894250</td>\n",
       "      <td>3.894250</td>\n",
       "      <td>3.894250</td>\n",
       "      <td>3.894250</td>\n",
       "      <td>3.894250</td>\n",
       "      <td>3.894250</td>\n",
       "      <td>4.286750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3.132487</td>\n",
       "      <td>3.132487</td>\n",
       "      <td>3.554114</td>\n",
       "      <td>3.554114</td>\n",
       "      <td>3.554114</td>\n",
       "      <td>3.554114</td>\n",
       "      <td>3.554114</td>\n",
       "      <td>3.554114</td>\n",
       "      <td>3.554114</td>\n",
       "      <td>3.554114</td>\n",
       "      <td>...</td>\n",
       "      <td>3.554114</td>\n",
       "      <td>3.554114</td>\n",
       "      <td>3.554114</td>\n",
       "      <td>3.554114</td>\n",
       "      <td>3.554114</td>\n",
       "      <td>3.554114</td>\n",
       "      <td>3.554114</td>\n",
       "      <td>3.554114</td>\n",
       "      <td>3.554114</td>\n",
       "      <td>3.132487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>7.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>7.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>19.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>19.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            target  target_out_of_vocab  answerEntity  questionEntity  \\\n",
       "count  4000.000000          4000.000000   4000.000000     4000.000000   \n",
       "mean      4.286750             4.286750      3.894250        3.894250   \n",
       "std       3.132487             3.132487      3.554114        3.554114   \n",
       "min       1.000000             1.000000      0.000000        0.000000   \n",
       "25%       1.000000             1.000000      0.000000        0.000000   \n",
       "50%       4.000000             4.000000      4.000000        4.000000   \n",
       "75%       7.000000             7.000000      7.000000        7.000000   \n",
       "max      19.000000            19.000000     19.000000       19.000000   \n",
       "\n",
       "       groundTruthAnswerEntity  complexityType        graph      correct  \\\n",
       "count              4000.000000     4000.000000  4000.000000  4000.000000   \n",
       "mean                  3.894250        3.894250     3.894250     3.894250   \n",
       "std                   3.554114        3.554114     3.554114     3.554114   \n",
       "min                   0.000000        0.000000     0.000000     0.000000   \n",
       "25%                   0.000000        0.000000     0.000000     0.000000   \n",
       "50%                   4.000000        4.000000     4.000000     4.000000   \n",
       "75%                   7.000000        7.000000     7.000000     7.000000   \n",
       "max                  19.000000       19.000000    19.000000    19.000000   \n",
       "\n",
       "       t5_sequence  gap_sequence  ...  gap_sequence_embedding  \\\n",
       "count  4000.000000   4000.000000  ...             4000.000000   \n",
       "mean      3.894250      3.894250  ...                3.894250   \n",
       "std       3.554114      3.554114  ...                3.554114   \n",
       "min       0.000000      0.000000  ...                0.000000   \n",
       "25%       0.000000      0.000000  ...                0.000000   \n",
       "50%       4.000000      4.000000  ...                4.000000   \n",
       "75%       7.000000      7.000000  ...                7.000000   \n",
       "max      19.000000     19.000000  ...               19.000000   \n",
       "\n",
       "       t5_sequence_embedding  question_answer_embedding  \\\n",
       "count            4000.000000                4000.000000   \n",
       "mean                3.894250                   3.894250   \n",
       "std                 3.554114                   3.554114   \n",
       "min                 0.000000                   0.000000   \n",
       "25%                 0.000000                   0.000000   \n",
       "50%                 4.000000                   4.000000   \n",
       "75%                 7.000000                   7.000000   \n",
       "max                19.000000                  19.000000   \n",
       "\n",
       "       highlighted_determ_sequence  no_highlighted_determ_sequence  \\\n",
       "count                  4000.000000                     4000.000000   \n",
       "mean                      3.894250                        3.894250   \n",
       "std                       3.554114                        3.554114   \n",
       "min                       0.000000                        0.000000   \n",
       "25%                       0.000000                        0.000000   \n",
       "50%                       4.000000                        4.000000   \n",
       "75%                       7.000000                        7.000000   \n",
       "max                      19.000000                       19.000000   \n",
       "\n",
       "       highlighted_t5_sequence  no_highlighted_t5_sequence  \\\n",
       "count              4000.000000                 4000.000000   \n",
       "mean                  3.894250                    3.894250   \n",
       "std                   3.554114                    3.554114   \n",
       "min                   0.000000                    0.000000   \n",
       "25%                   0.000000                    0.000000   \n",
       "50%                   4.000000                    4.000000   \n",
       "75%                   7.000000                    7.000000   \n",
       "max                  19.000000                   19.000000   \n",
       "\n",
       "       highlighted_gap_sequence  no_highlighted_gap_sequence  model_answers  \n",
       "count               4000.000000                  4000.000000    4000.000000  \n",
       "mean                   3.894250                     3.894250       4.286750  \n",
       "std                    3.554114                     3.554114       3.132487  \n",
       "min                    0.000000                     0.000000       1.000000  \n",
       "25%                    0.000000                     0.000000       1.000000  \n",
       "50%                    4.000000                     4.000000       4.000000  \n",
       "75%                    7.000000                     7.000000       7.000000  \n",
       "max                   19.000000                    19.000000      19.000000  \n",
       "\n",
       "[8 rows x 31 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# os.environ['HF_DATASETS_CACHE'] = '/workspace/storage/misc/huggingface'\n",
    "\n",
    "ds_type = \"xl\"  # 'large' or 'xl'\n",
    "\n",
    "\n",
    "mintaka_dataset_path = \"AmazonScience/mintaka\"\n",
    "features_dataset_path = f\"hle2000/KGQA_T5-{ds_type}-ssm\"\n",
    "seq2seq_outputs_dataset_path = f\"s-nlp/Mintaka_T5_{ds_type}_ssm_outputs\"\n",
    "\n",
    "\n",
    "features_ds = load_dataset(features_dataset_path)\n",
    "outputs_ds = load_dataset(seq2seq_outputs_dataset_path)\n",
    "mintaka_ds = load_dataset(mintaka_dataset_path)\n",
    "\n",
    "\n",
    "train_df = prepare_data(mintaka_ds[\"train\"], outputs_ds[\"train\"], features_ds[\"train\"])\n",
    "valid_df = prepare_data(\n",
    "    mintaka_ds[\"validation\"], outputs_ds[\"validation\"], features_ds[\"validation\"]\n",
    ")\n",
    "test_df = prepare_data(mintaka_ds[\"test\"], outputs_ds[\"test\"], features_ds[\"test\"])\n",
    "test_df.groupby([\"id\", \"question\"]).count().describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_map = {\n",
    "    \"text\": [\"question_answer_embedding\"],\n",
    "    \"graph\": [\n",
    "        \"num_nodes\",\n",
    "        \"num_edges\",\n",
    "        \"density\",\n",
    "        \"cycle\",\n",
    "        \"bridge\",\n",
    "        \"katz_centrality\",\n",
    "        \"page_rank\",\n",
    "        \"avg_ssp_length\",\n",
    "    ],\n",
    "    \"g2t_determ\": [\"determ_sequence_embedding\"],\n",
    "    \"g2t_t5\": [\"t5_sequence_embedding\"],\n",
    "    \"g2t_gap\": [\"gap_sequence_embedding\"],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_path = Path(\n",
    "    f\"/mnt/storage/QA_System_Project/subgraphs_reranking_runs/reranking_model_results/t5_{ds_type}_ssm/\"\n",
    ")\n",
    "results_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "\n",
    "full_random_ranker = FullRandomRanker()\n",
    "with open(\n",
    "    results_path / f\"full_random_reranking_seq2seq_{ds_type}_results.jsonl\", \"w\"\n",
    ") as f:\n",
    "    for result in full_random_ranker.rerank(test_df):\n",
    "        f.write(json.dumps(result) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_ranker = NORanker()\n",
    "with open(results_path / f\"NO_reranking_seq2seq_{ds_type}_results.jsonl\", \"w\") as f:\n",
    "    for result in no_ranker.rerank(test_df):\n",
    "        f.write(json.dumps(result) + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg_ranker = LogisticRegressionRanker(features_map[\"text\"])\n",
    "logreg_ranker.fit(train_df, n_jobs=8)\n",
    "with open(\n",
    "    results_path / f\"logreg_text_reranking_seq2seq_{ds_type}_results.jsonl\", \"w\"\n",
    ") as f:\n",
    "    for result in logreg_ranker.rerank(test_df):\n",
    "        f.write(json.dumps(result) + \"\\n\")\n",
    "\n",
    "\n",
    "logreg_ranker = LogisticRegressionRanker(features_map[\"graph\"])\n",
    "logreg_ranker.fit(train_df, n_jobs=8)\n",
    "with open(\n",
    "    results_path / f\"logreg_graph_reranking_seq2seq_{ds_type}_results.jsonl\", \"w\"\n",
    ") as f:\n",
    "    for result in logreg_ranker.rerank(test_df):\n",
    "        f.write(json.dumps(result) + \"\\n\")\n",
    "\n",
    "\n",
    "logreg_ranker = LogisticRegressionRanker(features_map[\"text\"] + features_map[\"graph\"])\n",
    "logreg_ranker.fit(train_df, n_jobs=8)\n",
    "with open(\n",
    "    results_path / f\"logreg_text_graph_reranking_seq2seq_{ds_type}_results.jsonl\", \"w\"\n",
    ") as f:\n",
    "    for result in logreg_ranker.rerank(test_df):\n",
    "        f.write(json.dumps(result) + \"\\n\")\n",
    "\n",
    "\n",
    "logreg_ranker = LogisticRegressionRanker(features_map[\"g2t_determ\"])\n",
    "logreg_ranker.fit(train_df, n_jobs=8)\n",
    "with open(\n",
    "    results_path / f\"logreg_g2t_determ_reranking_seq2seq_{ds_type}_results.jsonl\", \"w\"\n",
    ") as f:\n",
    "    for result in logreg_ranker.rerank(test_df):\n",
    "        f.write(json.dumps(result) + \"\\n\")\n",
    "\n",
    "\n",
    "logreg_ranker = LogisticRegressionRanker(features_map[\"g2t_t5\"])\n",
    "logreg_ranker.fit(train_df, n_jobs=8)\n",
    "with open(\n",
    "    results_path / f\"logreg_g2t_t5_reranking_seq2seq_{ds_type}_results.jsonl\", \"w\"\n",
    ") as f:\n",
    "    for result in logreg_ranker.rerank(test_df):\n",
    "        f.write(json.dumps(result) + \"\\n\")\n",
    "\n",
    "\n",
    "logreg_ranker = LogisticRegressionRanker(features_map[\"g2t_gap\"])\n",
    "logreg_ranker.fit(train_df, n_jobs=8)\n",
    "with open(\n",
    "    results_path / f\"logreg_g2t_gap_reranking_seq2seq_{ds_type}_results.jsonl\", \"w\"\n",
    ") as f:\n",
    "    for result in logreg_ranker.rerank(test_df):\n",
    "        f.write(json.dumps(result) + \"\\n\")\n",
    "\n",
    "\n",
    "logreg_ranker = LogisticRegressionRanker(\n",
    "    features_map[\"text\"] + features_map[\"g2t_determ\"] + features_map[\"graph\"]\n",
    ")\n",
    "logreg_ranker.fit(train_df, n_jobs=8)\n",
    "with open(\n",
    "    results_path\n",
    "    / f\"logreg_text_g2t_determ_graph_reranking_seq2seq_{ds_type}_results.jsonl\",\n",
    "    \"w\",\n",
    ") as f:\n",
    "    for result in logreg_ranker.rerank(test_df):\n",
    "        f.write(json.dumps(result) + \"\\n\")\n",
    "\n",
    "\n",
    "logreg_ranker = LogisticRegressionRanker(\n",
    "    features_map[\"text\"] + features_map[\"g2t_t5\"] + features_map[\"graph\"]\n",
    ")\n",
    "logreg_ranker.fit(train_df, n_jobs=8)\n",
    "with open(\n",
    "    results_path\n",
    "    / f\"logreg_text_g2t_t5_graph_reranking_seq2seq_{ds_type}_results.jsonl\",\n",
    "    \"w\",\n",
    ") as f:\n",
    "    for result in logreg_ranker.rerank(test_df):\n",
    "        f.write(json.dumps(result) + \"\\n\")\n",
    "\n",
    "logreg_ranker = LogisticRegressionRanker(\n",
    "    features_map[\"text\"] + features_map[\"g2t_gap\"] + features_map[\"graph\"]\n",
    ")\n",
    "logreg_ranker.fit(train_df, n_jobs=8)\n",
    "with open(\n",
    "    results_path\n",
    "    / f\"logreg_text_g2t_gap_graph_reranking_seq2seq_{ds_type}_results.jsonl\",\n",
    "    \"w\",\n",
    ") as f:\n",
    "    for result in logreg_ranker.rerank(test_df):\n",
    "        f.write(json.dumps(result) + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg_ranker = LinearRegressionRanker(features_map[\"text\"])\n",
    "logreg_ranker.fit(train_df, n_jobs=8)\n",
    "with open(\n",
    "    results_path / f\"linreg_text_reranking_seq2seq_{ds_type}_results.jsonl\", \"w\"\n",
    ") as f:\n",
    "    for result in logreg_ranker.rerank(test_df):\n",
    "        f.write(json.dumps(result) + \"\\n\")\n",
    "\n",
    "\n",
    "logreg_ranker = LinearRegressionRanker(features_map[\"graph\"])\n",
    "logreg_ranker.fit(train_df, n_jobs=8)\n",
    "with open(\n",
    "    results_path / f\"linreg_graph_reranking_seq2seq_{ds_type}_results.jsonl\", \"w\"\n",
    ") as f:\n",
    "    for result in logreg_ranker.rerank(test_df):\n",
    "        f.write(json.dumps(result) + \"\\n\")\n",
    "\n",
    "\n",
    "logreg_ranker = LinearRegressionRanker(features_map[\"text\"] + features_map[\"graph\"])\n",
    "logreg_ranker.fit(train_df, n_jobs=8)\n",
    "with open(\n",
    "    results_path / f\"linreg_text_graph_reranking_seq2seq_{ds_type}_results.jsonl\", \"w\"\n",
    ") as f:\n",
    "    for result in logreg_ranker.rerank(test_df):\n",
    "        f.write(json.dumps(result) + \"\\n\")\n",
    "\n",
    "\n",
    "logreg_ranker = LinearRegressionRanker(features_map[\"g2t_determ\"])\n",
    "logreg_ranker.fit(train_df, n_jobs=8)\n",
    "with open(\n",
    "    results_path / f\"linreg_g2t_determ_reranking_seq2seq_{ds_type}_results.jsonl\", \"w\"\n",
    ") as f:\n",
    "    for result in logreg_ranker.rerank(test_df):\n",
    "        f.write(json.dumps(result) + \"\\n\")\n",
    "\n",
    "\n",
    "logreg_ranker = LinearRegressionRanker(features_map[\"g2t_t5\"])\n",
    "logreg_ranker.fit(train_df, n_jobs=8)\n",
    "with open(\n",
    "    results_path / f\"linreg_g2t_t5_reranking_seq2seq_{ds_type}_results.jsonl\", \"w\"\n",
    ") as f:\n",
    "    for result in logreg_ranker.rerank(test_df):\n",
    "        f.write(json.dumps(result) + \"\\n\")\n",
    "\n",
    "\n",
    "logreg_ranker = LinearRegressionRanker(features_map[\"g2t_gap\"])\n",
    "logreg_ranker.fit(train_df, n_jobs=8)\n",
    "with open(\n",
    "    results_path / f\"linreg_g2t_gap_reranking_seq2seq_{ds_type}_results.jsonl\", \"w\"\n",
    ") as f:\n",
    "    for result in logreg_ranker.rerank(test_df):\n",
    "        f.write(json.dumps(result) + \"\\n\")\n",
    "\n",
    "\n",
    "logreg_ranker = LinearRegressionRanker(\n",
    "    features_map[\"text\"] + features_map[\"g2t_determ\"] + features_map[\"graph\"]\n",
    ")\n",
    "logreg_ranker.fit(train_df, n_jobs=8)\n",
    "with open(\n",
    "    results_path\n",
    "    / f\"linreg_text_g2t_determ_graph_reranking_seq2seq_{ds_type}_results.jsonl\",\n",
    "    \"w\",\n",
    ") as f:\n",
    "    for result in logreg_ranker.rerank(test_df):\n",
    "        f.write(json.dumps(result) + \"\\n\")\n",
    "\n",
    "\n",
    "logreg_ranker = LinearRegressionRanker(\n",
    "    features_map[\"text\"] + features_map[\"g2t_t5\"] + features_map[\"graph\"]\n",
    ")\n",
    "logreg_ranker.fit(train_df, n_jobs=8)\n",
    "with open(\n",
    "    results_path\n",
    "    / f\"linreg_text_g2t_t5_graph_reranking_seq2seq_{ds_type}_results.jsonl\",\n",
    "    \"w\",\n",
    ") as f:\n",
    "    for result in logreg_ranker.rerank(test_df):\n",
    "        f.write(json.dumps(result) + \"\\n\")\n",
    "\n",
    "\n",
    "logreg_ranker = LinearRegressionRanker(\n",
    "    features_map[\"text\"] + features_map[\"g2t_gap\"] + features_map[\"graph\"]\n",
    ")\n",
    "logreg_ranker.fit(train_df, n_jobs=8)\n",
    "with open(\n",
    "    results_path\n",
    "    / f\"linreg_text_g2t_gap_graph_reranking_seq2seq_{ds_type}_results.jsonl\",\n",
    "    \"w\",\n",
    ") as f:\n",
    "    for result in logreg_ranker.rerank(test_df):\n",
    "        f.write(json.dumps(result) + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MPNet "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_path = Path(\n",
    "    f\"/workspace/storage/misc/subgraphs_reranking_runs/reranking_model_results/t5_{ds_type}_ssm/\"\n",
    ")\n",
    "Path(results_path).mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"sentence-transformers/all-mpnet-base-v2\")\n",
    "\n",
    "\n",
    "def apply_sep(seq):\n",
    "    if isinstance(seq, str):\n",
    "        q_a_splits = seq.split(\";\")\n",
    "        seq = f\"{q_a_splits[0]}{tokenizer}{q_a_splits[-1]}\"\n",
    "    return seq\n",
    "\n",
    "\n",
    "test_df[\"question_answer\"] = test_df[\"question_answer\"].apply(apply_sep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Try load model...\n",
      "Model Loaded.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d5407bd35bd4bcd9eb52f9475b97120",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\")\n",
    "\n",
    "model_path = \"/workspace/storage/misc/subgraphs_reranking_results/question_answer/T5-xl-ssm/question_answer_nocherries_fixed_train/outputs/checkpoint-best\"\n",
    "mpnet_ranker = MPNetRanker(\"question_answer\", model_path, device)\n",
    "with open(\n",
    "    results_path / f\"mpnet_text)only_determ_reranking_seq2seq_{ds_type}_results.jsonl\",\n",
    "    \"w+\",\n",
    ") as f:\n",
    "    for result in mpnet_ranker.rerank(test_df):\n",
    "        f.write(json.dumps(result) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Try load model...\n",
      "Model Loaded.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "579f2caacc9d4f04894e484d9cd40161",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Try load model...\n",
      "Model Loaded.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d93143f2fad34243a88cbc9bd3cf2f86",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\")\n",
    "\n",
    "model_path = f\"/mnt/storage/QA_System_Project/subgraphs_reranking_runs/determ/T5-{ds_type}-ssm/no_cherries_hl_false_determ/outputs/checkpoint-best\"\n",
    "mpnet_ranker = MPNetRanker(\"no_highlighted_determ_sequence\", model_path, device)\n",
    "with open(\n",
    "    results_path / f\"mpnet_no_hl_g2t_determ_reranking_seq2seq_{ds_type}_results.jsonl\",\n",
    "    \"w\",\n",
    ") as f:\n",
    "    for result in mpnet_ranker.rerank(test_df):\n",
    "        f.write(json.dumps(result) + \"\\n\")\n",
    "\n",
    "model_path = f\"/mnt/storage/QA_System_Project/subgraphs_reranking_runs/determ/T5-{ds_type}-ssm/no_cherries_hl_true_determ/outputs/checkpoint-best/\"\n",
    "mpnet_ranker = MPNetRanker(\"highlighted_determ_sequence\", model_path, device)\n",
    "with open(\n",
    "    results_path / f\"mpnet_hl_g2t_determ_reranking_seq2seq_{ds_type}_results.jsonl\", \"w\"\n",
    ") as f:\n",
    "    for result in mpnet_ranker.rerank(test_df):\n",
    "        f.write(json.dumps(result) + \"\\n\")\n",
    "\n",
    "\n",
    "model_path = f\"/mnt/storage/QA_System_Project/subgraphs_reranking_runs/g2t/T5-{ds_type}-ssm/no_cherries_fixed_train_g2t_hl_true_large/outputs/checkpoint-best\"\n",
    "mpnet_ranker = MPNetRanker(\"highlighted_t5_sequence\", model_path, device)\n",
    "with open(\n",
    "    results_path / f\"mpnet_hl_g2t_t5_reranking_seq2seq_{ds_type}_results.jsonl\", \"w\"\n",
    ") as f:\n",
    "    for result in mpnet_ranker.rerank(test_df):\n",
    "        f.write(json.dumps(result) + \"\\n\")\n",
    "\n",
    "model_path = f\"/mnt/storage/QA_System_Project/subgraphs_reranking_runs/g2t/T5-{ds_type}-ssm/no_cherries_fixed_train_g2t_hl_false_large/outputs/checkpoint-best\"\n",
    "mpnet_ranker = MPNetRanker(\"no_highlighted_t5_sequence\", model_path, device)\n",
    "with open(\n",
    "    results_path / f\"mpnet_no_hl_g2t_t5_reranking_seq2seq_{ds_type}_results.jsonl\", \"w\"\n",
    ") as f:\n",
    "    for result in mpnet_ranker.rerank(test_df):\n",
    "        f.write(json.dumps(result) + \"\\n\")\n",
    "\n",
    "\n",
    "model_path = f\"/mnt/storage/QA_System_Project/subgraphs_reranking_runs/gap/T5-{ds_type}-ssm/no_cherries_fixed_train_hl_true_gap_large/outputs/checkpoint-best\"\n",
    "mpnet_ranker = MPNetRanker(\"highlighted_gap_sequence\", model_path, device)\n",
    "with open(\n",
    "    results_path / f\"mpnet_hl_g2t_gap_reranking_seq2seq_{ds_type}_results.jsonl\", \"w\"\n",
    ") as f:\n",
    "    for result in mpnet_ranker.rerank(test_df):\n",
    "        f.write(json.dumps(result) + \"\\n\")\n",
    "\n",
    "model_path = f\"/mnt/storage/QA_System_Project/subgraphs_reranking_runs/gap/T5-{ds_type}-ssm/no_cherries_fixed_train_hl_false_gap_large/outputs/checkpoint-best\"\n",
    "mpnet_ranker = MPNetRanker(\"no_highlighted_gap_sequence\", model_path, device)\n",
    "with open(\n",
    "    results_path / f\"mpnet_no_hl_g2t_gap_reranking_seq2seq_{ds_type}_results.jsonl\", \"w\"\n",
    ") as f:\n",
    "    for result in mpnet_ranker.rerank(test_df):\n",
    "        f.write(json.dumps(result) + \"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
