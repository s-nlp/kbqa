{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-03 10:54:03.095669: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-05-03 10:54:03.294182: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-05-03 10:54:03.990625: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
      "2024-05-03 10:54:03.990699: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
      "2024-05-03 10:54:03.990707: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from datasets import load_dataset, Dataset\n",
    "import random\n",
    "import json\n",
    "\n",
    "import numpy as np\n",
    "from transformers import set_seed\n",
    "import torch\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "from ranking_model import (\n",
    "    LogisticRegressionRanker,\n",
    "    LinearRegressionRanker,\n",
    "    MPNetRanker,\n",
    "    CatboostRanker,\n",
    "    FullRandomRanker,\n",
    "    NORanker,\n",
    ")\n",
    "from ranking_data_utils import prepare_data\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def poop(s: preprocessing._data):\n",
    "    print(\"oogas\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "oogas\n"
     ]
    }
   ],
   "source": [
    "poop(preprocessing.StandardScaler())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "torch.cuda.manual_seed_all(42)\n",
    "set_seed(42)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/datasets/load.py:1486: FutureWarning: The repository for AmazonScience/mintaka contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/AmazonScience/mintaka\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# os.environ['HF_DATASETS_CACHE'] = '/workspace/storage/misc/huggingface'\n",
    "\n",
    "ds_type = \"t5xlssm\"  # 't5largessm', 't5xlssm', 'mistral' or 'mixtral'\n",
    "\n",
    "hf_cache_dir = \"/workspace/storage/misc/huggingface\"\n",
    "mintaka_dataset_path = \"AmazonScience/mintaka\"\n",
    "kgqa_ds_path = \"s-nlp/KGQASubgraphsRanking\"\n",
    "\n",
    "\n",
    "features_ds = load_dataset(\n",
    "    kgqa_ds_path, data_dir=f\"{ds_type}_subgraphs\", cache_dir=hf_cache_dir\n",
    ")\n",
    "outputs_ds = load_dataset(\n",
    "    kgqa_ds_path, data_dir=f\"{ds_type}_outputs\", cache_dir=hf_cache_dir\n",
    ")\n",
    "mintaka_ds = load_dataset(mintaka_dataset_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>target_out_of_vocab</th>\n",
       "      <th>answerEntity</th>\n",
       "      <th>questionEntity</th>\n",
       "      <th>groundTruthAnswerEntity</th>\n",
       "      <th>complexityType</th>\n",
       "      <th>graph</th>\n",
       "      <th>correct</th>\n",
       "      <th>t5_sequence</th>\n",
       "      <th>gap_sequence</th>\n",
       "      <th>...</th>\n",
       "      <th>gap_sequence_embedding</th>\n",
       "      <th>t5_sequence_embedding</th>\n",
       "      <th>question_answer_embedding</th>\n",
       "      <th>highlighted_determ_sequence</th>\n",
       "      <th>no_highlighted_determ_sequence</th>\n",
       "      <th>highlighted_t5_sequence</th>\n",
       "      <th>no_highlighted_t5_sequence</th>\n",
       "      <th>highlighted_gap_sequence</th>\n",
       "      <th>no_highlighted_gap_sequence</th>\n",
       "      <th>model_answers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>4000.000000</td>\n",
       "      <td>4000.000000</td>\n",
       "      <td>4000.000000</td>\n",
       "      <td>4000.000000</td>\n",
       "      <td>4000.000000</td>\n",
       "      <td>4000.000000</td>\n",
       "      <td>4000.000000</td>\n",
       "      <td>4000.000000</td>\n",
       "      <td>4000.000000</td>\n",
       "      <td>4000.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>4000.000000</td>\n",
       "      <td>4000.000000</td>\n",
       "      <td>4000.000000</td>\n",
       "      <td>4000.000000</td>\n",
       "      <td>4000.000000</td>\n",
       "      <td>4000.000000</td>\n",
       "      <td>4000.000000</td>\n",
       "      <td>4000.000000</td>\n",
       "      <td>4000.000000</td>\n",
       "      <td>4000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>4.286750</td>\n",
       "      <td>4.286750</td>\n",
       "      <td>3.894250</td>\n",
       "      <td>3.894250</td>\n",
       "      <td>3.894250</td>\n",
       "      <td>3.894250</td>\n",
       "      <td>3.894250</td>\n",
       "      <td>3.894250</td>\n",
       "      <td>3.894250</td>\n",
       "      <td>3.894250</td>\n",
       "      <td>...</td>\n",
       "      <td>3.894250</td>\n",
       "      <td>3.894250</td>\n",
       "      <td>3.894250</td>\n",
       "      <td>3.894250</td>\n",
       "      <td>3.894250</td>\n",
       "      <td>3.894250</td>\n",
       "      <td>3.894250</td>\n",
       "      <td>3.894250</td>\n",
       "      <td>3.894250</td>\n",
       "      <td>4.286750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3.132487</td>\n",
       "      <td>3.132487</td>\n",
       "      <td>3.554114</td>\n",
       "      <td>3.554114</td>\n",
       "      <td>3.554114</td>\n",
       "      <td>3.554114</td>\n",
       "      <td>3.554114</td>\n",
       "      <td>3.554114</td>\n",
       "      <td>3.554114</td>\n",
       "      <td>3.554114</td>\n",
       "      <td>...</td>\n",
       "      <td>3.554114</td>\n",
       "      <td>3.554114</td>\n",
       "      <td>3.554114</td>\n",
       "      <td>3.554114</td>\n",
       "      <td>3.554114</td>\n",
       "      <td>3.554114</td>\n",
       "      <td>3.554114</td>\n",
       "      <td>3.554114</td>\n",
       "      <td>3.554114</td>\n",
       "      <td>3.132487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>7.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>7.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>19.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>19.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            target  target_out_of_vocab  answerEntity  questionEntity  \\\n",
       "count  4000.000000          4000.000000   4000.000000     4000.000000   \n",
       "mean      4.286750             4.286750      3.894250        3.894250   \n",
       "std       3.132487             3.132487      3.554114        3.554114   \n",
       "min       1.000000             1.000000      0.000000        0.000000   \n",
       "25%       1.000000             1.000000      0.000000        0.000000   \n",
       "50%       4.000000             4.000000      4.000000        4.000000   \n",
       "75%       7.000000             7.000000      7.000000        7.000000   \n",
       "max      19.000000            19.000000     19.000000       19.000000   \n",
       "\n",
       "       groundTruthAnswerEntity  complexityType        graph      correct  \\\n",
       "count              4000.000000     4000.000000  4000.000000  4000.000000   \n",
       "mean                  3.894250        3.894250     3.894250     3.894250   \n",
       "std                   3.554114        3.554114     3.554114     3.554114   \n",
       "min                   0.000000        0.000000     0.000000     0.000000   \n",
       "25%                   0.000000        0.000000     0.000000     0.000000   \n",
       "50%                   4.000000        4.000000     4.000000     4.000000   \n",
       "75%                   7.000000        7.000000     7.000000     7.000000   \n",
       "max                  19.000000       19.000000    19.000000    19.000000   \n",
       "\n",
       "       t5_sequence  gap_sequence  ...  gap_sequence_embedding  \\\n",
       "count  4000.000000   4000.000000  ...             4000.000000   \n",
       "mean      3.894250      3.894250  ...                3.894250   \n",
       "std       3.554114      3.554114  ...                3.554114   \n",
       "min       0.000000      0.000000  ...                0.000000   \n",
       "25%       0.000000      0.000000  ...                0.000000   \n",
       "50%       4.000000      4.000000  ...                4.000000   \n",
       "75%       7.000000      7.000000  ...                7.000000   \n",
       "max      19.000000     19.000000  ...               19.000000   \n",
       "\n",
       "       t5_sequence_embedding  question_answer_embedding  \\\n",
       "count            4000.000000                4000.000000   \n",
       "mean                3.894250                   3.894250   \n",
       "std                 3.554114                   3.554114   \n",
       "min                 0.000000                   0.000000   \n",
       "25%                 0.000000                   0.000000   \n",
       "50%                 4.000000                   4.000000   \n",
       "75%                 7.000000                   7.000000   \n",
       "max                19.000000                  19.000000   \n",
       "\n",
       "       highlighted_determ_sequence  no_highlighted_determ_sequence  \\\n",
       "count                  4000.000000                     4000.000000   \n",
       "mean                      3.894250                        3.894250   \n",
       "std                       3.554114                        3.554114   \n",
       "min                       0.000000                        0.000000   \n",
       "25%                       0.000000                        0.000000   \n",
       "50%                       4.000000                        4.000000   \n",
       "75%                       7.000000                        7.000000   \n",
       "max                      19.000000                       19.000000   \n",
       "\n",
       "       highlighted_t5_sequence  no_highlighted_t5_sequence  \\\n",
       "count              4000.000000                 4000.000000   \n",
       "mean                  3.894250                    3.894250   \n",
       "std                   3.554114                    3.554114   \n",
       "min                   0.000000                    0.000000   \n",
       "25%                   0.000000                    0.000000   \n",
       "50%                   4.000000                    4.000000   \n",
       "75%                   7.000000                    7.000000   \n",
       "max                  19.000000                   19.000000   \n",
       "\n",
       "       highlighted_gap_sequence  no_highlighted_gap_sequence  model_answers  \n",
       "count               4000.000000                  4000.000000    4000.000000  \n",
       "mean                   3.894250                     3.894250       4.286750  \n",
       "std                    3.554114                     3.554114       3.132487  \n",
       "min                    0.000000                     0.000000       1.000000  \n",
       "25%                    0.000000                     0.000000       1.000000  \n",
       "50%                    4.000000                     4.000000       4.000000  \n",
       "75%                    7.000000                     7.000000       7.000000  \n",
       "max                   19.000000                    19.000000      19.000000  \n",
       "\n",
       "[8 rows x 31 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = prepare_data(mintaka_ds[\"train\"], outputs_ds[\"train\"], features_ds[\"train\"])\n",
    "valid_df = prepare_data(\n",
    "    mintaka_ds[\"validation\"], outputs_ds[\"validation\"], features_ds[\"validation\"]\n",
    ")\n",
    "test_df = prepare_data(mintaka_ds[\"test\"], outputs_ds[\"test\"], features_ds[\"test\"])\n",
    "test_df.groupby([\"id\", \"question\"]).count().describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_map = {\n",
    "    \"text\": [\"question_answer_embedding\"],\n",
    "    \"graph\": [\n",
    "        \"num_nodes\",\n",
    "        \"num_edges\",\n",
    "        \"density\",\n",
    "        \"cycle\",\n",
    "        \"bridge\",\n",
    "        \"katz_centrality\",\n",
    "        \"page_rank\",\n",
    "        \"avg_ssp_length\",\n",
    "    ],\n",
    "    \"g2t_determ\": [\"determ_sequence_embedding\"],\n",
    "    \"g2t_t5\": [\"t5_sequence_embedding\"],\n",
    "    \"g2t_gap\": [\"gap_sequence_embedding\"],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_path = Path(\n",
    "    f\"/workspace/storage/misc/subgraphs_reranking_runs/reranking_model_results/{ds_type}/\"\n",
    ")\n",
    "results_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "\n",
    "full_random_ranker = FullRandomRanker()\n",
    "with open(\n",
    "    results_path / f\"full_random_reranking_seq2seq_{ds_type}_results.jsonl\", \"w\"\n",
    ") as f:\n",
    "    for result in full_random_ranker.rerank(test_df):\n",
    "        f.write(json.dumps(result) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_ranker = NORanker()\n",
    "with open(results_path / f\"NO_reranking_seq2seq_{ds_type}_results.jsonl\", \"w\") as f:\n",
    "    for result in no_ranker.rerank(test_df):\n",
    "        f.write(json.dumps(result) + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspace/kbqa/experiments/subgraphs_reranking/ranking_model.py:169: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_df[self.graph_features] = scaler.fit_transform(\n",
      "/workspace/kbqa/experiments/subgraphs_reranking/ranking_model.py:169: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_df[self.graph_features] = scaler.fit_transform(\n",
      "/workspace/kbqa/experiments/subgraphs_reranking/ranking_model.py:169: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_df[self.graph_features] = scaler.fit_transform(\n",
      "/workspace/kbqa/experiments/subgraphs_reranking/ranking_model.py:169: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_df[self.graph_features] = scaler.fit_transform(\n",
      "/workspace/kbqa/experiments/subgraphs_reranking/ranking_model.py:169: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_df[self.graph_features] = scaler.fit_transform(\n"
     ]
    }
   ],
   "source": [
    "logreg_ranker = LogisticRegressionRanker(sequence_features=features_map[\"text\"])\n",
    "logreg_ranker.fit(train_df, n_jobs=8)\n",
    "with open(\n",
    "    results_path / f\"logreg_text_reranking_seq2seq_{ds_type}_results.jsonl\", \"w\"\n",
    ") as f:\n",
    "    for result in logreg_ranker.rerank(test_df):\n",
    "        f.write(json.dumps(result) + \"\\n\")\n",
    "\n",
    "scaler = preprocessing.MinMaxScaler()\n",
    "logreg_ranker = LogisticRegressionRanker(graph_features=features_map[\"graph\"])\n",
    "logreg_ranker.fit(train_df, n_jobs=8, scaler=scaler)\n",
    "with open(\n",
    "    results_path / f\"logreg_graph_reranking_seq2seq_{ds_type}_results.jsonl\", \"w\"\n",
    ") as f:\n",
    "    for result in logreg_ranker.rerank(test_df):\n",
    "        f.write(json.dumps(result) + \"\\n\")\n",
    "\n",
    "\n",
    "logreg_ranker = LogisticRegressionRanker(\n",
    "    sequence_features=features_map[\"text\"], graph_features=features_map[\"graph\"]\n",
    ")\n",
    "logreg_ranker.fit(train_df, n_jobs=8, scaler=scaler)\n",
    "with open(\n",
    "    results_path / f\"logreg_text_graph_reranking_seq2seq_{ds_type}_results.jsonl\", \"w\"\n",
    ") as f:\n",
    "    for result in logreg_ranker.rerank(test_df):\n",
    "        f.write(json.dumps(result) + \"\\n\")\n",
    "\n",
    "\n",
    "logreg_ranker = LogisticRegressionRanker(sequence_features=features_map[\"g2t_determ\"])\n",
    "logreg_ranker.fit(train_df, n_jobs=8)\n",
    "with open(\n",
    "    results_path / f\"logreg_g2t_determ_reranking_seq2seq_{ds_type}_results.jsonl\", \"w\"\n",
    ") as f:\n",
    "    for result in logreg_ranker.rerank(test_df):\n",
    "        f.write(json.dumps(result) + \"\\n\")\n",
    "\n",
    "\n",
    "logreg_ranker = LogisticRegressionRanker(sequence_features=features_map[\"g2t_t5\"])\n",
    "logreg_ranker.fit(train_df, n_jobs=8)\n",
    "with open(\n",
    "    results_path / f\"logreg_g2t_t5_reranking_seq2seq_{ds_type}_results.jsonl\", \"w\"\n",
    ") as f:\n",
    "    for result in logreg_ranker.rerank(test_df):\n",
    "        f.write(json.dumps(result) + \"\\n\")\n",
    "\n",
    "\n",
    "logreg_ranker = LogisticRegressionRanker(sequence_features=features_map[\"g2t_gap\"])\n",
    "logreg_ranker.fit(train_df, n_jobs=8)\n",
    "with open(\n",
    "    results_path / f\"logreg_g2t_gap_reranking_seq2seq_{ds_type}_results.jsonl\", \"w\"\n",
    ") as f:\n",
    "    for result in logreg_ranker.rerank(test_df):\n",
    "        f.write(json.dumps(result) + \"\\n\")\n",
    "\n",
    "\n",
    "logreg_ranker = LogisticRegressionRanker(\n",
    "    sequence_features=features_map[\"text\"] + features_map[\"g2t_determ\"],\n",
    "    graph_features=features_map[\"graph\"],\n",
    ")\n",
    "logreg_ranker.fit(train_df, n_jobs=8, scaler=scaler)\n",
    "with open(\n",
    "    results_path\n",
    "    / f\"logreg_text_g2t_determ_graph_reranking_seq2seq_{ds_type}_results.jsonl\",\n",
    "    \"w\",\n",
    ") as f:\n",
    "    for result in logreg_ranker.rerank(test_df):\n",
    "        f.write(json.dumps(result) + \"\\n\")\n",
    "\n",
    "\n",
    "logreg_ranker = LogisticRegressionRanker(\n",
    "    sequence_features=features_map[\"text\"] + features_map[\"g2t_t5\"],\n",
    "    graph_features=features_map[\"graph\"],\n",
    ")\n",
    "logreg_ranker.fit(train_df, n_jobs=8, scaler=scaler)\n",
    "with open(\n",
    "    results_path\n",
    "    / f\"logreg_text_g2t_t5_graph_reranking_seq2seq_{ds_type}_results.jsonl\",\n",
    "    \"w\",\n",
    ") as f:\n",
    "    for result in logreg_ranker.rerank(test_df):\n",
    "        f.write(json.dumps(result) + \"\\n\")\n",
    "\n",
    "logreg_ranker = LogisticRegressionRanker(\n",
    "    sequence_features=features_map[\"text\"] + features_map[\"g2t_gap\"],\n",
    "    graph_features=features_map[\"graph\"],\n",
    ")\n",
    "logreg_ranker.fit(train_df, n_jobs=8, scaler=scaler)\n",
    "with open(\n",
    "    results_path\n",
    "    / f\"logreg_text_g2t_gap_graph_reranking_seq2seq_{ds_type}_results.jsonl\",\n",
    "    \"w\",\n",
    ") as f:\n",
    "    for result in logreg_ranker.rerank(test_df):\n",
    "        f.write(json.dumps(result) + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg_ranker = LinearRegressionRanker(sequence_features=features_map[\"text\"])\n",
    "logreg_ranker.fit(train_df, n_jobs=8)\n",
    "with open(\n",
    "    results_path / f\"linreg_text_reranking_seq2seq_{ds_type}_results.jsonl\", \"w\"\n",
    ") as f:\n",
    "    for result in logreg_ranker.rerank(test_df):\n",
    "        f.write(json.dumps(result) + \"\\n\")\n",
    "\n",
    "\n",
    "logreg_ranker = LinearRegressionRanker(graph_features=features_map[\"graph\"])\n",
    "logreg_ranker.fit(train_df, n_jobs=8)\n",
    "with open(\n",
    "    results_path / f\"linreg_graph_reranking_seq2seq_{ds_type}_results.jsonl\", \"w\"\n",
    ") as f:\n",
    "    for result in logreg_ranker.rerank(test_df):\n",
    "        f.write(json.dumps(result) + \"\\n\")\n",
    "\n",
    "\n",
    "logreg_ranker = LinearRegressionRanker(\n",
    "    sequence_features=features_map[\"text\"], graph_features=features_map[\"graph\"]\n",
    ")\n",
    "logreg_ranker.fit(train_df, n_jobs=8)\n",
    "with open(\n",
    "    results_path / f\"linreg_text_graph_reranking_seq2seq_{ds_type}_results.jsonl\", \"w\"\n",
    ") as f:\n",
    "    for result in logreg_ranker.rerank(test_df):\n",
    "        f.write(json.dumps(result) + \"\\n\")\n",
    "\n",
    "\n",
    "logreg_ranker = LinearRegressionRanker(sequence_features=features_map[\"g2t_determ\"])\n",
    "logreg_ranker.fit(train_df, n_jobs=8)\n",
    "with open(\n",
    "    results_path / f\"linreg_g2t_determ_reranking_seq2seq_{ds_type}_results.jsonl\", \"w\"\n",
    ") as f:\n",
    "    for result in logreg_ranker.rerank(test_df):\n",
    "        f.write(json.dumps(result) + \"\\n\")\n",
    "\n",
    "\n",
    "logreg_ranker = LinearRegressionRanker(sequence_features=features_map[\"g2t_t5\"])\n",
    "logreg_ranker.fit(train_df, n_jobs=8)\n",
    "with open(\n",
    "    results_path / f\"linreg_g2t_t5_reranking_seq2seq_{ds_type}_results.jsonl\", \"w\"\n",
    ") as f:\n",
    "    for result in logreg_ranker.rerank(test_df):\n",
    "        f.write(json.dumps(result) + \"\\n\")\n",
    "\n",
    "\n",
    "logreg_ranker = LinearRegressionRanker(sequence_features=features_map[\"g2t_gap\"])\n",
    "logreg_ranker.fit(train_df, n_jobs=8)\n",
    "with open(\n",
    "    results_path / f\"linreg_g2t_gap_reranking_seq2seq_{ds_type}_results.jsonl\", \"w\"\n",
    ") as f:\n",
    "    for result in logreg_ranker.rerank(test_df):\n",
    "        f.write(json.dumps(result) + \"\\n\")\n",
    "\n",
    "\n",
    "logreg_ranker = LinearRegressionRanker(\n",
    "    sequence_features=features_map[\"text\"] + features_map[\"g2t_determ\"],\n",
    "    graph_features=features_map[\"graph\"],\n",
    ")\n",
    "logreg_ranker.fit(train_df, n_jobs=8)\n",
    "with open(\n",
    "    results_path\n",
    "    / f\"linreg_text_g2t_determ_graph_reranking_seq2seq_{ds_type}_results.jsonl\",\n",
    "    \"w\",\n",
    ") as f:\n",
    "    for result in logreg_ranker.rerank(test_df):\n",
    "        f.write(json.dumps(result) + \"\\n\")\n",
    "\n",
    "\n",
    "logreg_ranker = LinearRegressionRanker(\n",
    "    sequence_features=features_map[\"text\"] + features_map[\"g2t_t5\"],\n",
    "    graph_features=features_map[\"graph\"],\n",
    ")\n",
    "logreg_ranker.fit(train_df, n_jobs=8)\n",
    "with open(\n",
    "    results_path\n",
    "    / f\"linreg_text_g2t_t5_graph_reranking_seq2seq_{ds_type}_results.jsonl\",\n",
    "    \"w\",\n",
    ") as f:\n",
    "    for result in logreg_ranker.rerank(test_df):\n",
    "        f.write(json.dumps(result) + \"\\n\")\n",
    "\n",
    "\n",
    "logreg_ranker = LinearRegressionRanker(\n",
    "    sequence_features=features_map[\"text\"] + features_map[\"g2t_gap\"],\n",
    "    graph_features=features_map[\"graph\"],\n",
    ")\n",
    "logreg_ranker.fit(train_df, n_jobs=8)\n",
    "with open(\n",
    "    results_path\n",
    "    / f\"linreg_text_g2t_gap_graph_reranking_seq2seq_{ds_type}_results.jsonl\",\n",
    "    \"w\",\n",
    ") as f:\n",
    "    for result in logreg_ranker.rerank(test_df):\n",
    "        f.write(json.dumps(result) + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MPNet "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"sentence-transformers/all-mpnet-base-v2\")\n",
    "\n",
    "\n",
    "def apply_sep(seq):\n",
    "    if isinstance(seq, str):\n",
    "        q_a_splits = seq.split(\";\")\n",
    "        seq = f\"{q_a_splits[0]}{tokenizer}{q_a_splits[-1]}\"\n",
    "    return seq\n",
    "\n",
    "\n",
    "test_df[\"question_answer\"] = test_df[\"question_answer\"].apply(apply_sep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Try load model...\n",
      "Model Loaded.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "579f2caacc9d4f04894e484d9cd40161",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Try load model...\n",
      "Model Loaded.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d93143f2fad34243a88cbc9bd3cf2f86",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\")\n",
    "\n",
    "model_path = \"/workspace/storage/misc/subgraphs_reranking_results/question_answer/T5-xl-ssm/question_answer_nocherries_fixed_train/outputs/checkpoint-best\"\n",
    "mpnet_ranker = MPNetRanker(\"question_answer\", model_path, device)\n",
    "with open(\n",
    "    results_path / f\"mpnet_text_only_determ_reranking_seq2seq_{ds_type}_results.jsonl\",\n",
    "    \"w+\",\n",
    ") as f:\n",
    "    for result in mpnet_ranker.rerank(test_df):\n",
    "        f.write(json.dumps(result) + \"\\n\")\n",
    "\n",
    "model_path = f\"/mnt/storage/QA_System_Project/subgraphs_reranking_runs/determ/T5-{ds_type}-ssm/no_cherries_hl_false_determ/outputs/checkpoint-best\"\n",
    "mpnet_ranker = MPNetRanker(\"no_highlighted_determ_sequence\", model_path, device)\n",
    "with open(\n",
    "    results_path / f\"mpnet_no_hl_g2t_determ_reranking_seq2seq_{ds_type}_results.jsonl\",\n",
    "    \"w\",\n",
    ") as f:\n",
    "    for result in mpnet_ranker.rerank(test_df):\n",
    "        f.write(json.dumps(result) + \"\\n\")\n",
    "\n",
    "model_path = f\"/mnt/storage/QA_System_Project/subgraphs_reranking_runs/determ/T5-{ds_type}-ssm/no_cherries_hl_true_determ/outputs/checkpoint-best/\"\n",
    "mpnet_ranker = MPNetRanker(\"highlighted_determ_sequence\", model_path, device)\n",
    "with open(\n",
    "    results_path / f\"mpnet_hl_g2t_determ_reranking_seq2seq_{ds_type}_results.jsonl\", \"w\"\n",
    ") as f:\n",
    "    for result in mpnet_ranker.rerank(test_df):\n",
    "        f.write(json.dumps(result) + \"\\n\")\n",
    "\n",
    "\n",
    "model_path = f\"/mnt/storage/QA_System_Project/subgraphs_reranking_runs/g2t/T5-{ds_type}-ssm/no_cherries_fixed_train_g2t_hl_true_large/outputs/checkpoint-best\"\n",
    "mpnet_ranker = MPNetRanker(\"highlighted_t5_sequence\", model_path, device)\n",
    "with open(\n",
    "    results_path / f\"mpnet_hl_g2t_t5_reranking_seq2seq_{ds_type}_results.jsonl\", \"w\"\n",
    ") as f:\n",
    "    for result in mpnet_ranker.rerank(test_df):\n",
    "        f.write(json.dumps(result) + \"\\n\")\n",
    "\n",
    "model_path = f\"/mnt/storage/QA_System_Project/subgraphs_reranking_runs/g2t/T5-{ds_type}-ssm/no_cherries_fixed_train_g2t_hl_false_large/outputs/checkpoint-best\"\n",
    "mpnet_ranker = MPNetRanker(\"no_highlighted_t5_sequence\", model_path, device)\n",
    "with open(\n",
    "    results_path / f\"mpnet_no_hl_g2t_t5_reranking_seq2seq_{ds_type}_results.jsonl\", \"w\"\n",
    ") as f:\n",
    "    for result in mpnet_ranker.rerank(test_df):\n",
    "        f.write(json.dumps(result) + \"\\n\")\n",
    "\n",
    "\n",
    "model_path = f\"/mnt/storage/QA_System_Project/subgraphs_reranking_runs/gap/T5-{ds_type}-ssm/no_cherries_fixed_train_hl_true_gap_large/outputs/checkpoint-best\"\n",
    "mpnet_ranker = MPNetRanker(\"highlighted_gap_sequence\", model_path, device)\n",
    "with open(\n",
    "    results_path / f\"mpnet_hl_g2t_gap_reranking_seq2seq_{ds_type}_results.jsonl\", \"w\"\n",
    ") as f:\n",
    "    for result in mpnet_ranker.rerank(test_df):\n",
    "        f.write(json.dumps(result) + \"\\n\")\n",
    "\n",
    "model_path = f\"/mnt/storage/QA_System_Project/subgraphs_reranking_runs/gap/T5-{ds_type}-ssm/no_cherries_fixed_train_hl_false_gap_large/outputs/checkpoint-best\"\n",
    "mpnet_ranker = MPNetRanker(\"no_highlighted_gap_sequence\", model_path, device)\n",
    "with open(\n",
    "    results_path / f\"mpnet_no_hl_g2t_gap_reranking_seq2seq_{ds_type}_results.jsonl\", \"w\"\n",
    ") as f:\n",
    "    for result in mpnet_ranker.rerank(test_df):\n",
    "        f.write(json.dumps(result) + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "catboost_dir = (\n",
    "    f\"/workspace/storage/misc/features_reranking/catboost/unified_reranking/{ds_type}\"\n",
    ")\n",
    "model_weights = f\"{catboost_dir}/text/best_model\"\n",
    "catboost_ranker = CatboostRanker(model_weights, graph_features=features_map[\"text\"])\n",
    "\n",
    "with open(\n",
    "    results_path / f\"catboost_graph_reranking_seq2seq_{ds_type}_results.jsonl\", \"w\"\n",
    ") as f:\n",
    "    for result in catboost_ranker.rerank(test_df):\n",
    "        f.write(json.dumps(result) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trying to load the model...\n",
      "Model Loaded.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "387842ac132b49e7aac60bb326e69e57",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "catboost_dir = (\n",
    "    f\"/workspace/storage/misc/features_reranking/catboost/unified_reranking/{ds_type}\"\n",
    ")\n",
    "model_weights = f\"{catboost_dir}/graph/best_model\"\n",
    "fitted_scaler_path = f\"{catboost_dir}/graph/fitted_scaler.bz2\"\n",
    "catboost_ranker = CatboostRanker(\n",
    "    model_weights, graph_features=features_map[\"graph\"], scaler_path=fitted_scaler_path\n",
    ")\n",
    "\n",
    "with open(\n",
    "    results_path / f\"catboost_graph_reranking_seq2seq_{ds_type}_results.jsonl\", \"w\"\n",
    ") as f:\n",
    "    for result in catboost_ranker.rerank(test_df):\n",
    "        f.write(json.dumps(result) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trying to load the model...\n",
      "Model Loaded.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "177b5f610de44f18a349afb57dae8211",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_weights = f\"{catboost_dir}/text_graph/best_model\"\n",
    "fitted_scaler_path = f\"{catboost_dir}/text_graph/fitted_scaler.bz2\"\n",
    "catboost_ranker = CatboostRanker(\n",
    "    model_weights,\n",
    "    sequence_features=features_map[\"text\"],\n",
    "    graph_features=features_map[\"graph\"],\n",
    "    scaler_path=fitted_scaler_path,\n",
    ")\n",
    "\n",
    "with open(\n",
    "    results_path / f\"catboost_text_graph_reranking_seq2seq_{ds_type}_results.jsonl\", \"w\"\n",
    ") as f:\n",
    "    for result in catboost_ranker.rerank(test_df):\n",
    "        f.write(json.dumps(result) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trying to load the model...\n",
      "Model Loaded.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54f8eb0a67344258ba0cb2db752d88c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_weights = f\"{catboost_dir}/g2t_determ/best_model\"\n",
    "catboost_ranker = CatboostRanker(\n",
    "    model_weights, sequence_features=features_map[\"g2t_determ\"]\n",
    ")\n",
    "\n",
    "with open(\n",
    "    results_path / f\"catboost_g2t_determ_reranking_seq2seq_{ds_type}_results.jsonl\", \"w\"\n",
    ") as f:\n",
    "    for result in catboost_ranker.rerank(test_df):\n",
    "        f.write(json.dumps(result) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trying to load the model...\n",
      "Model Loaded.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b6b1baa38794664ab53885e9b68283a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_weights = f\"{catboost_dir}/g2t_t5/best_model\"\n",
    "catboost_ranker = CatboostRanker(\n",
    "    model_weights, sequence_features=features_map[\"g2t_t5\"]\n",
    ")\n",
    "\n",
    "with open(\n",
    "    results_path / f\"catboost_g2t_t5_reranking_seq2seq_{ds_type}_results.jsonl\", \"w\"\n",
    ") as f:\n",
    "    for result in catboost_ranker.rerank(test_df):\n",
    "        f.write(json.dumps(result) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trying to load the model...\n",
      "Model Loaded.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d83ca03af9ce4861baa615cc04c64ff0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_weights = f\"{catboost_dir}/g2t_gap/best_model\"\n",
    "catboost_ranker = CatboostRanker(\n",
    "    model_weights, sequence_features=features_map[\"g2t_gap\"]\n",
    ")\n",
    "\n",
    "with open(\n",
    "    results_path / f\"catboost_g2t_gap_reranking_seq2seq_{ds_type}_results.jsonl\", \"w\"\n",
    ") as f:\n",
    "    for result in catboost_ranker.rerank(test_df):\n",
    "        f.write(json.dumps(result) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trying to load the model...\n",
      "Model Loaded.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "141c985e38f940269b5657720a0eaa70",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_weights = f\"{catboost_dir}/text_graph_g2t_determ/best_model\"\n",
    "fitted_scaler_path = f\"{catboost_dir}/text_graph_g2t_determ/fitted_scaler.bz2\"\n",
    "catboost_ranker = CatboostRanker(\n",
    "    model_weights,\n",
    "    sequence_features=features_map[\"text\"] + features_map[\"g2t_determ\"],\n",
    "    graph_features=features_map[\"graph\"],\n",
    "    scaler_path=fitted_scaler_path,\n",
    ")\n",
    "with open(\n",
    "    results_path\n",
    "    / f\"catboost_text_graph_g2t_determ_reranking_seq2seq_{ds_type}_results.jsonl\",\n",
    "    \"w\",\n",
    ") as f:\n",
    "    for result in catboost_ranker.rerank(test_df):\n",
    "        f.write(json.dumps(result) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trying to load the model...\n",
      "Model Loaded.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db3a397f28564a6fa6ae54a6bc3c92b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_weights = f\"{catboost_dir}/text_graph_g2t_t5/best_model\"\n",
    "fitted_scaler_path = f\"{catboost_dir}/text_graph_g2t_t5/fitted_scaler.bz2\"\n",
    "catboost_ranker = CatboostRanker(\n",
    "    model_weights,\n",
    "    sequence_features=features_map[\"text\"] + features_map[\"g2t_t5\"],\n",
    "    graph_features=features_map[\"graph\"],\n",
    "    scaler_path=fitted_scaler_path,\n",
    ")\n",
    "\n",
    "with open(\n",
    "    results_path\n",
    "    / f\"catboost_text_graph_g2t_t5_reranking_seq2seq_{ds_type}_results.jsonl\",\n",
    "    \"w\",\n",
    ") as f:\n",
    "    for result in catboost_ranker.rerank(test_df):\n",
    "        f.write(json.dumps(result) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trying to load the model...\n",
      "Model Loaded.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62ebf69b68b0494cb0b17fbb4b359dfb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_weights = f\"{catboost_dir}/text_graph_g2t_gap/best_model\"\n",
    "fitted_scaler_path = f\"{catboost_dir}/text_graph_g2t_gap/fitted_scaler.bz2\"\n",
    "catboost_ranker = CatboostRanker(\n",
    "    model_weights,\n",
    "    sequence_features=features_map[\"text\"] + features_map[\"g2t_gap\"],\n",
    "    graph_features=features_map[\"graph\"],\n",
    "    scaler_path=fitted_scaler_path,\n",
    ")\n",
    "\n",
    "with open(\n",
    "    results_path\n",
    "    / f\"catboost_text_graph_g2t_gap_reranking_seq2seq_{ds_type}_results.jsonl\",\n",
    "    \"w\",\n",
    ") as f:\n",
    "    for result in catboost_ranker.rerank(test_df):\n",
    "        f.write(json.dumps(result) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
