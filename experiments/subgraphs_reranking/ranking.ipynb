{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-30 17:43:24.933877: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-04-30 17:43:25.090768: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-04-30 17:43:25.801544: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
      "2024-04-30 17:43:25.801630: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
      "2024-04-30 17:43:25.801638: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from datasets import load_dataset, Dataset\n",
    "import random\n",
    "import json\n",
    "\n",
    "import numpy as np\n",
    "from transformers import set_seed\n",
    "import torch\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "from ranking_model import LogisticRegressionRanker, LinearRegressionRanker, MPNetRanker, FullRandomRanker, NORanker, SemanticRanker\n",
    "from ranking_data_utils import prepare_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "torch.cuda.manual_seed_all(42)\n",
    "set_seed(42)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/datasets/load.py:1486: FutureWarning: The repository for AmazonScience/mintaka contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/AmazonScience/mintaka\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>index</th>\n",
       "      <th>answerEntity</th>\n",
       "      <th>groundTruthAnswerEntity</th>\n",
       "      <th>questionEntity</th>\n",
       "      <th>complexityType</th>\n",
       "      <th>graph</th>\n",
       "      <th>correct</th>\n",
       "      <th>t5_sequence</th>\n",
       "      <th>gap_sequence</th>\n",
       "      <th>...</th>\n",
       "      <th>bridge</th>\n",
       "      <th>katz_centrality</th>\n",
       "      <th>page_rank</th>\n",
       "      <th>avg_ssp_length</th>\n",
       "      <th>determ_sequence</th>\n",
       "      <th>determ_sequence_embedding</th>\n",
       "      <th>gap_sequence_embedding</th>\n",
       "      <th>t5_sequence_embedding</th>\n",
       "      <th>question_answer_embedding</th>\n",
       "      <th>model_answers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>4000.000000</td>\n",
       "      <td>4000.000000</td>\n",
       "      <td>4000.000000</td>\n",
       "      <td>4000.000000</td>\n",
       "      <td>4000.000000</td>\n",
       "      <td>4000.000000</td>\n",
       "      <td>4000.000000</td>\n",
       "      <td>4000.000000</td>\n",
       "      <td>4000.000000</td>\n",
       "      <td>4000.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>4000.000000</td>\n",
       "      <td>4000.000000</td>\n",
       "      <td>4000.000000</td>\n",
       "      <td>4000.000000</td>\n",
       "      <td>4000.000000</td>\n",
       "      <td>4000.000000</td>\n",
       "      <td>4000.000000</td>\n",
       "      <td>4000.000000</td>\n",
       "      <td>4000.000000</td>\n",
       "      <td>4000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2.845500</td>\n",
       "      <td>2.437250</td>\n",
       "      <td>2.437250</td>\n",
       "      <td>2.437250</td>\n",
       "      <td>2.437250</td>\n",
       "      <td>2.437250</td>\n",
       "      <td>2.437250</td>\n",
       "      <td>2.437250</td>\n",
       "      <td>2.437250</td>\n",
       "      <td>2.437250</td>\n",
       "      <td>...</td>\n",
       "      <td>2.437250</td>\n",
       "      <td>2.437250</td>\n",
       "      <td>2.437250</td>\n",
       "      <td>2.437250</td>\n",
       "      <td>2.437250</td>\n",
       "      <td>2.437250</td>\n",
       "      <td>2.437250</td>\n",
       "      <td>2.437250</td>\n",
       "      <td>2.437250</td>\n",
       "      <td>2.845500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.013863</td>\n",
       "      <td>2.409256</td>\n",
       "      <td>2.409256</td>\n",
       "      <td>2.409256</td>\n",
       "      <td>2.409256</td>\n",
       "      <td>2.409256</td>\n",
       "      <td>2.409256</td>\n",
       "      <td>2.409256</td>\n",
       "      <td>2.409256</td>\n",
       "      <td>2.409256</td>\n",
       "      <td>...</td>\n",
       "      <td>2.409256</td>\n",
       "      <td>2.409256</td>\n",
       "      <td>2.409256</td>\n",
       "      <td>2.409256</td>\n",
       "      <td>2.409256</td>\n",
       "      <td>2.409256</td>\n",
       "      <td>2.409256</td>\n",
       "      <td>2.409256</td>\n",
       "      <td>2.409256</td>\n",
       "      <td>2.013863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>17.000000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>17.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            target        index  answerEntity  groundTruthAnswerEntity  \\\n",
       "count  4000.000000  4000.000000   4000.000000              4000.000000   \n",
       "mean      2.845500     2.437250      2.437250                 2.437250   \n",
       "std       2.013863     2.409256      2.409256                 2.409256   \n",
       "min       1.000000     0.000000      0.000000                 0.000000   \n",
       "25%       1.000000     0.000000      0.000000                 0.000000   \n",
       "50%       2.000000     2.000000      2.000000                 2.000000   \n",
       "75%       4.000000     4.000000      4.000000                 4.000000   \n",
       "max      17.000000    17.000000     17.000000                17.000000   \n",
       "\n",
       "       questionEntity  complexityType        graph      correct  t5_sequence  \\\n",
       "count     4000.000000     4000.000000  4000.000000  4000.000000  4000.000000   \n",
       "mean         2.437250        2.437250     2.437250     2.437250     2.437250   \n",
       "std          2.409256        2.409256     2.409256     2.409256     2.409256   \n",
       "min          0.000000        0.000000     0.000000     0.000000     0.000000   \n",
       "25%          0.000000        0.000000     0.000000     0.000000     0.000000   \n",
       "50%          2.000000        2.000000     2.000000     2.000000     2.000000   \n",
       "75%          4.000000        4.000000     4.000000     4.000000     4.000000   \n",
       "max         17.000000       17.000000    17.000000    17.000000    17.000000   \n",
       "\n",
       "       gap_sequence  ...       bridge  katz_centrality    page_rank  \\\n",
       "count   4000.000000  ...  4000.000000      4000.000000  4000.000000   \n",
       "mean       2.437250  ...     2.437250         2.437250     2.437250   \n",
       "std        2.409256  ...     2.409256         2.409256     2.409256   \n",
       "min        0.000000  ...     0.000000         0.000000     0.000000   \n",
       "25%        0.000000  ...     0.000000         0.000000     0.000000   \n",
       "50%        2.000000  ...     2.000000         2.000000     2.000000   \n",
       "75%        4.000000  ...     4.000000         4.000000     4.000000   \n",
       "max       17.000000  ...    17.000000        17.000000    17.000000   \n",
       "\n",
       "       avg_ssp_length  determ_sequence  determ_sequence_embedding  \\\n",
       "count     4000.000000      4000.000000                4000.000000   \n",
       "mean         2.437250         2.437250                   2.437250   \n",
       "std          2.409256         2.409256                   2.409256   \n",
       "min          0.000000         0.000000                   0.000000   \n",
       "25%          0.000000         0.000000                   0.000000   \n",
       "50%          2.000000         2.000000                   2.000000   \n",
       "75%          4.000000         4.000000                   4.000000   \n",
       "max         17.000000        17.000000                  17.000000   \n",
       "\n",
       "       gap_sequence_embedding  t5_sequence_embedding  \\\n",
       "count             4000.000000            4000.000000   \n",
       "mean                 2.437250               2.437250   \n",
       "std                  2.409256               2.409256   \n",
       "min                  0.000000               0.000000   \n",
       "25%                  0.000000               0.000000   \n",
       "50%                  2.000000               2.000000   \n",
       "75%                  4.000000               4.000000   \n",
       "max                 17.000000              17.000000   \n",
       "\n",
       "       question_answer_embedding  model_answers  \n",
       "count                4000.000000    4000.000000  \n",
       "mean                    2.437250       2.845500  \n",
       "std                     2.409256       2.013863  \n",
       "min                     0.000000       1.000000  \n",
       "25%                     0.000000       1.000000  \n",
       "50%                     2.000000       2.000000  \n",
       "75%                     4.000000       4.000000  \n",
       "max                    17.000000      17.000000  \n",
       "\n",
       "[8 rows x 31 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# os.environ['HF_DATASETS_CACHE'] = '/workspace/storage/misc/huggingface'\n",
    "\n",
    "mintaka_dataset_path = \"AmazonScience/mintaka\"\n",
    "kgqa_dataset_path = f\"s-nlp/KGQASubgraphsRanking\"\n",
    "\n",
    "candidate_source = 'mixtral'\n",
    "\n",
    "\n",
    "features_ds = load_dataset(kgqa_dataset_path, f\"{candidate_source}_subgraphs\")\n",
    "outputs_ds = load_dataset(kgqa_dataset_path, f\"{candidate_source}_outputs\")\n",
    "mintaka_ds = load_dataset(mintaka_dataset_path)\n",
    "\n",
    "\n",
    "train_df = prepare_data(mintaka_ds[\"train\"], outputs_ds[\"train\"], features_ds[\"train\"])\n",
    "valid_df = prepare_data(\n",
    "    mintaka_ds[\"validation\"], outputs_ds[\"validation\"], features_ds[\"validation\"]\n",
    ")\n",
    "test_df = prepare_data(mintaka_ds[\"test\"], outputs_ds[\"test\"], features_ds[\"test\"])\n",
    "test_df.groupby([\"id\", \"question\"]).count().describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_map = {\n",
    "    \"text\": [\"question_answer_embedding\"],\n",
    "    \"graph\": [\n",
    "        \"num_nodes\",\n",
    "        \"num_edges\",\n",
    "        \"density\",\n",
    "        \"cycle\",\n",
    "        \"bridge\",\n",
    "        \"katz_centrality\",\n",
    "        \"page_rank\",\n",
    "        \"avg_ssp_length\",\n",
    "    ],\n",
    "    \"g2t_determ\": [\"determ_sequence_embedding\"],\n",
    "    \"g2t_t5\": [\"t5_sequence_embedding\"],\n",
    "    \"g2t_gap\": [\"gap_sequence_embedding\"],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_path = Path(\n",
    "    f\"/workspace/storage/misc/subgraphs_reranking_runs/reranking_model_results/{candidate_source}/\"\n",
    ")\n",
    "results_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "\n",
    "full_random_ranker = FullRandomRanker()\n",
    "with open(\n",
    "    results_path / f\"full_random_reranking_results.jsonl\", \"w\"\n",
    ") as f:\n",
    "    for result in full_random_ranker.rerank(test_df):\n",
    "        f.write(json.dumps(result) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_ranker = NORanker()\n",
    "with open(results_path / f\"NO_reranking_results.jsonl\", \"w\") as f:\n",
    "    for result in no_ranker.rerank(test_df):\n",
    "        f.write(json.dumps(result) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76482c99e2154093a88d71291a199e77",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "semantic_ranker = SemanticRanker()\n",
    "with open(results_path / f'semantic_reranking_results.jsonl', 'w') as f:\n",
    "    for result in semantic_ranker.rerank(test_df):\n",
    "        f.write(json.dumps(result)+'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "logreg_ranker = LogisticRegressionRanker(features_map[\"text\"])\n",
    "logreg_ranker.fit(train_df, n_jobs=8)\n",
    "with open(\n",
    "    results_path / f\"logreg_text_reranking_results.jsonl\", \"w\"\n",
    ") as f:\n",
    "    for result in logreg_ranker.rerank(test_df):\n",
    "        f.write(json.dumps(result) + \"\\n\")\n",
    "\n",
    "\n",
    "logreg_ranker = LogisticRegressionRanker(features_map[\"graph\"])\n",
    "logreg_ranker.fit(train_df, n_jobs=8)\n",
    "with open(\n",
    "    results_path / f\"logreg_graph_reranking_results.jsonl\", \"w\"\n",
    ") as f:\n",
    "    for result in logreg_ranker.rerank(test_df):\n",
    "        f.write(json.dumps(result) + \"\\n\")\n",
    "\n",
    "\n",
    "logreg_ranker = LogisticRegressionRanker(features_map[\"text\"] + features_map[\"graph\"])\n",
    "logreg_ranker.fit(train_df, n_jobs=8)\n",
    "with open(\n",
    "    results_path / f\"logreg_text_graph_reranking_results.jsonl\", \"w\"\n",
    ") as f:\n",
    "    for result in logreg_ranker.rerank(test_df):\n",
    "        f.write(json.dumps(result) + \"\\n\")\n",
    "\n",
    "\n",
    "logreg_ranker = LogisticRegressionRanker(features_map[\"g2t_determ\"])\n",
    "logreg_ranker.fit(train_df, n_jobs=8)\n",
    "with open(\n",
    "    results_path / f\"logreg_g2t_determ_reranking_results.jsonl\", \"w\"\n",
    ") as f:\n",
    "    for result in logreg_ranker.rerank(test_df):\n",
    "        f.write(json.dumps(result) + \"\\n\")\n",
    "\n",
    "\n",
    "logreg_ranker = LogisticRegressionRanker(features_map[\"g2t_t5\"])\n",
    "logreg_ranker.fit(train_df, n_jobs=8)\n",
    "with open(\n",
    "    results_path / f\"logreg_g2t_t5_reranking_results.jsonl\", \"w\"\n",
    ") as f:\n",
    "    for result in logreg_ranker.rerank(test_df):\n",
    "        f.write(json.dumps(result) + \"\\n\")\n",
    "\n",
    "\n",
    "logreg_ranker = LogisticRegressionRanker(features_map[\"g2t_gap\"])\n",
    "logreg_ranker.fit(train_df, n_jobs=8)\n",
    "with open(\n",
    "    results_path / f\"logreg_g2t_gap_reranking_results.jsonl\", \"w\"\n",
    ") as f:\n",
    "    for result in logreg_ranker.rerank(test_df):\n",
    "        f.write(json.dumps(result) + \"\\n\")\n",
    "\n",
    "\n",
    "logreg_ranker = LogisticRegressionRanker(\n",
    "    features_map[\"text\"] + features_map[\"g2t_determ\"] + features_map[\"graph\"]\n",
    ")\n",
    "logreg_ranker.fit(train_df, n_jobs=8)\n",
    "with open(\n",
    "    results_path\n",
    "    / f\"logreg_text_g2t_determ_graph_reranking_results.jsonl\",\n",
    "    \"w\",\n",
    ") as f:\n",
    "    for result in logreg_ranker.rerank(test_df):\n",
    "        f.write(json.dumps(result) + \"\\n\")\n",
    "\n",
    "\n",
    "logreg_ranker = LogisticRegressionRanker(\n",
    "    features_map[\"text\"] + features_map[\"g2t_t5\"] + features_map[\"graph\"]\n",
    ")\n",
    "logreg_ranker.fit(train_df, n_jobs=8)\n",
    "with open(\n",
    "    results_path\n",
    "    / f\"logreg_text_g2t_t5_graph_reranking_results.jsonl\",\n",
    "    \"w\",\n",
    ") as f:\n",
    "    for result in logreg_ranker.rerank(test_df):\n",
    "        f.write(json.dumps(result) + \"\\n\")\n",
    "\n",
    "logreg_ranker = LogisticRegressionRanker(\n",
    "    features_map[\"text\"] + features_map[\"g2t_gap\"] + features_map[\"graph\"]\n",
    ")\n",
    "logreg_ranker.fit(train_df, n_jobs=8)\n",
    "with open(\n",
    "    results_path\n",
    "    / f\"logreg_text_g2t_gap_graph_reranking_results.jsonl\",\n",
    "    \"w\",\n",
    ") as f:\n",
    "    for result in logreg_ranker.rerank(test_df):\n",
    "        f.write(json.dumps(result) + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg_ranker = LinearRegressionRanker(features_map[\"text\"])\n",
    "logreg_ranker.fit(train_df, n_jobs=8)\n",
    "with open(\n",
    "    results_path / f\"linreg_text_reranking_results.jsonl\", \"w\"\n",
    ") as f:\n",
    "    for result in logreg_ranker.rerank(test_df):\n",
    "        f.write(json.dumps(result) + \"\\n\")\n",
    "\n",
    "\n",
    "logreg_ranker = LinearRegressionRanker(features_map[\"graph\"])\n",
    "logreg_ranker.fit(train_df, n_jobs=8)\n",
    "with open(\n",
    "    results_path / f\"linreg_graph_reranking_results.jsonl\", \"w\"\n",
    ") as f:\n",
    "    for result in logreg_ranker.rerank(test_df):\n",
    "        f.write(json.dumps(result) + \"\\n\")\n",
    "\n",
    "\n",
    "logreg_ranker = LinearRegressionRanker(features_map[\"text\"] + features_map[\"graph\"])\n",
    "logreg_ranker.fit(train_df, n_jobs=8)\n",
    "with open(\n",
    "    results_path / f\"linreg_text_graph_reranking_results.jsonl\", \"w\"\n",
    ") as f:\n",
    "    for result in logreg_ranker.rerank(test_df):\n",
    "        f.write(json.dumps(result) + \"\\n\")\n",
    "\n",
    "\n",
    "logreg_ranker = LinearRegressionRanker(features_map[\"g2t_determ\"])\n",
    "logreg_ranker.fit(train_df, n_jobs=8)\n",
    "with open(\n",
    "    results_path / f\"linreg_g2t_determ_reranking_results.jsonl\", \"w\"\n",
    ") as f:\n",
    "    for result in logreg_ranker.rerank(test_df):\n",
    "        f.write(json.dumps(result) + \"\\n\")\n",
    "\n",
    "\n",
    "logreg_ranker = LinearRegressionRanker(features_map[\"g2t_t5\"])\n",
    "logreg_ranker.fit(train_df, n_jobs=8)\n",
    "with open(\n",
    "    results_path / f\"linreg_g2t_t5_reranking_results.jsonl\", \"w\"\n",
    ") as f:\n",
    "    for result in logreg_ranker.rerank(test_df):\n",
    "        f.write(json.dumps(result) + \"\\n\")\n",
    "\n",
    "\n",
    "logreg_ranker = LinearRegressionRanker(features_map[\"g2t_gap\"])\n",
    "logreg_ranker.fit(train_df, n_jobs=8)\n",
    "with open(\n",
    "    results_path / f\"linreg_g2t_gap_reranking_results.jsonl\", \"w\"\n",
    ") as f:\n",
    "    for result in logreg_ranker.rerank(test_df):\n",
    "        f.write(json.dumps(result) + \"\\n\")\n",
    "\n",
    "\n",
    "logreg_ranker = LinearRegressionRanker(\n",
    "    features_map[\"text\"] + features_map[\"g2t_determ\"] + features_map[\"graph\"]\n",
    ")\n",
    "logreg_ranker.fit(train_df, n_jobs=8)\n",
    "with open(\n",
    "    results_path / f\"linreg_text_g2t_determ_graph_reranking_results.jsonl\",\n",
    "    \"w\",\n",
    ") as f:\n",
    "    for result in logreg_ranker.rerank(test_df):\n",
    "        f.write(json.dumps(result) + \"\\n\")\n",
    "\n",
    "\n",
    "logreg_ranker = LinearRegressionRanker(\n",
    "    features_map[\"text\"] + features_map[\"g2t_t5\"] + features_map[\"graph\"]\n",
    ")\n",
    "logreg_ranker.fit(train_df, n_jobs=8)\n",
    "with open(\n",
    "    results_path / f\"linreg_text_g2t_t5_graph_reranking_results.jsonl\",\n",
    "    \"w\",\n",
    ") as f:\n",
    "    for result in logreg_ranker.rerank(test_df):\n",
    "        f.write(json.dumps(result) + \"\\n\")\n",
    "\n",
    "\n",
    "logreg_ranker = LinearRegressionRanker(\n",
    "    features_map[\"text\"] + features_map[\"g2t_gap\"] + features_map[\"graph\"]\n",
    ")\n",
    "logreg_ranker.fit(train_df, n_jobs=8)\n",
    "with open(\n",
    "    results_path / f\"linreg_text_g2t_gap_graph_reranking_results.jsonl\",\n",
    "    \"w\",\n",
    ") as f:\n",
    "    for result in logreg_ranker.rerank(test_df):\n",
    "        f.write(json.dumps(result) + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MPNet "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from transformers import AutoTokenizer\n",
    "\n",
    "# tokenizer = AutoTokenizer.from_pretrained(\"sentence-transformers/all-mpnet-base-v2\")\n",
    "\n",
    "\n",
    "# def apply_sep(seq):\n",
    "#     if isinstance(seq, str):\n",
    "#         q_a_splits = seq.split(\";\")\n",
    "#         seq = f\"{q_a_splits[0]}{tokenizer.sep_token}{q_a_splits[-1]}\"\n",
    "#     return seq\n",
    "\n",
    "\n",
    "# test_df[\"question_answer\"] = test_df[\"question_answer\"].apply(apply_sep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Try load model...\n",
      "Model Loaded.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "579f2caacc9d4f04894e484d9cd40161",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Try load model...\n",
      "Model Loaded.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d93143f2fad34243a88cbc9bd3cf2f86",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# device = torch.device(\"cuda\")\n",
    "\n",
    "# model_path = \"/workspace/storage/misc/subgraphs_reranking_results/question_answer/T5-xl-ssm/question_answer_nocherries_fixed_train/outputs/checkpoint-best\"\n",
    "# mpnet_ranker = MPNetRanker(\"question_answer\", model_path, device)\n",
    "# with open(\n",
    "#     results_path / f\"mpnet_text_only_determ_reranking_seq2seq_{ds_type}_results.jsonl\",\n",
    "#     \"w+\",\n",
    "# ) as f:\n",
    "#     for result in mpnet_ranker.rerank(test_df):\n",
    "#         f.write(json.dumps(result) + \"\\n\")\n",
    "\n",
    "# model_path = f\"/mnt/storage/QA_System_Project/subgraphs_reranking_runs/determ/T5-{ds_type}-ssm/no_cherries_hl_false_determ/outputs/checkpoint-best\"\n",
    "# mpnet_ranker = MPNetRanker(\"no_highlighted_determ_sequence\", model_path, device)\n",
    "# with open(\n",
    "#     results_path / f\"mpnet_no_hl_g2t_determ_reranking_seq2seq_{ds_type}_results.jsonl\",\n",
    "#     \"w\",\n",
    "# ) as f:\n",
    "#     for result in mpnet_ranker.rerank(test_df):\n",
    "#         f.write(json.dumps(result) + \"\\n\")\n",
    "\n",
    "# model_path = f\"/mnt/storage/QA_System_Project/subgraphs_reranking_runs/determ/T5-{ds_type}-ssm/no_cherries_hl_true_determ/outputs/checkpoint-best/\"\n",
    "# mpnet_ranker = MPNetRanker(\"highlighted_determ_sequence\", model_path, device)\n",
    "# with open(\n",
    "#     results_path / f\"mpnet_hl_g2t_determ_reranking_seq2seq_{ds_type}_results.jsonl\", \"w\"\n",
    "# ) as f:\n",
    "#     for result in mpnet_ranker.rerank(test_df):\n",
    "#         f.write(json.dumps(result) + \"\\n\")\n",
    "\n",
    "\n",
    "# model_path = f\"/mnt/storage/QA_System_Project/subgraphs_reranking_runs/g2t/T5-{ds_type}-ssm/no_cherries_fixed_train_g2t_hl_true_large/outputs/checkpoint-best\"\n",
    "# mpnet_ranker = MPNetRanker(\"highlighted_t5_sequence\", model_path, device)\n",
    "# with open(\n",
    "#     results_path / f\"mpnet_hl_g2t_t5_reranking_seq2seq_{ds_type}_results.jsonl\", \"w\"\n",
    "# ) as f:\n",
    "#     for result in mpnet_ranker.rerank(test_df):\n",
    "#         f.write(json.dumps(result) + \"\\n\")\n",
    "\n",
    "# model_path = f\"/mnt/storage/QA_System_Project/subgraphs_reranking_runs/g2t/T5-{ds_type}-ssm/no_cherries_fixed_train_g2t_hl_false_large/outputs/checkpoint-best\"\n",
    "# mpnet_ranker = MPNetRanker(\"no_highlighted_t5_sequence\", model_path, device)\n",
    "# with open(\n",
    "#     results_path / f\"mpnet_no_hl_g2t_t5_reranking_seq2seq_{ds_type}_results.jsonl\", \"w\"\n",
    "# ) as f:\n",
    "#     for result in mpnet_ranker.rerank(test_df):\n",
    "#         f.write(json.dumps(result) + \"\\n\")\n",
    "\n",
    "\n",
    "# model_path = f\"/mnt/storage/QA_System_Project/subgraphs_reranking_runs/gap/T5-{ds_type}-ssm/no_cherries_fixed_train_hl_true_gap_large/outputs/checkpoint-best\"\n",
    "# mpnet_ranker = MPNetRanker(\"highlighted_gap_sequence\", model_path, device)\n",
    "# with open(\n",
    "#     results_path / f\"mpnet_hl_g2t_gap_reranking_seq2seq_{ds_type}_results.jsonl\", \"w\"\n",
    "# ) as f:\n",
    "#     for result in mpnet_ranker.rerank(test_df):\n",
    "#         f.write(json.dumps(result) + \"\\n\")\n",
    "\n",
    "# model_path = f\"/mnt/storage/QA_System_Project/subgraphs_reranking_runs/gap/T5-{ds_type}-ssm/no_cherries_fixed_train_hl_false_gap_large/outputs/checkpoint-best\"\n",
    "# mpnet_ranker = MPNetRanker(\"no_highlighted_gap_sequence\", model_path, device)\n",
    "# with open(\n",
    "#     results_path / f\"mpnet_no_hl_g2t_gap_reranking_seq2seq_{ds_type}_results.jsonl\", \"w\"\n",
    "# ) as f:\n",
    "#     for result in mpnet_ranker.rerank(test_df):\n",
    "#         f.write(json.dumps(result) + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trying to load the model...\n",
      "Model Loaded.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "874d43e75683475ab2bca45084a68329",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# from catboost import CatBoostRegressor\n",
    "\n",
    "# model_weights = \"/workspace/storage/misc/features_reranking/catboost/unified_reranking/T5-large-ssm/catboost_text_large_ASK/best_model\"\n",
    "# catboost_ranker = CatboostRanker(model_weights, features_map[\"text\"])\n",
    "\n",
    "# with open(\n",
    "#     results_path / f\"catboost_text_reranking_seq2seq_{ds_type}_results.jsonl\", \"w\"\n",
    "# ) as f:\n",
    "#     for result in catboost_ranker.rerank(test_df):\n",
    "#         f.write(json.dumps(result) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
