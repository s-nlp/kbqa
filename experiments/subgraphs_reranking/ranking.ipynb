{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-22 07:35:56.045077: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-04-22 07:35:56.244147: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-04-22 07:35:56.935544: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
      "2024-04-22 07:35:56.935621: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
      "2024-04-22 07:35:56.935629: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from datasets import load_dataset, Dataset\n",
    "import random\n",
    "import json\n",
    "\n",
    "import numpy as np\n",
    "from transformers import set_seed\n",
    "import torch\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "from ranking_model import LogisticRegressionRanker, LinearRegressionRanker, MPNetRanker, FullRandomRanker, NORanker\n",
    "from ranking_data_utils import prepare_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "torch.cuda.manual_seed_all(42)\n",
    "set_seed(42)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/datasets/load.py:1486: FutureWarning: The repository for AmazonScience/mintaka contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/AmazonScience/mintaka\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>target_out_of_vocab</th>\n",
       "      <th>answerEntity</th>\n",
       "      <th>questionEntity</th>\n",
       "      <th>groundTruthAnswerEntity</th>\n",
       "      <th>complexityType</th>\n",
       "      <th>graph</th>\n",
       "      <th>correct</th>\n",
       "      <th>t5_sequence</th>\n",
       "      <th>gap_sequence</th>\n",
       "      <th>...</th>\n",
       "      <th>gap_sequence_embedding</th>\n",
       "      <th>t5_sequence_embedding</th>\n",
       "      <th>question_answer_embedding</th>\n",
       "      <th>highlighted_determ_sequence</th>\n",
       "      <th>no_highlighted_determ_sequence</th>\n",
       "      <th>highlighted_t5_sequence</th>\n",
       "      <th>no_highlighted_t5_sequence</th>\n",
       "      <th>highlighted_gap_sequence</th>\n",
       "      <th>no_highlighted_gap_sequence</th>\n",
       "      <th>model_answers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>4000.000000</td>\n",
       "      <td>4000.000000</td>\n",
       "      <td>4000.000000</td>\n",
       "      <td>4000.000000</td>\n",
       "      <td>4000.000000</td>\n",
       "      <td>4000.000000</td>\n",
       "      <td>4000.000000</td>\n",
       "      <td>4000.000000</td>\n",
       "      <td>4000.000000</td>\n",
       "      <td>4000.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>4000.000000</td>\n",
       "      <td>4000.000000</td>\n",
       "      <td>4000.000000</td>\n",
       "      <td>4000.000000</td>\n",
       "      <td>4000.000000</td>\n",
       "      <td>4000.000000</td>\n",
       "      <td>4000.000000</td>\n",
       "      <td>4000.000000</td>\n",
       "      <td>4000.000000</td>\n",
       "      <td>4000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>4.534500</td>\n",
       "      <td>4.534500</td>\n",
       "      <td>4.141750</td>\n",
       "      <td>4.141750</td>\n",
       "      <td>4.141750</td>\n",
       "      <td>4.141750</td>\n",
       "      <td>4.141750</td>\n",
       "      <td>4.141750</td>\n",
       "      <td>4.141750</td>\n",
       "      <td>4.141750</td>\n",
       "      <td>...</td>\n",
       "      <td>4.141750</td>\n",
       "      <td>4.141750</td>\n",
       "      <td>4.141750</td>\n",
       "      <td>4.141750</td>\n",
       "      <td>4.141750</td>\n",
       "      <td>4.141750</td>\n",
       "      <td>4.141750</td>\n",
       "      <td>4.141750</td>\n",
       "      <td>4.141750</td>\n",
       "      <td>4.534500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3.300005</td>\n",
       "      <td>3.300005</td>\n",
       "      <td>3.729026</td>\n",
       "      <td>3.729026</td>\n",
       "      <td>3.729026</td>\n",
       "      <td>3.729026</td>\n",
       "      <td>3.729026</td>\n",
       "      <td>3.729026</td>\n",
       "      <td>3.729026</td>\n",
       "      <td>3.729026</td>\n",
       "      <td>...</td>\n",
       "      <td>3.729026</td>\n",
       "      <td>3.729026</td>\n",
       "      <td>3.729026</td>\n",
       "      <td>3.729026</td>\n",
       "      <td>3.729026</td>\n",
       "      <td>3.729026</td>\n",
       "      <td>3.729026</td>\n",
       "      <td>3.729026</td>\n",
       "      <td>3.729026</td>\n",
       "      <td>3.300005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>7.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>7.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>19.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>19.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            target  target_out_of_vocab  answerEntity  questionEntity  \\\n",
       "count  4000.000000          4000.000000   4000.000000     4000.000000   \n",
       "mean      4.534500             4.534500      4.141750        4.141750   \n",
       "std       3.300005             3.300005      3.729026        3.729026   \n",
       "min       1.000000             1.000000      0.000000        0.000000   \n",
       "25%       1.000000             1.000000      0.000000        0.000000   \n",
       "50%       5.000000             5.000000      5.000000        5.000000   \n",
       "75%       7.000000             7.000000      7.000000        7.000000   \n",
       "max      19.000000            19.000000     19.000000       19.000000   \n",
       "\n",
       "       groundTruthAnswerEntity  complexityType        graph      correct  \\\n",
       "count              4000.000000     4000.000000  4000.000000  4000.000000   \n",
       "mean                  4.141750        4.141750     4.141750     4.141750   \n",
       "std                   3.729026        3.729026     3.729026     3.729026   \n",
       "min                   0.000000        0.000000     0.000000     0.000000   \n",
       "25%                   0.000000        0.000000     0.000000     0.000000   \n",
       "50%                   5.000000        5.000000     5.000000     5.000000   \n",
       "75%                   7.000000        7.000000     7.000000     7.000000   \n",
       "max                  19.000000       19.000000    19.000000    19.000000   \n",
       "\n",
       "       t5_sequence  gap_sequence  ...  gap_sequence_embedding  \\\n",
       "count  4000.000000   4000.000000  ...             4000.000000   \n",
       "mean      4.141750      4.141750  ...                4.141750   \n",
       "std       3.729026      3.729026  ...                3.729026   \n",
       "min       0.000000      0.000000  ...                0.000000   \n",
       "25%       0.000000      0.000000  ...                0.000000   \n",
       "50%       5.000000      5.000000  ...                5.000000   \n",
       "75%       7.000000      7.000000  ...                7.000000   \n",
       "max      19.000000     19.000000  ...               19.000000   \n",
       "\n",
       "       t5_sequence_embedding  question_answer_embedding  \\\n",
       "count            4000.000000                4000.000000   \n",
       "mean                4.141750                   4.141750   \n",
       "std                 3.729026                   3.729026   \n",
       "min                 0.000000                   0.000000   \n",
       "25%                 0.000000                   0.000000   \n",
       "50%                 5.000000                   5.000000   \n",
       "75%                 7.000000                   7.000000   \n",
       "max                19.000000                  19.000000   \n",
       "\n",
       "       highlighted_determ_sequence  no_highlighted_determ_sequence  \\\n",
       "count                  4000.000000                     4000.000000   \n",
       "mean                      4.141750                        4.141750   \n",
       "std                       3.729026                        3.729026   \n",
       "min                       0.000000                        0.000000   \n",
       "25%                       0.000000                        0.000000   \n",
       "50%                       5.000000                        5.000000   \n",
       "75%                       7.000000                        7.000000   \n",
       "max                      19.000000                       19.000000   \n",
       "\n",
       "       highlighted_t5_sequence  no_highlighted_t5_sequence  \\\n",
       "count              4000.000000                 4000.000000   \n",
       "mean                  4.141750                    4.141750   \n",
       "std                   3.729026                    3.729026   \n",
       "min                   0.000000                    0.000000   \n",
       "25%                   0.000000                    0.000000   \n",
       "50%                   5.000000                    5.000000   \n",
       "75%                   7.000000                    7.000000   \n",
       "max                  19.000000                   19.000000   \n",
       "\n",
       "       highlighted_gap_sequence  no_highlighted_gap_sequence  model_answers  \n",
       "count               4000.000000                  4000.000000    4000.000000  \n",
       "mean                   4.141750                     4.141750       4.534500  \n",
       "std                    3.729026                     3.729026       3.300005  \n",
       "min                    0.000000                     0.000000       1.000000  \n",
       "25%                    0.000000                     0.000000       1.000000  \n",
       "50%                    5.000000                     5.000000       5.000000  \n",
       "75%                    7.000000                     7.000000       7.000000  \n",
       "max                   19.000000                    19.000000      19.000000  \n",
       "\n",
       "[8 rows x 31 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# os.environ['HF_DATASETS_CACHE'] = '/workspace/storage/misc/huggingface'\n",
    "\n",
    "ds_type = 'large' # 'large' or 'xl'\n",
    "\n",
    "\n",
    "mintaka_dataset_path = \"AmazonScience/mintaka\"\n",
    "features_dataset_path = f\"hle2000/KGQA_T5-{ds_type}-ssm\"\n",
    "seq2seq_outputs_dataset_path = f\"s-nlp/Mintaka_T5_{ds_type}_ssm_outputs\"\n",
    "\n",
    "\n",
    "features_ds = load_dataset(features_dataset_path)\n",
    "outputs_ds = load_dataset(seq2seq_outputs_dataset_path)\n",
    "mintaka_ds = load_dataset(mintaka_dataset_path)\n",
    "\n",
    "\n",
    "train_df = prepare_data(mintaka_ds['train'], outputs_ds['train'], features_ds['train'])\n",
    "valid_df = prepare_data(mintaka_ds['validation'], outputs_ds['validation'], features_ds['validation'])\n",
    "test_df = prepare_data(mintaka_ds['test'], outputs_ds['test'], features_ds['test'])\n",
    "test_df.groupby(['id', 'question']).count().describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_map = {\n",
    "    'text': ['question_answer_embedding'],\n",
    "    'graph': ['num_nodes', 'num_edges', 'density', 'cycle', 'bridge', 'katz_centrality', 'page_rank', 'avg_ssp_length'],\n",
    "    'g2t_determ': ['determ_sequence_embedding'],\n",
    "    'g2t_t5': ['t5_sequence_embedding'],\n",
    "    'g2t_gap': ['gap_sequence_embedding'],\n",
    "}\n",
    "\n",
    "\n",
    "results_path = Path(f'/mnt/storage/QA_System_Project/subgraphs_reranking_runs/reranking_model_results/t5_{ds_type}_ssm/')\n",
    "results_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "\n",
    "full_random_ranker = FullRandomRanker()\n",
    "with open(results_path / f'full_random_reranking_seq2seq_{ds_type}_results.jsonl', 'w') as f:\n",
    "    for result in full_random_ranker.rerank(test_df):\n",
    "        f.write(json.dumps(result)+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_ranker = NORanker()\n",
    "with open(results_path / f'NO_reranking_seq2seq_{ds_type}_results.jsonl', 'w') as f:\n",
    "    for result in no_ranker.rerank(test_df):\n",
    "        f.write(json.dumps(result)+'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg_ranker = LogisticRegressionRanker(features_map['text'])\n",
    "logreg_ranker.fit(train_df, n_jobs=8)\n",
    "with open(results_path / f'logreg_text_reranking_seq2seq_{ds_type}_results.jsonl', 'w') as f:\n",
    "    for result in logreg_ranker.rerank(test_df):\n",
    "        f.write(json.dumps(result)+'\\n')\n",
    "\n",
    "\n",
    "logreg_ranker = LogisticRegressionRanker(features_map['graph'])\n",
    "logreg_ranker.fit(train_df, n_jobs=8)\n",
    "with open(results_path / f'logreg_graph_reranking_seq2seq_{ds_type}_results.jsonl', 'w') as f:\n",
    "    for result in logreg_ranker.rerank(test_df):\n",
    "        f.write(json.dumps(result)+'\\n')\n",
    "\n",
    "\n",
    "logreg_ranker = LogisticRegressionRanker(features_map['text'] + features_map['graph'])\n",
    "logreg_ranker.fit(train_df, n_jobs=8)\n",
    "with open(results_path / f'logreg_text_graph_reranking_seq2seq_{ds_type}_results.jsonl', 'w') as f:\n",
    "    for result in logreg_ranker.rerank(test_df):\n",
    "        f.write(json.dumps(result)+'\\n')\n",
    "\n",
    "\n",
    "logreg_ranker = LogisticRegressionRanker(features_map['g2t_determ'])\n",
    "logreg_ranker.fit(train_df, n_jobs=8)\n",
    "with open(results_path / f'logreg_g2t_determ_reranking_seq2seq_{ds_type}_results.jsonl', 'w') as f:\n",
    "    for result in logreg_ranker.rerank(test_df):\n",
    "        f.write(json.dumps(result)+'\\n')\n",
    "\n",
    "\n",
    "logreg_ranker = LogisticRegressionRanker(features_map['g2t_t5'])\n",
    "logreg_ranker.fit(train_df, n_jobs=8)\n",
    "with open(results_path / f'logreg_g2t_t5_reranking_seq2seq_{ds_type}_results.jsonl', 'w') as f:\n",
    "    for result in logreg_ranker.rerank(test_df):\n",
    "        f.write(json.dumps(result)+'\\n')\n",
    "\n",
    "\n",
    "logreg_ranker = LogisticRegressionRanker(features_map['g2t_gap'])\n",
    "logreg_ranker.fit(train_df, n_jobs=8)\n",
    "with open(results_path / f'logreg_g2t_gap_reranking_seq2seq_{ds_type}_results.jsonl', 'w') as f:\n",
    "    for result in logreg_ranker.rerank(test_df):\n",
    "        f.write(json.dumps(result)+'\\n')\n",
    "\n",
    "\n",
    "logreg_ranker = LogisticRegressionRanker(features_map['text'] + features_map['g2t_determ'] + features_map['graph'])\n",
    "logreg_ranker.fit(train_df, n_jobs=8)\n",
    "with open(results_path / f'logreg_text_g2t_determ_graph_reranking_seq2seq_{ds_type}_results.jsonl', 'w') as f:\n",
    "    for result in logreg_ranker.rerank(test_df):\n",
    "        f.write(json.dumps(result)+'\\n')\n",
    "\n",
    "\n",
    "logreg_ranker = LogisticRegressionRanker(features_map['text'] + features_map['g2t_t5'] + features_map['graph'])\n",
    "logreg_ranker.fit(train_df, n_jobs=8)\n",
    "with open(results_path / f'logreg_text_g2t_t5_graph_reranking_seq2seq_{ds_type}_results.jsonl', 'w') as f:\n",
    "    for result in logreg_ranker.rerank(test_df):\n",
    "        f.write(json.dumps(result)+'\\n')\n",
    "\n",
    "logreg_ranker = LogisticRegressionRanker(features_map['text'] + features_map['g2t_gap'] + features_map['graph'])\n",
    "logreg_ranker.fit(train_df, n_jobs=8)\n",
    "with open(results_path / f'logreg_text_g2t_gap_graph_reranking_seq2seq_{ds_type}_results.jsonl', 'w') as f:\n",
    "    for result in logreg_ranker.rerank(test_df):\n",
    "        f.write(json.dumps(result)+'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg_ranker = LinearRegressionRanker(features_map['text'])\n",
    "logreg_ranker.fit(train_df, n_jobs=8)\n",
    "with open(results_path / f'linreg_text_reranking_seq2seq_{ds_type}_results.jsonl', 'w') as f:\n",
    "    for result in logreg_ranker.rerank(test_df):\n",
    "        f.write(json.dumps(result)+'\\n')\n",
    "\n",
    "\n",
    "logreg_ranker = LinearRegressionRanker(features_map['graph'])\n",
    "logreg_ranker.fit(train_df, n_jobs=8)\n",
    "with open(results_path / f'linreg_graph_reranking_seq2seq_{ds_type}_results.jsonl', 'w') as f:\n",
    "    for result in logreg_ranker.rerank(test_df):\n",
    "        f.write(json.dumps(result)+'\\n')\n",
    "\n",
    "\n",
    "logreg_ranker = LinearRegressionRanker(features_map['text'] + features_map['graph'])\n",
    "logreg_ranker.fit(train_df, n_jobs=8)\n",
    "with open(results_path / f'linreg_text_graph_reranking_seq2seq_{ds_type}_results.jsonl', 'w') as f:\n",
    "    for result in logreg_ranker.rerank(test_df):\n",
    "        f.write(json.dumps(result)+'\\n')\n",
    "\n",
    "\n",
    "logreg_ranker = LinearRegressionRanker(features_map['g2t_determ'])\n",
    "logreg_ranker.fit(train_df, n_jobs=8)\n",
    "with open(results_path / f'linreg_g2t_determ_reranking_seq2seq_{ds_type}_results.jsonl', 'w') as f:\n",
    "    for result in logreg_ranker.rerank(test_df):\n",
    "        f.write(json.dumps(result)+'\\n')\n",
    "\n",
    "\n",
    "logreg_ranker = LinearRegressionRanker(features_map['g2t_t5'])\n",
    "logreg_ranker.fit(train_df, n_jobs=8)\n",
    "with open(results_path / f'linreg_g2t_t5_reranking_seq2seq_{ds_type}_results.jsonl', 'w') as f:\n",
    "    for result in logreg_ranker.rerank(test_df):\n",
    "        f.write(json.dumps(result)+'\\n')\n",
    "\n",
    "\n",
    "logreg_ranker = LinearRegressionRanker(features_map['g2t_gap'])\n",
    "logreg_ranker.fit(train_df, n_jobs=8)\n",
    "with open(results_path / f'linreg_g2t_gap_reranking_seq2seq_{ds_type}_results.jsonl', 'w') as f:\n",
    "    for result in logreg_ranker.rerank(test_df):\n",
    "        f.write(json.dumps(result)+'\\n')\n",
    "\n",
    "\n",
    "logreg_ranker = LinearRegressionRanker(features_map['text'] + features_map['g2t_determ'] + features_map['graph'])\n",
    "logreg_ranker.fit(train_df, n_jobs=8)\n",
    "with open(results_path / f'linreg_text_g2t_determ_graph_reranking_seq2seq_{ds_type}_results.jsonl', 'w') as f:\n",
    "    for result in logreg_ranker.rerank(test_df):\n",
    "        f.write(json.dumps(result)+'\\n')\n",
    "\n",
    "\n",
    "logreg_ranker = LinearRegressionRanker(features_map['text'] + features_map['g2t_t5'] + features_map['graph'])\n",
    "logreg_ranker.fit(train_df, n_jobs=8)\n",
    "with open(results_path / f'linreg_text_g2t_t5_graph_reranking_seq2seq_{ds_type}_results.jsonl', 'w') as f:\n",
    "    for result in logreg_ranker.rerank(test_df):\n",
    "        f.write(json.dumps(result)+'\\n')\n",
    "\n",
    "\n",
    "logreg_ranker = LinearRegressionRanker(features_map['text'] + features_map['g2t_gap'] + features_map['graph'])\n",
    "logreg_ranker.fit(train_df, n_jobs=8)\n",
    "with open(results_path / f'linreg_text_g2t_gap_graph_reranking_seq2seq_{ds_type}_results.jsonl', 'w') as f:\n",
    "    for result in logreg_ranker.rerank(test_df):\n",
    "        f.write(json.dumps(result)+'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MPNet "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Try load model...\n",
      "Model Loaded.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "579f2caacc9d4f04894e484d9cd40161",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Try load model...\n",
      "Model Loaded.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d93143f2fad34243a88cbc9bd3cf2f86",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "device = torch.device('cuda')\n",
    "\n",
    "model_path = f\"/mnt/storage/QA_System_Project/subgraphs_reranking_runs/determ/T5-{ds_type}-ssm/no_cherries_hl_false_determ/outputs/checkpoint-best\"\n",
    "mpnet_ranker = MPNetRanker('no_highlighted_determ_sequence', model_path, device)\n",
    "with open(results_path / f'mpnet_no_hl_g2t_determ_reranking_seq2seq_{ds_type}_results.jsonl', 'w') as f:\n",
    "    for result in mpnet_ranker.rerank(test_df):\n",
    "        f.write(json.dumps(result)+'\\n')\n",
    "\n",
    "model_path = f\"/mnt/storage/QA_System_Project/subgraphs_reranking_runs/determ/T5-{ds_type}-ssm/no_cherries_hl_true_determ/outputs/checkpoint-best/\"\n",
    "mpnet_ranker = MPNetRanker('highlighted_determ_sequence', model_path, device)\n",
    "with open(results_path / f'mpnet_hl_g2t_determ_reranking_seq2seq_{ds_type}_results.jsonl', 'w') as f:\n",
    "    for result in mpnet_ranker.rerank(test_df):\n",
    "        f.write(json.dumps(result)+'\\n')\n",
    "\n",
    "\n",
    "model_path = f\"/mnt/storage/QA_System_Project/subgraphs_reranking_runs/g2t/T5-{ds_type}-ssm/no_cherries_fixed_train_g2t_hl_true_large/outputs/checkpoint-best\"\n",
    "mpnet_ranker = MPNetRanker('highlighted_t5_sequence', model_path, device)\n",
    "with open(results_path / f'mpnet_hl_g2t_t5_reranking_seq2seq_{ds_type}_results.jsonl', 'w') as f:\n",
    "    for result in mpnet_ranker.rerank(test_df):\n",
    "        f.write(json.dumps(result)+'\\n')\n",
    "\n",
    "model_path = f\"/mnt/storage/QA_System_Project/subgraphs_reranking_runs/g2t/T5-{ds_type}-ssm/no_cherries_fixed_train_g2t_hl_false_large/outputs/checkpoint-best\"\n",
    "mpnet_ranker = MPNetRanker('no_highlighted_t5_sequence', model_path, device)\n",
    "with open(results_path / f'mpnet_no_hl_g2t_t5_reranking_seq2seq_{ds_type}_results.jsonl', 'w') as f:\n",
    "    for result in mpnet_ranker.rerank(test_df):\n",
    "        f.write(json.dumps(result)+'\\n')\n",
    "\n",
    "\n",
    "model_path = f\"/mnt/storage/QA_System_Project/subgraphs_reranking_runs/gap/T5-{ds_type}-ssm/no_cherries_fixed_train_hl_true_gap_large/outputs/checkpoint-best\"\n",
    "mpnet_ranker = MPNetRanker('highlighted_gap_sequence', model_path, device)\n",
    "with open(results_path / f'mpnet_hl_g2t_gap_reranking_seq2seq_{ds_type}_results.jsonl', 'w') as f:\n",
    "    for result in mpnet_ranker.rerank(test_df):\n",
    "        f.write(json.dumps(result)+'\\n')\n",
    "\n",
    "model_path = f\"/mnt/storage/QA_System_Project/subgraphs_reranking_runs/gap/T5-{ds_type}-ssm/no_cherries_fixed_train_hl_false_gap_large/outputs/checkpoint-best\"\n",
    "mpnet_ranker = MPNetRanker('no_highlighted_gap_sequence', model_path, device)\n",
    "with open(results_path / f'mpnet_no_hl_g2t_gap_reranking_seq2seq_{ds_type}_results.jsonl', 'w') as f:\n",
    "    for result in mpnet_ranker.rerank(test_df):\n",
    "        f.write(json.dumps(result)+'\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
