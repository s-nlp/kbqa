{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-26 13:48:18.021373: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-04-26 13:48:18.289791: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-04-26 13:48:19.089867: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
      "2024-04-26 13:48:19.089972: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
      "2024-04-26 13:48:19.089981: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from datasets import load_dataset, Dataset\n",
    "import random\n",
    "import json\n",
    "\n",
    "import numpy as np\n",
    "from transformers import set_seed\n",
    "import torch\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "from ranking_model import (\n",
    "    LogisticRegressionRanker,\n",
    "    LinearRegressionRanker,\n",
    "    MPNetRanker,\n",
    "    CatboostRanker,\n",
    "    FullRandomRanker,\n",
    "    NORanker,\n",
    ")\n",
    "from ranking_data_utils import prepare_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "torch.cuda.manual_seed_all(42)\n",
    "set_seed(42)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset parquet (/root/.cache/huggingface/datasets/hle2000___parquet/hle2000--KGQA_T5-large-ssm-a8dcb8937d89b482/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec119a33adba47c48b0b57e67197bb73",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset parquet (/root/.cache/huggingface/datasets/s-nlp___parquet/s-nlp--Mintaka_T5_large_ssm_outputs-dba37ee9cdaa84db/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a2d8ffdc0524f3882025d19ca9cbcf1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No config specified, defaulting to: mintaka/en\n",
      "Found cached dataset mintaka (/root/.cache/huggingface/datasets/AmazonScience___mintaka/en/1.0.0/bb35d95f07aed78fa590601245009c5f585efe909dbd4a8f2a4025ccf65bb11d)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a95477e402d4e518db99105b0d0e293",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>target_out_of_vocab</th>\n",
       "      <th>answerEntity</th>\n",
       "      <th>questionEntity</th>\n",
       "      <th>groundTruthAnswerEntity</th>\n",
       "      <th>complexityType</th>\n",
       "      <th>graph</th>\n",
       "      <th>correct</th>\n",
       "      <th>t5_sequence</th>\n",
       "      <th>gap_sequence</th>\n",
       "      <th>...</th>\n",
       "      <th>gap_sequence_embedding</th>\n",
       "      <th>t5_sequence_embedding</th>\n",
       "      <th>question_answer_embedding</th>\n",
       "      <th>highlighted_determ_sequence</th>\n",
       "      <th>no_highlighted_determ_sequence</th>\n",
       "      <th>highlighted_t5_sequence</th>\n",
       "      <th>no_highlighted_t5_sequence</th>\n",
       "      <th>highlighted_gap_sequence</th>\n",
       "      <th>no_highlighted_gap_sequence</th>\n",
       "      <th>model_answers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>4000.000000</td>\n",
       "      <td>4000.000000</td>\n",
       "      <td>4000.000000</td>\n",
       "      <td>4000.000000</td>\n",
       "      <td>4000.000000</td>\n",
       "      <td>4000.000000</td>\n",
       "      <td>4000.000000</td>\n",
       "      <td>4000.000000</td>\n",
       "      <td>4000.000000</td>\n",
       "      <td>4000.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>4000.000000</td>\n",
       "      <td>4000.000000</td>\n",
       "      <td>4000.000000</td>\n",
       "      <td>4000.000000</td>\n",
       "      <td>4000.000000</td>\n",
       "      <td>4000.000000</td>\n",
       "      <td>4000.000000</td>\n",
       "      <td>4000.000000</td>\n",
       "      <td>4000.000000</td>\n",
       "      <td>4000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>4.534500</td>\n",
       "      <td>4.534500</td>\n",
       "      <td>4.141750</td>\n",
       "      <td>4.141750</td>\n",
       "      <td>4.141750</td>\n",
       "      <td>4.141750</td>\n",
       "      <td>4.141750</td>\n",
       "      <td>4.141750</td>\n",
       "      <td>4.141750</td>\n",
       "      <td>4.141750</td>\n",
       "      <td>...</td>\n",
       "      <td>4.141750</td>\n",
       "      <td>4.141750</td>\n",
       "      <td>4.141750</td>\n",
       "      <td>4.141750</td>\n",
       "      <td>4.141750</td>\n",
       "      <td>4.141750</td>\n",
       "      <td>4.141750</td>\n",
       "      <td>4.141750</td>\n",
       "      <td>4.141750</td>\n",
       "      <td>4.534500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3.300005</td>\n",
       "      <td>3.300005</td>\n",
       "      <td>3.729026</td>\n",
       "      <td>3.729026</td>\n",
       "      <td>3.729026</td>\n",
       "      <td>3.729026</td>\n",
       "      <td>3.729026</td>\n",
       "      <td>3.729026</td>\n",
       "      <td>3.729026</td>\n",
       "      <td>3.729026</td>\n",
       "      <td>...</td>\n",
       "      <td>3.729026</td>\n",
       "      <td>3.729026</td>\n",
       "      <td>3.729026</td>\n",
       "      <td>3.729026</td>\n",
       "      <td>3.729026</td>\n",
       "      <td>3.729026</td>\n",
       "      <td>3.729026</td>\n",
       "      <td>3.729026</td>\n",
       "      <td>3.729026</td>\n",
       "      <td>3.300005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>7.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>7.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>19.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>19.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            target  target_out_of_vocab  answerEntity  questionEntity  \\\n",
       "count  4000.000000          4000.000000   4000.000000     4000.000000   \n",
       "mean      4.534500             4.534500      4.141750        4.141750   \n",
       "std       3.300005             3.300005      3.729026        3.729026   \n",
       "min       1.000000             1.000000      0.000000        0.000000   \n",
       "25%       1.000000             1.000000      0.000000        0.000000   \n",
       "50%       5.000000             5.000000      5.000000        5.000000   \n",
       "75%       7.000000             7.000000      7.000000        7.000000   \n",
       "max      19.000000            19.000000     19.000000       19.000000   \n",
       "\n",
       "       groundTruthAnswerEntity  complexityType        graph      correct  \\\n",
       "count              4000.000000     4000.000000  4000.000000  4000.000000   \n",
       "mean                  4.141750        4.141750     4.141750     4.141750   \n",
       "std                   3.729026        3.729026     3.729026     3.729026   \n",
       "min                   0.000000        0.000000     0.000000     0.000000   \n",
       "25%                   0.000000        0.000000     0.000000     0.000000   \n",
       "50%                   5.000000        5.000000     5.000000     5.000000   \n",
       "75%                   7.000000        7.000000     7.000000     7.000000   \n",
       "max                  19.000000       19.000000    19.000000    19.000000   \n",
       "\n",
       "       t5_sequence  gap_sequence  ...  gap_sequence_embedding  \\\n",
       "count  4000.000000   4000.000000  ...             4000.000000   \n",
       "mean      4.141750      4.141750  ...                4.141750   \n",
       "std       3.729026      3.729026  ...                3.729026   \n",
       "min       0.000000      0.000000  ...                0.000000   \n",
       "25%       0.000000      0.000000  ...                0.000000   \n",
       "50%       5.000000      5.000000  ...                5.000000   \n",
       "75%       7.000000      7.000000  ...                7.000000   \n",
       "max      19.000000     19.000000  ...               19.000000   \n",
       "\n",
       "       t5_sequence_embedding  question_answer_embedding  \\\n",
       "count            4000.000000                4000.000000   \n",
       "mean                4.141750                   4.141750   \n",
       "std                 3.729026                   3.729026   \n",
       "min                 0.000000                   0.000000   \n",
       "25%                 0.000000                   0.000000   \n",
       "50%                 5.000000                   5.000000   \n",
       "75%                 7.000000                   7.000000   \n",
       "max                19.000000                  19.000000   \n",
       "\n",
       "       highlighted_determ_sequence  no_highlighted_determ_sequence  \\\n",
       "count                  4000.000000                     4000.000000   \n",
       "mean                      4.141750                        4.141750   \n",
       "std                       3.729026                        3.729026   \n",
       "min                       0.000000                        0.000000   \n",
       "25%                       0.000000                        0.000000   \n",
       "50%                       5.000000                        5.000000   \n",
       "75%                       7.000000                        7.000000   \n",
       "max                      19.000000                       19.000000   \n",
       "\n",
       "       highlighted_t5_sequence  no_highlighted_t5_sequence  \\\n",
       "count              4000.000000                 4000.000000   \n",
       "mean                  4.141750                    4.141750   \n",
       "std                   3.729026                    3.729026   \n",
       "min                   0.000000                    0.000000   \n",
       "25%                   0.000000                    0.000000   \n",
       "50%                   5.000000                    5.000000   \n",
       "75%                   7.000000                    7.000000   \n",
       "max                  19.000000                   19.000000   \n",
       "\n",
       "       highlighted_gap_sequence  no_highlighted_gap_sequence  model_answers  \n",
       "count               4000.000000                  4000.000000    4000.000000  \n",
       "mean                   4.141750                     4.141750       4.534500  \n",
       "std                    3.729026                     3.729026       3.300005  \n",
       "min                    0.000000                     0.000000       1.000000  \n",
       "25%                    0.000000                     0.000000       1.000000  \n",
       "50%                    5.000000                     5.000000       5.000000  \n",
       "75%                    7.000000                     7.000000       7.000000  \n",
       "max                   19.000000                    19.000000      19.000000  \n",
       "\n",
       "[8 rows x 31 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# os.environ['HF_DATASETS_CACHE'] = '/workspace/storage/misc/huggingface'\n",
    "\n",
    "ds_type = \"large\"  # 'large' or 'xl'\n",
    "\n",
    "\n",
    "mintaka_dataset_path = \"AmazonScience/mintaka\"\n",
    "features_dataset_path = f\"hle2000/KGQA_T5-{ds_type}-ssm\"\n",
    "seq2seq_outputs_dataset_path = f\"s-nlp/Mintaka_T5_{ds_type}_ssm_outputs\"\n",
    "\n",
    "\n",
    "features_ds = load_dataset(features_dataset_path)\n",
    "outputs_ds = load_dataset(seq2seq_outputs_dataset_path)\n",
    "mintaka_ds = load_dataset(mintaka_dataset_path)\n",
    "\n",
    "\n",
    "train_df = prepare_data(mintaka_ds[\"train\"], outputs_ds[\"train\"], features_ds[\"train\"])\n",
    "valid_df = prepare_data(\n",
    "    mintaka_ds[\"validation\"], outputs_ds[\"validation\"], features_ds[\"validation\"]\n",
    ")\n",
    "test_df = prepare_data(mintaka_ds[\"test\"], outputs_ds[\"test\"], features_ds[\"test\"])\n",
    "test_df.groupby([\"id\", \"question\"]).count().describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_map = {\n",
    "    \"text\": [\"question_answer_embedding\"],\n",
    "    \"graph\": [\n",
    "        \"num_nodes\",\n",
    "        \"num_edges\",\n",
    "        \"density\",\n",
    "        \"cycle\",\n",
    "        \"bridge\",\n",
    "        \"katz_centrality\",\n",
    "        \"page_rank\",\n",
    "        \"avg_ssp_length\",\n",
    "    ],\n",
    "    \"g2t_determ\": [\"determ_sequence_embedding\"],\n",
    "    \"g2t_t5\": [\"t5_sequence_embedding\"],\n",
    "    \"g2t_gap\": [\"gap_sequence_embedding\"],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_path = Path(\n",
    "    f\"/workspace/storage/misc/subgraphs_reranking_runs/reranking_model_results/t5_{ds_type}_ssm/\"\n",
    ")\n",
    "results_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "\n",
    "full_random_ranker = FullRandomRanker()\n",
    "with open(\n",
    "    results_path / f\"full_random_reranking_seq2seq_{ds_type}_results.jsonl\", \"w\"\n",
    ") as f:\n",
    "    for result in full_random_ranker.rerank(test_df):\n",
    "        f.write(json.dumps(result) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_ranker = NORanker()\n",
    "with open(results_path / f\"NO_reranking_seq2seq_{ds_type}_results.jsonl\", \"w\") as f:\n",
    "    for result in no_ranker.rerank(test_df):\n",
    "        f.write(json.dumps(result) + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg_ranker = LogisticRegressionRanker(features_map[\"text\"])\n",
    "logreg_ranker.fit(train_df, n_jobs=8)\n",
    "with open(\n",
    "    results_path / f\"logreg_text_reranking_seq2seq_{ds_type}_results.jsonl\", \"w\"\n",
    ") as f:\n",
    "    for result in logreg_ranker.rerank(test_df):\n",
    "        f.write(json.dumps(result) + \"\\n\")\n",
    "\n",
    "\n",
    "logreg_ranker = LogisticRegressionRanker(features_map[\"graph\"])\n",
    "logreg_ranker.fit(train_df, n_jobs=8)\n",
    "with open(\n",
    "    results_path / f\"logreg_graph_reranking_seq2seq_{ds_type}_results.jsonl\", \"w\"\n",
    ") as f:\n",
    "    for result in logreg_ranker.rerank(test_df):\n",
    "        f.write(json.dumps(result) + \"\\n\")\n",
    "\n",
    "\n",
    "logreg_ranker = LogisticRegressionRanker(features_map[\"text\"] + features_map[\"graph\"])\n",
    "logreg_ranker.fit(train_df, n_jobs=8)\n",
    "with open(\n",
    "    results_path / f\"logreg_text_graph_reranking_seq2seq_{ds_type}_results.jsonl\", \"w\"\n",
    ") as f:\n",
    "    for result in logreg_ranker.rerank(test_df):\n",
    "        f.write(json.dumps(result) + \"\\n\")\n",
    "\n",
    "\n",
    "logreg_ranker = LogisticRegressionRanker(features_map[\"g2t_determ\"])\n",
    "logreg_ranker.fit(train_df, n_jobs=8)\n",
    "with open(\n",
    "    results_path / f\"logreg_g2t_determ_reranking_seq2seq_{ds_type}_results.jsonl\", \"w\"\n",
    ") as f:\n",
    "    for result in logreg_ranker.rerank(test_df):\n",
    "        f.write(json.dumps(result) + \"\\n\")\n",
    "\n",
    "\n",
    "logreg_ranker = LogisticRegressionRanker(features_map[\"g2t_t5\"])\n",
    "logreg_ranker.fit(train_df, n_jobs=8)\n",
    "with open(\n",
    "    results_path / f\"logreg_g2t_t5_reranking_seq2seq_{ds_type}_results.jsonl\", \"w\"\n",
    ") as f:\n",
    "    for result in logreg_ranker.rerank(test_df):\n",
    "        f.write(json.dumps(result) + \"\\n\")\n",
    "\n",
    "\n",
    "logreg_ranker = LogisticRegressionRanker(features_map[\"g2t_gap\"])\n",
    "logreg_ranker.fit(train_df, n_jobs=8)\n",
    "with open(\n",
    "    results_path / f\"logreg_g2t_gap_reranking_seq2seq_{ds_type}_results.jsonl\", \"w\"\n",
    ") as f:\n",
    "    for result in logreg_ranker.rerank(test_df):\n",
    "        f.write(json.dumps(result) + \"\\n\")\n",
    "\n",
    "\n",
    "logreg_ranker = LogisticRegressionRanker(\n",
    "    features_map[\"text\"] + features_map[\"g2t_determ\"] + features_map[\"graph\"]\n",
    ")\n",
    "logreg_ranker.fit(train_df, n_jobs=8)\n",
    "with open(\n",
    "    results_path\n",
    "    / f\"logreg_text_g2t_determ_graph_reranking_seq2seq_{ds_type}_results.jsonl\",\n",
    "    \"w\",\n",
    ") as f:\n",
    "    for result in logreg_ranker.rerank(test_df):\n",
    "        f.write(json.dumps(result) + \"\\n\")\n",
    "\n",
    "\n",
    "logreg_ranker = LogisticRegressionRanker(\n",
    "    features_map[\"text\"] + features_map[\"g2t_t5\"] + features_map[\"graph\"]\n",
    ")\n",
    "logreg_ranker.fit(train_df, n_jobs=8)\n",
    "with open(\n",
    "    results_path\n",
    "    / f\"logreg_text_g2t_t5_graph_reranking_seq2seq_{ds_type}_results.jsonl\",\n",
    "    \"w\",\n",
    ") as f:\n",
    "    for result in logreg_ranker.rerank(test_df):\n",
    "        f.write(json.dumps(result) + \"\\n\")\n",
    "\n",
    "logreg_ranker = LogisticRegressionRanker(\n",
    "    features_map[\"text\"] + features_map[\"g2t_gap\"] + features_map[\"graph\"]\n",
    ")\n",
    "logreg_ranker.fit(train_df, n_jobs=8)\n",
    "with open(\n",
    "    results_path\n",
    "    / f\"logreg_text_g2t_gap_graph_reranking_seq2seq_{ds_type}_results.jsonl\",\n",
    "    \"w\",\n",
    ") as f:\n",
    "    for result in logreg_ranker.rerank(test_df):\n",
    "        f.write(json.dumps(result) + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg_ranker = LinearRegressionRanker(features_map[\"text\"])\n",
    "logreg_ranker.fit(train_df, n_jobs=8)\n",
    "with open(\n",
    "    results_path / f\"linreg_text_reranking_seq2seq_{ds_type}_results.jsonl\", \"w\"\n",
    ") as f:\n",
    "    for result in logreg_ranker.rerank(test_df):\n",
    "        f.write(json.dumps(result) + \"\\n\")\n",
    "\n",
    "\n",
    "logreg_ranker = LinearRegressionRanker(features_map[\"graph\"])\n",
    "logreg_ranker.fit(train_df, n_jobs=8)\n",
    "with open(\n",
    "    results_path / f\"linreg_graph_reranking_seq2seq_{ds_type}_results.jsonl\", \"w\"\n",
    ") as f:\n",
    "    for result in logreg_ranker.rerank(test_df):\n",
    "        f.write(json.dumps(result) + \"\\n\")\n",
    "\n",
    "\n",
    "logreg_ranker = LinearRegressionRanker(features_map[\"text\"] + features_map[\"graph\"])\n",
    "logreg_ranker.fit(train_df, n_jobs=8)\n",
    "with open(\n",
    "    results_path / f\"linreg_text_graph_reranking_seq2seq_{ds_type}_results.jsonl\", \"w\"\n",
    ") as f:\n",
    "    for result in logreg_ranker.rerank(test_df):\n",
    "        f.write(json.dumps(result) + \"\\n\")\n",
    "\n",
    "\n",
    "logreg_ranker = LinearRegressionRanker(features_map[\"g2t_determ\"])\n",
    "logreg_ranker.fit(train_df, n_jobs=8)\n",
    "with open(\n",
    "    results_path / f\"linreg_g2t_determ_reranking_seq2seq_{ds_type}_results.jsonl\", \"w\"\n",
    ") as f:\n",
    "    for result in logreg_ranker.rerank(test_df):\n",
    "        f.write(json.dumps(result) + \"\\n\")\n",
    "\n",
    "\n",
    "logreg_ranker = LinearRegressionRanker(features_map[\"g2t_t5\"])\n",
    "logreg_ranker.fit(train_df, n_jobs=8)\n",
    "with open(\n",
    "    results_path / f\"linreg_g2t_t5_reranking_seq2seq_{ds_type}_results.jsonl\", \"w\"\n",
    ") as f:\n",
    "    for result in logreg_ranker.rerank(test_df):\n",
    "        f.write(json.dumps(result) + \"\\n\")\n",
    "\n",
    "\n",
    "logreg_ranker = LinearRegressionRanker(features_map[\"g2t_gap\"])\n",
    "logreg_ranker.fit(train_df, n_jobs=8)\n",
    "with open(\n",
    "    results_path / f\"linreg_g2t_gap_reranking_seq2seq_{ds_type}_results.jsonl\", \"w\"\n",
    ") as f:\n",
    "    for result in logreg_ranker.rerank(test_df):\n",
    "        f.write(json.dumps(result) + \"\\n\")\n",
    "\n",
    "\n",
    "logreg_ranker = LinearRegressionRanker(\n",
    "    features_map[\"text\"] + features_map[\"g2t_determ\"] + features_map[\"graph\"]\n",
    ")\n",
    "logreg_ranker.fit(train_df, n_jobs=8)\n",
    "with open(\n",
    "    results_path\n",
    "    / f\"linreg_text_g2t_determ_graph_reranking_seq2seq_{ds_type}_results.jsonl\",\n",
    "    \"w\",\n",
    ") as f:\n",
    "    for result in logreg_ranker.rerank(test_df):\n",
    "        f.write(json.dumps(result) + \"\\n\")\n",
    "\n",
    "\n",
    "logreg_ranker = LinearRegressionRanker(\n",
    "    features_map[\"text\"] + features_map[\"g2t_t5\"] + features_map[\"graph\"]\n",
    ")\n",
    "logreg_ranker.fit(train_df, n_jobs=8)\n",
    "with open(\n",
    "    results_path\n",
    "    / f\"linreg_text_g2t_t5_graph_reranking_seq2seq_{ds_type}_results.jsonl\",\n",
    "    \"w\",\n",
    ") as f:\n",
    "    for result in logreg_ranker.rerank(test_df):\n",
    "        f.write(json.dumps(result) + \"\\n\")\n",
    "\n",
    "\n",
    "logreg_ranker = LinearRegressionRanker(\n",
    "    features_map[\"text\"] + features_map[\"g2t_gap\"] + features_map[\"graph\"]\n",
    ")\n",
    "logreg_ranker.fit(train_df, n_jobs=8)\n",
    "with open(\n",
    "    results_path\n",
    "    / f\"linreg_text_g2t_gap_graph_reranking_seq2seq_{ds_type}_results.jsonl\",\n",
    "    \"w\",\n",
    ") as f:\n",
    "    for result in logreg_ranker.rerank(test_df):\n",
    "        f.write(json.dumps(result) + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MPNet "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"sentence-transformers/all-mpnet-base-v2\")\n",
    "\n",
    "\n",
    "def apply_sep(seq):\n",
    "    if isinstance(seq, str):\n",
    "        q_a_splits = seq.split(\";\")\n",
    "        seq = f\"{q_a_splits[0]}{tokenizer}{q_a_splits[-1]}\"\n",
    "    return seq\n",
    "\n",
    "\n",
    "test_df[\"question_answer\"] = test_df[\"question_answer\"].apply(apply_sep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Try load model...\n",
      "Model Loaded.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "579f2caacc9d4f04894e484d9cd40161",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Try load model...\n",
      "Model Loaded.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d93143f2fad34243a88cbc9bd3cf2f86",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\")\n",
    "\n",
    "model_path = \"/workspace/storage/misc/subgraphs_reranking_results/question_answer/T5-xl-ssm/question_answer_nocherries_fixed_train/outputs/checkpoint-best\"\n",
    "mpnet_ranker = MPNetRanker(\"question_answer\", model_path, device)\n",
    "with open(\n",
    "    results_path / f\"mpnet_text_only_determ_reranking_seq2seq_{ds_type}_results.jsonl\",\n",
    "    \"w+\",\n",
    ") as f:\n",
    "    for result in mpnet_ranker.rerank(test_df):\n",
    "        f.write(json.dumps(result) + \"\\n\")\n",
    "\n",
    "model_path = f\"/mnt/storage/QA_System_Project/subgraphs_reranking_runs/determ/T5-{ds_type}-ssm/no_cherries_hl_false_determ/outputs/checkpoint-best\"\n",
    "mpnet_ranker = MPNetRanker(\"no_highlighted_determ_sequence\", model_path, device)\n",
    "with open(\n",
    "    results_path / f\"mpnet_no_hl_g2t_determ_reranking_seq2seq_{ds_type}_results.jsonl\",\n",
    "    \"w\",\n",
    ") as f:\n",
    "    for result in mpnet_ranker.rerank(test_df):\n",
    "        f.write(json.dumps(result) + \"\\n\")\n",
    "\n",
    "model_path = f\"/mnt/storage/QA_System_Project/subgraphs_reranking_runs/determ/T5-{ds_type}-ssm/no_cherries_hl_true_determ/outputs/checkpoint-best/\"\n",
    "mpnet_ranker = MPNetRanker(\"highlighted_determ_sequence\", model_path, device)\n",
    "with open(\n",
    "    results_path / f\"mpnet_hl_g2t_determ_reranking_seq2seq_{ds_type}_results.jsonl\", \"w\"\n",
    ") as f:\n",
    "    for result in mpnet_ranker.rerank(test_df):\n",
    "        f.write(json.dumps(result) + \"\\n\")\n",
    "\n",
    "\n",
    "model_path = f\"/mnt/storage/QA_System_Project/subgraphs_reranking_runs/g2t/T5-{ds_type}-ssm/no_cherries_fixed_train_g2t_hl_true_large/outputs/checkpoint-best\"\n",
    "mpnet_ranker = MPNetRanker(\"highlighted_t5_sequence\", model_path, device)\n",
    "with open(\n",
    "    results_path / f\"mpnet_hl_g2t_t5_reranking_seq2seq_{ds_type}_results.jsonl\", \"w\"\n",
    ") as f:\n",
    "    for result in mpnet_ranker.rerank(test_df):\n",
    "        f.write(json.dumps(result) + \"\\n\")\n",
    "\n",
    "model_path = f\"/mnt/storage/QA_System_Project/subgraphs_reranking_runs/g2t/T5-{ds_type}-ssm/no_cherries_fixed_train_g2t_hl_false_large/outputs/checkpoint-best\"\n",
    "mpnet_ranker = MPNetRanker(\"no_highlighted_t5_sequence\", model_path, device)\n",
    "with open(\n",
    "    results_path / f\"mpnet_no_hl_g2t_t5_reranking_seq2seq_{ds_type}_results.jsonl\", \"w\"\n",
    ") as f:\n",
    "    for result in mpnet_ranker.rerank(test_df):\n",
    "        f.write(json.dumps(result) + \"\\n\")\n",
    "\n",
    "\n",
    "model_path = f\"/mnt/storage/QA_System_Project/subgraphs_reranking_runs/gap/T5-{ds_type}-ssm/no_cherries_fixed_train_hl_true_gap_large/outputs/checkpoint-best\"\n",
    "mpnet_ranker = MPNetRanker(\"highlighted_gap_sequence\", model_path, device)\n",
    "with open(\n",
    "    results_path / f\"mpnet_hl_g2t_gap_reranking_seq2seq_{ds_type}_results.jsonl\", \"w\"\n",
    ") as f:\n",
    "    for result in mpnet_ranker.rerank(test_df):\n",
    "        f.write(json.dumps(result) + \"\\n\")\n",
    "\n",
    "model_path = f\"/mnt/storage/QA_System_Project/subgraphs_reranking_runs/gap/T5-{ds_type}-ssm/no_cherries_fixed_train_hl_false_gap_large/outputs/checkpoint-best\"\n",
    "mpnet_ranker = MPNetRanker(\"no_highlighted_gap_sequence\", model_path, device)\n",
    "with open(\n",
    "    results_path / f\"mpnet_no_hl_g2t_gap_reranking_seq2seq_{ds_type}_results.jsonl\", \"w\"\n",
    ") as f:\n",
    "    for result in mpnet_ranker.rerank(test_df):\n",
    "        f.write(json.dumps(result) + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trying to load the model...\n",
      "Model Loaded.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "874d43e75683475ab2bca45084a68329",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from catboost import CatBoostRegressor\n",
    "\n",
    "model_weights = \"/workspace/storage/misc/features_reranking/catboost/unified_reranking/T5-large-ssm/catboost_text_large_ASK/best_model\"\n",
    "catboost_ranker = CatboostRanker(model_weights, features_map[\"text\"])\n",
    "\n",
    "with open(\n",
    "    results_path / f\"catboost_text_reranking_seq2seq_{ds_type}_results.jsonl\", \"w\"\n",
    ") as f:\n",
    "    for result in catboost_ranker.rerank(test_df):\n",
    "        f.write(json.dumps(result) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
