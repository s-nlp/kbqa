{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import datasets\n",
    "from pathlib import Path\n",
    "from transformers import T5ForConditionalGeneration, AutoTokenizer\n",
    "from typing import List, Optional, Dict\n",
    "import pickle\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "tqdm.pandas()\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from pywikidata import Entity\n",
    "from kbqa.utils.train_eval import get_best_checkpoint_path\n",
    "\n",
    "from trie import MarisaTrie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fatal: destination path 'wikidata-simplequestions' already exists and is not an empty directory.\n",
      "File ‘lang_title2wikidataID-normalized_with_redirect.pkl’ already there; not retrieving.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/askplatypus/wikidata-simplequestions.git\n",
    "!wget -nc https://dl.fbaipublicfiles.com/GENRE/lang_title2wikidataID-normalized_with_redirect.pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./lang_title2wikidataID-normalized_with_redirect.pkl\", \"rb\") as f:\n",
    "    lang_title2wikidataID = pickle.load(f)\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"google/t5-large-ssm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\n",
    "    \"./wikidata-simplequestions/annotated_wd_data_train_answerable.txt\",\n",
    "    sep=\"\\t\",\n",
    "    names=[\"S\", \"P\", \"O\", \"Q\"],\n",
    ")\n",
    "\n",
    "valid_df = pd.read_csv(\n",
    "    \"./wikidata-simplequestions/annotated_wd_data_valid_answerable.txt\",\n",
    "    sep=\"\\t\",\n",
    "    names=[\"S\", \"P\", \"O\", \"Q\"],\n",
    ")\n",
    "\n",
    "test_df = pd.read_csv(\n",
    "    \"./wikidata-simplequestions/annotated_wd_data_test_answerable.txt\",\n",
    "    sep=\"\\t\",\n",
    "    names=[\"S\", \"P\", \"O\", \"Q\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19481/19481 [00:04<00:00, 4290.21it/s]\n",
      "100%|██████████| 19481/19481 [00:00<00:00, 196902.06it/s]\n",
      "100%|██████████| 19481/19481 [00:01<00:00, 10951.96it/s]\n",
      "100%|██████████| 2821/2821 [00:00<00:00, 5616.17it/s]\n",
      "100%|██████████| 2821/2821 [00:00<00:00, 223974.63it/s]\n",
      "100%|██████████| 2821/2821 [00:00<00:00, 12071.05it/s]\n",
      "100%|██████████| 5622/5622 [00:00<00:00, 5796.05it/s]\n",
      "100%|██████████| 5622/5622 [00:00<00:00, 227504.41it/s]\n",
      "100%|██████████| 5622/5622 [00:00<00:00, 11889.87it/s]\n"
     ]
    }
   ],
   "source": [
    "allowed_names_en = [name for lang, name in lang_title2wikidataID.keys() if lang == \"en\"]\n",
    "\n",
    "for df in [train_df, valid_df, test_df]:\n",
    "    allowed_names_en += (\n",
    "        df[\"S\"].progress_apply(lambda idx: Entity(idx).label).unique().tolist()\n",
    "    )\n",
    "    allowed_names_en += (\n",
    "        df[\"P\"]\n",
    "        .progress_apply(lambda idx: Entity(idx.replace(\"R\", \"P\")).label)\n",
    "        .unique()\n",
    "        .tolist()\n",
    "    )\n",
    "    allowed_names_en += (\n",
    "        df[\"O\"].progress_apply(lambda idx: Entity(idx).label).unique().tolist()\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14753570/14753570 [12:13<00:00, 20117.12it/s]\n"
     ]
    }
   ],
   "source": [
    "allowed_names_en = list(set(allowed_names_en))\n",
    "allowed_names_en = list(\n",
    "    filter(lambda s: isinstance(s, str) and s != \"\", allowed_names_en)\n",
    ")\n",
    "\n",
    "allowed_names_en_tok = [tokenizer(name)[\"input_ids\"] for name in tqdm(allowed_names_en)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tok_names_padded = [\n",
    "    [\n",
    "        tokenizer.pad_token_id,\n",
    "    ]\n",
    "    + toks\n",
    "    for toks in allowed_names_en_tok\n",
    "]\n",
    "trie = MarisaTrie(sequences=tok_names_padded, cache_fist_branch=True)\n",
    "with open(\"./wdsq_t5_trie.pkl\", \"wb\") as f:\n",
    "    pickle.dump(trie, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14753570/14753570 [12:57<00:00, 18975.63it/s]\n"
     ]
    }
   ],
   "source": [
    "mgenre_tokenizer = AutoTokenizer.from_pretrained(\"facebook/mgenre-wiki\")\n",
    "allowed_names_en_tok_mgenre = [\n",
    "    mgenre_tokenizer(name + \" >> en\")[\"input_ids\"] for name in tqdm(allowed_names_en)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "tok_names_padded_mgenre = [\n",
    "    [\n",
    "        mgenre_tokenizer.sep_token_id,\n",
    "    ]\n",
    "    + toks\n",
    "    for toks in allowed_names_en_tok_mgenre\n",
    "]\n",
    "trie = MarisaTrie(sequences=tok_names_padded_mgenre, cache_fist_branch=True)\n",
    "with open(\"./wdsq_mgenre_trie.pkl\", \"wb\") as f:\n",
    "    pickle.dump(trie, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10 (default, Jun 22 2022, 20:18:18) \n[GCC 9.4.0]"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
