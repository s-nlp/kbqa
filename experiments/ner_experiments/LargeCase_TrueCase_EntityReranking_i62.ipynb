{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xH6JOFnZVvEI"
      },
      "source": [
        "### Install requirements and downoad packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "T0SGVUHXVrq7",
        "outputId": "ce62e741-4db8-4d25-a7e0-c7d669fc8e28"
      },
      "outputs": [],
      "source": [
        "! pip install allennlp==0.8.4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uXWniVxKK670",
        "outputId": "b2729bca-5d73-49c6-f379-8c8325d0cc69"
      },
      "outputs": [],
      "source": [
        "! pip install overrides==3.1.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2as0lBEJKWb-",
        "outputId": "c36b5862-6742-4a18-cd42-bbf44dc3a304"
      },
      "outputs": [],
      "source": [
        "! git clone https://github.com/mayhewsw/pytorch-truecaser pytorch_truecaser"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YMUWQncMKdTY",
        "outputId": "8e680038-17f7-4618-efd4-f7fe19e1cd21"
      },
      "outputs": [],
      "source": [
        "!wget https://github.com/mayhewsw/pytorch-truecaser/releases/download/v1.0/wiki-truecaser-model-en.tar.gz\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w7BQpRObMNgQ",
        "outputId": "7a5e5200-fabf-46f0-d1bf-f9beafc1fdc9"
      },
      "outputs": [],
      "source": [
        "! pip3 uninstall  scikit-learn -y\n",
        "! pip3 install -i https://pypi.douban.com/simple scikit-learn==0.19.2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xax2vdRsKiqQ",
        "outputId": "c597cb99-26f9-4254-ce2d-e6253699a669"
      },
      "outputs": [],
      "source": [
        "from allennlp.predictors.predictor import Predictor\n",
        "from pytorch_truecaser.mylib import *\n",
        "from allennlp.models.archival import load_archive\n",
        "\n",
        "from typing import List"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S8BIFBkzYUKd"
      },
      "source": [
        "### Truecase Without NER Mayhewsw"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "QcH_cBvfWqHQ"
      },
      "outputs": [],
      "source": [
        "def truecase_withoutner_mayhewsw(sentence, archive, predictor):\n",
        "\n",
        "  out = predictor.predict(sentence)\n",
        "  outline = predictor.dump_line(out).split('\\n')[0]\n",
        "  sentence_withoutner = '[START] '+ str(outline) +' [END]'\n",
        " \n",
        "  return sentence_withoutner"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "_9Gq2L_YOk_I",
        "outputId": "dfb90666-ba69-4ee0-ff77-bd055ba10fd2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'[START] Where did Roger Marquis die [END]'"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "archive = load_archive(\"wiki-truecaser-model-en.tar.gz\")\n",
        "predictor = Predictor.from_archive(archive, \"truecaser-predictor\")\n",
        "\n",
        "#example truecase_withoutner_mayhewsw\n",
        "sent = 'Where did roger marquis die'\n",
        "truecase_withoutner_mayhewsw(sent, archive, predictor)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LecSfgc2Yc1t"
      },
      "source": [
        "### Truecase With NER Mayhewsw"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "o3ky254RZkU-"
      },
      "outputs": [],
      "source": [
        "def truecase_withner_mayhewsw(sentence_withner, sentence_truecase):\n",
        "\n",
        "    sent_to_change = sentence_withner.replace(\"  \", \" \")\n",
        "    sent_to_change = sent_to_change.split(' ')\n",
        "    if '' in sent_to_change:\n",
        "        sent_to_change.remove('')\n",
        "    sent_truecase = sentence_truecase.replace(\"  \", \" \")\n",
        "    sent_truecase = sent_truecase[8:-6].split(' ')\n",
        "    if '' in sent_truecase:\n",
        "        sent_truecase.remove('')\n",
        "\n",
        "    if \"[START]  [END]\" not in sent_to_change and len(sent_to_change) == len(sent_truecase)+2:\n",
        "        for m in range(len(sent_to_change)):\n",
        "            if '[START]' in sent_to_change[m]:\n",
        "                id_start = m\n",
        "            elif '[END]' in sent_to_change[m]:\n",
        "                id_end = m\n",
        "        for k in range(id_start):\n",
        "            sent_to_change[k] = sent_truecase[k]\n",
        "        for l in range(id_start+1, id_end):\n",
        "            sent_to_change[l] = sent_truecase[l-1]\n",
        "        for z in range(id_end+1, len(sent_to_change)-1):\n",
        "            sent_to_change[z] = sent_truecase[z-2]\n",
        "        return ' '.join(sent_to_change)\n",
        "    else:\n",
        "        return ' '.join(sent_truecase)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "JUWIaTs8ayOm",
        "outputId": "8c110afa-7cf3-4c14-eca3-11c472671327"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Where did [START] Roger Marquis [END] die'"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#example truecase with ner mayhewsw\n",
        "sent = 'Where did roger marquis die'\n",
        "\n",
        "#sentence with ner is taken from NerToSentenceInsertion class\n",
        "sentence_with_ner = \"Where did [START] roger marquis [END] die\"\n",
        "\n",
        "sentence_true_case = truecase_withoutner_mayhewsw(sent, archive, predictor)\n",
        "\n",
        "truecase_withner_mayhewsw(sentence_with_ner, sentence_true_case)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-si-lHJ5chXj"
      },
      "source": [
        "### Reranking of final prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "Ho90m33zdnhA"
      },
      "outputs": [],
      "source": [
        "def predictions_reranking(preds_main: List[str], preds_secondary: List[str]):\n",
        "    preds_joined = []\n",
        "    min_index = min(len(preds_main), len(preds_secondary))\n",
        "    \n",
        "    #if the length of pred_main and pred_secondary coincide\n",
        "    for k in range(min_index):\n",
        "        if preds_main[k] == preds_secondary[k]:\n",
        "            preds_joined.append(preds_main[k])\n",
        "        else:\n",
        "            preds_joined.append(preds_main[k])\n",
        "            preds_joined.append(preds_secondary[k])\n",
        "    \n",
        "    #if pred_main larger than pred_secondary \n",
        "    if len(preds_main) > len(preds_secondary):\n",
        "        diff = len(preds_main)- len(preds_secondary)\n",
        "        subset = preds_main[-diff:]\n",
        "        for t in range(len(subset)):\n",
        "            preds_joined.append(subset[t])\n",
        "    \n",
        "    #if pred_secondary larger than pred_main\n",
        "    elif len(preds_main) < len(preds_secondary):\n",
        "        diff = len(preds_secondary)- len(preds_main)\n",
        "        subset = preds_secondary[-diff:]\n",
        "        for t in range(len(subset)):\n",
        "            preds_joined.append(subset[t])\n",
        "    \n",
        "    #delete repated ids\n",
        "\n",
        "    remove_indices = []\n",
        "    \n",
        "    for q in range(len(preds_joined)):\n",
        "        for p in range(q):\n",
        "            if preds_joined[q] == preds_joined[p]:\n",
        "                remove_indices.append(q)\n",
        "    \n",
        "    preds_joined_upd = [i for w, i in enumerate(preds_joined) if w not in remove_indices]\n",
        "    \n",
        "    return preds_joined_upd"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-UgZc2SAcnNO"
      },
      "source": [
        "1) Obtain prediction Truecase With NER Mayhewsw\n",
        "\n",
        "2) Obtain prediction for the Truecase Without NER Mayhewsw\n",
        "\n",
        "3) Obtain prediction for the initial sentence with class NerToSentenceInsertion\n",
        "\n",
        "4) Compute function predictions_reranking (Truecase With NER Mayhewsw, Truecase Without NER Mayhewsw )\n",
        "\n",
        "5) Compute function predictions_reranking (class NerToSentenceInsertion, prediction obtained in step 4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "KL8CL9VWd-e-",
        "outputId": "5e72fa01-0114-419c-de1b-5be07c9ea03c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['Q7358590',\n",
              " 'Q8068232',\n",
              " 'Q8012493',\n",
              " 'Q2712858',\n",
              " 'Q7358592',\n",
              " 'Q6628665',\n",
              " 'Q1773375',\n",
              " 'Q6628660',\n",
              " 'Q763848']"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#Example of reranking\n",
        "# Results obtained for the sentence 'Where did roger marquis die'\n",
        "\n",
        "#1\n",
        "preds_truecase_with_ner = \"Q7358590, Q7358592, Q1773375\".split(', ')\n",
        "#2\n",
        "preds_truecase_without_ner = \"Q8012493, Q7358590, Q6628660, Q763848, Q7358592\".split(', ')\n",
        "#3\n",
        "preds_ner_to_sentence_insertion = \"Q7358590, Q8068232, Q2712858, Q6628665\".split(', ')\n",
        "#4\n",
        "\n",
        "reranking_1step = predictions_reranking(preds_truecase_with_ner, preds_truecase_without_ner)\n",
        "reranking_2step = predictions_reranking(preds_ner_to_sentence_insertion, reranking_1step)\n",
        "reranking_2step"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pickle\n",
        "import torch\n",
        "import os\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "\n",
        "tqdm.pandas()\n",
        "\n",
        "import sys\n",
        "sys.path.insert(0,'../../')\n",
        "from caches.ner_to_sentence_insertion import NerToSentenceInsertion\n",
        "from genre.fairseq_model import mGENRE  # pylint: disable=import-error,import-error\n",
        "from wikidata.wikidata_entity_to_label import WikidataEntityToLabel\n",
        "from caches.genre import GENREWikidataEntityesCache\n",
        "from wikidata.wikidata_subgraphs_retriever import SubgraphsRetriever\n",
        "from wikidata.wikidata_shortest_path import WikidataShortestPathCache\n",
        "from wikidata.wikidata_label_to_entity import WikidataLabelToEntity\n",
        "from wikidata.wikidata_redirects import WikidataRedirectsCache\n",
        "from genre.trie import Trie, MarisaTrie  # pylint: disable=unused-import,import-error"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [],
      "source": [
        "# os.environ['CUDA_VISIBLE_DEVICES'] = '2'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "finished loading pkl\n"
          ]
        }
      ],
      "source": [
        "with open('../../../genre_requirements/lang_title2wikidataID-normalized_with_redirect.pkl', \"rb\") as f:\n",
        "    lang_title_wikidata_id = pickle.load(f)\n",
        "\n",
        "with open('../../../genre_requirements/titles_lang_all105_marisa_trie_with_redirect.pkl', \"rb\") as f:\n",
        "    trie = pickle.load(f)\n",
        "\n",
        "print(\"finished loading pkl\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = mGENRE.from_pretrained('../../../genre_requirements/fairseq_multilingual_entity_disambiguation/').eval()\n",
        "model.to(device)\n",
        "\n",
        "genre_entities = GENREWikidataEntityesCache(\n",
        "    model,\n",
        "    trie,\n",
        "    lang_title_wikidata_id,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>S</th>\n",
              "      <th>Q</th>\n",
              "      <th>Q_with_NER</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Q8070</td>\n",
              "      <td>What can cause a tsunami?</td>\n",
              "      <td>What Can Cause A [START] Tsunami [END]?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Q2222</td>\n",
              "      <td>Who wrote the novel \"uncle Tom's Cabin\"?</td>\n",
              "      <td>Who Wrote The Novel \"[START] Uncle Tom [END]'s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Q83186</td>\n",
              "      <td>Who is the author of the play \"Romeo and Juliet\"?</td>\n",
              "      <td>Who Is The Author Of The Play \"[START] Romeo A...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Q218</td>\n",
              "      <td>What is the name of the capital of Romania?</td>\n",
              "      <td>What Is The Name Of The [START] Capital Of Rom...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Q5928</td>\n",
              "      <td>What instrument did Jimi Hendrix play?</td>\n",
              "      <td>What Instrument Did [START] Jimi Hendrix [END]...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        S                                                  Q  \\\n",
              "0   Q8070                          What can cause a tsunami?   \n",
              "1   Q2222           Who wrote the novel \"uncle Tom's Cabin\"?   \n",
              "2  Q83186  Who is the author of the play \"Romeo and Juliet\"?   \n",
              "3    Q218        What is the name of the capital of Romania?   \n",
              "4   Q5928             What instrument did Jimi Hendrix play?   \n",
              "\n",
              "                                          Q_with_NER  \n",
              "0            What Can Cause A [START] Tsunami [END]?  \n",
              "1  Who Wrote The Novel \"[START] Uncle Tom [END]'s...  \n",
              "2  Who Is The Author Of The Play \"[START] Romeo A...  \n",
              "3  What Is The Name Of The [START] Capital Of Rom...  \n",
              "4  What Instrument Did [START] Jimi Hendrix [END]...  "
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "# Firstly run prepare_wdsq_and_rubq_datasets_for_el_i62.ipynb\n",
        "test_df = pd.read_csv(\n",
        "    './RuBQ_test_part4ner.csv',\n",
        ")\n",
        "test_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1913/1913 [00:56<00:00, 33.82it/s]\n"
          ]
        }
      ],
      "source": [
        "test_df['q_without_ner_mayhewsw'] = test_df['Q'].progress_apply(\n",
        "    lambda q: truecase_withoutner_mayhewsw(q, archive, predictor)\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1913/1913 [00:00<00:00, 20189.02it/s]\n"
          ]
        }
      ],
      "source": [
        "test_df['q_with_ner_mayhewsw'] = test_df.progress_apply(\n",
        "    lambda row: truecase_withner_mayhewsw(row['Q_with_NER'], row['q_without_ner_mayhewsw']),\n",
        "    axis=1\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "30it [00:00, 4479.34it/s]             \n"
          ]
        }
      ],
      "source": [
        "def chunks(lst, size):\n",
        "    \"\"\"Yield successive n-sized chunks from lst.\"\"\"\n",
        "    for i in range(0, len(lst), size):\n",
        "        yield lst[i : i + size]\n",
        "\n",
        "batch_size = 64\n",
        "Q_with_NER_entities = []\n",
        "for batch in tqdm(chunks(test_df['Q_with_NER'].values, batch_size), total=test_df.index.size // batch_size):\n",
        "    Q_with_NER_entities.extend(genre_entities.sentences_batch_to_entities(batch.tolist()))\n",
        "\n",
        "test_df['Q_with_NER_entities'] = Q_with_NER_entities"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "30it [00:00, 2960.34it/s]             \n"
          ]
        }
      ],
      "source": [
        "q_without_ner_mayhewsw_entities = []\n",
        "for batch in tqdm(chunks(test_df['q_without_ner_mayhewsw'].values, batch_size), total=test_df.index.size // batch_size):\n",
        "    q_without_ner_mayhewsw_entities.extend(genre_entities.sentences_batch_to_entities(batch.tolist()))\n",
        "\n",
        "test_df['q_without_ner_mayhewsw_entities'] = q_without_ner_mayhewsw_entities"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "30it [00:00, 10477.03it/s]            \n"
          ]
        }
      ],
      "source": [
        "q_with_ner_mayhewsw_entities = []\n",
        "for batch in tqdm(chunks(test_df['q_with_ner_mayhewsw'].values, batch_size), total=test_df.index.size // batch_size):\n",
        "    q_with_ner_mayhewsw_entities.extend(genre_entities.sentences_batch_to_entities(batch.tolist()))\n",
        "\n",
        "test_df['q_with_ner_mayhewsw_entities'] = q_with_ner_mayhewsw_entities"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1913/1913 [00:00<00:00, 7332.94it/s]\n"
          ]
        }
      ],
      "source": [
        "\n",
        "test_df['entities_after_rerank_v1'] = test_df.progress_apply(\n",
        "    lambda row: predictions_reranking(\n",
        "        [e['id'] for e in row['Q_with_NER_entities']],\n",
        "        predictions_reranking(\n",
        "            [e['id'] for e in row['q_with_ner_mayhewsw_entities']],\n",
        "            [e['id'] for e in row['q_without_ner_mayhewsw_entities']],\n",
        "        )\n",
        "    ),\n",
        "    axis=1\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Preds Q_with_NER_entities | Accuracy@1 =  0.5812859383167799\n",
            "Preds Q_with_NER_entities | Accuracy@2 =  0.6706743335075798\n",
            "Preds Q_with_NER_entities | Accuracy@3 =  0.7041296393099843\n",
            "Preds Q_with_NER_entities | Accuracy@4 =  0.7239937271301621\n",
            "Preds Q_with_NER_entities | Accuracy@5 =  0.7412441191845269\n",
            "\n",
            "Preds q_without_ner_mayhewsw_entities | Accuracy@1 =  0.5504443282801882\n",
            "Preds q_without_ner_mayhewsw_entities | Accuracy@2 =  0.6424464192368008\n",
            "Preds q_without_ner_mayhewsw_entities | Accuracy@3 =  0.6811291165708312\n",
            "Preds q_without_ner_mayhewsw_entities | Accuracy@4 =  0.702038682697334\n",
            "Preds q_without_ner_mayhewsw_entities | Accuracy@5 =  0.7250392054364871\n",
            "\n",
            "Preds q_with_ner_mayhewsw_entities | Accuracy@1 =  0.5849451123889179\n",
            "Preds q_with_ner_mayhewsw_entities | Accuracy@2 =  0.6638787245164662\n",
            "Preds q_with_ner_mayhewsw_entities | Accuracy@3 =  0.6999477260846837\n",
            "Preds q_with_ner_mayhewsw_entities | Accuracy@4 =  0.7208572922111867\n",
            "Preds q_with_ner_mayhewsw_entities | Accuracy@5 =  0.7365394668060637\n",
            "\n",
            "Preds entities_after_rerank_v1 | Accuracy@1 =  0.5812859383167799\n",
            "Preds entities_after_rerank_v1 | Accuracy@2 =  0.6957658128593832\n",
            "Preds entities_after_rerank_v1 | Accuracy@3 =  0.7480397281756404\n",
            "Preds entities_after_rerank_v1 | Accuracy@4 =  0.7783585990590696\n",
            "Preds entities_after_rerank_v1 | Accuracy@5 =  0.7909043387349712\n",
            "\n"
          ]
        }
      ],
      "source": [
        "def accuracy_top_k(targets, candidate_lists, top_k=5):\n",
        "    correct = 0\n",
        "    for idx in range(len(targets)):\n",
        "        target = targets[idx]\n",
        "        candidates = candidate_lists[idx]\n",
        "        correct += int(target in candidates[:top_k])\n",
        "    return correct / len(targets)\n",
        "\n",
        "\n",
        "for ecol in ['Q_with_NER_entities', 'q_without_ner_mayhewsw_entities', 'q_with_ner_mayhewsw_entities', 'entities_after_rerank_v1']:\n",
        "    targets = test_df['S'].values\n",
        "    if ecol == 'entities_after_rerank_v1':\n",
        "        candidate_lists = test_df[ecol].values\n",
        "    else:\n",
        "        candidate_lists = test_df[ecol].apply(lambda ents: [e['id'] for e in ents]).values\n",
        "\n",
        "    for k in range(1, 6):\n",
        "        acc = accuracy_top_k(\n",
        "            targets,\n",
        "            candidate_lists,\n",
        "            k\n",
        "        )\n",
        "        print(f'Preds {ecol} | Accuracy@{k} = ', acc)\n",
        "    print('')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {},
      "outputs": [],
      "source": [
        "test_df.to_pickle('RuBQ_EL_results.pkl')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {},
      "outputs": [],
      "source": [
        "entity2label = WikidataEntityToLabel()\n",
        "\n",
        "for ecol in ['Q_with_NER_entities', 'q_without_ner_mayhewsw_entities', 'q_with_ner_mayhewsw_entities']:\n",
        "    test_df[ecol+'_view'] = test_df[ecol].apply(\n",
        "        lambda ents: [\n",
        "            (e['id'], [t for t in e['texts'] if 'en' in t.split('>>')[-1]])\n",
        "            for e in ents\n",
        "        ]\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {},
      "outputs": [],
      "source": [
        "test_df[[\n",
        "    'Q', 'S', 'Q_with_NER_entities_view',\n",
        "    'Q_with_NER', 'q_without_ner_mayhewsw', 'q_with_ner_mayhewsw',\n",
        "    'q_without_ner_mayhewsw_entities_view', 'q_with_ner_mayhewsw_entities_view', 'entities_after_rerank_v1'\n",
        "]].to_excel('RuBQ_EL_results.xlsx')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.7.12 ('base')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.12"
    },
    "vscode": {
      "interpreter": {
        "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
