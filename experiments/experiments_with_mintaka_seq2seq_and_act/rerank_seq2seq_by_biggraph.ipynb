{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "from tqdm.auto import tqdm\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import ujson\n",
    "\n",
    "import torch\n",
    "\n",
    "import datasets\n",
    "from evaluateqa.mintaka import evaluate as evaluate_mintaka\n",
    "from evaluateqa.mintaka import calculate_metrics_for_prediction\n",
    "from evaluateqa.mintaka.evaluate import normalize_and_tokenize_text\n",
    "\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['CUDA_VISIBLE_DEVICES'] = '1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(8)\n",
    "random.seed(8)\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "biggraph_path = Path('/workspace/kbqa/PyTorchBigGraph')\n",
    "biggraph_names_path   = biggraph_path / 'wikidata_translation_v1_names.json'\n",
    "biggraph_vectors_path = biggraph_path / 'wikidata_translation_v1_vectors.npy'\n",
    "\n",
    "with open(biggraph_names_path, 'r') as f:\n",
    "    biggraph_names = ujson.load(f)\n",
    "biggraph_vectors = np.load(biggraph_vectors_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "673b70a0d37d482b8735e53d6c197144",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/78413185 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(78413185, 75413999)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "biggraph_name2id = {}\n",
    "for idx, name in enumerate(tqdm(biggraph_names)):\n",
    "    try:\n",
    "        biggraph_name2id[name.split('>')[0].split('/')[-1]] = idx\n",
    "    except: \n",
    "        pass\n",
    "\n",
    "len(biggraph_names), len(biggraph_name2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "entities = {\n",
    "    'London': biggraph_name2id['Q84'],\n",
    "    'Paris': biggraph_name2id['Q90'],\n",
    "    'UK': biggraph_name2id['Q145'],\n",
    "    'Imperial College London': biggraph_name2id['Q189022'],\n",
    "    'France': biggraph_name2id['Q142'],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entity1                   Entity2                   Dot_product\n",
      "London                    London                    60.947242736816406\n",
      "London                    Paris                     16.715190887451172\n",
      "London                    UK                        15.051984786987305\n",
      "London                    Imperial College London   16.485960006713867\n",
      "London                    France                    5.931976795196533\n",
      "Paris                     London                    16.715190887451172\n",
      "Paris                     Paris                     47.60779571533203\n",
      "Paris                     UK                        5.8029632568359375\n",
      "Paris                     Imperial College London   10.893638610839844\n",
      "Paris                     France                    16.393808364868164\n",
      "UK                        London                    15.051984786987305\n",
      "UK                        Paris                     5.8029632568359375\n",
      "UK                        UK                        44.623741149902344\n",
      "UK                        Imperial College London   13.00413703918457\n",
      "UK                        France                    15.787551879882812\n",
      "Imperial College London   London                    16.485960006713867\n",
      "Imperial College London   Paris                     10.893638610839844\n",
      "Imperial College London   UK                        13.00413703918457\n",
      "Imperial College London   Imperial College London   59.450340270996094\n",
      "Imperial College London   France                    8.991714477539062\n",
      "France                    London                    5.931976795196533\n",
      "France                    Paris                     16.393808364868164\n",
      "France                    UK                        15.787551879882812\n",
      "France                    Imperial College London   8.991714477539062\n",
      "France                    France                    40.8941535949707\n"
     ]
    }
   ],
   "source": [
    "print(f\"{'Entity1':25} {'Entity2':25} {'Dot_product'}\")\n",
    "for key, val in entities.items():\n",
    "    for key2, val2 in entities.items():\n",
    "        dot_product = np.dot(\n",
    "            biggraph_vectors[val],\n",
    "            biggraph_vectors[val2]\n",
    "        )\n",
    "        print(f\"{key:25} {key2:25} {dot_product}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>lang</th>\n",
       "      <th>question</th>\n",
       "      <th>answerText</th>\n",
       "      <th>category</th>\n",
       "      <th>complexityType</th>\n",
       "      <th>questionEntity</th>\n",
       "      <th>answerEntity</th>\n",
       "      <th>generated_text</th>\n",
       "      <th>sequences_scores</th>\n",
       "      <th>generated_entities</th>\n",
       "      <th>answerRetrievedType</th>\n",
       "      <th>filtered_by_type_preds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>fae46b21</td>\n",
       "      <td>en</td>\n",
       "      <td>What man was a famous American author and also...</td>\n",
       "      <td>Mark Twain</td>\n",
       "      <td>history</td>\n",
       "      <td>intersection</td>\n",
       "      <td>[{'name': 'Q1497', 'entityType': 'entity', 'la...</td>\n",
       "      <td>[{'name': 'Q7245', 'label': 'Mark Twain'}]</td>\n",
       "      <td>[Edgar Allan Poe, Ernest Hemingway, Charles Di...</td>\n",
       "      <td>[-0.2734780908, -0.3756849766, -0.418252229700...</td>\n",
       "      <td>[Q16867, Q23434, Q5686, Q131149, Q34597, Q3616...</td>\n",
       "      <td>Q5</td>\n",
       "      <td>[Q16867, Q23434, Q5686, Q131149, Q34597, Q3616...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bc8713cc</td>\n",
       "      <td>en</td>\n",
       "      <td>How many Academy Awards has Jake Gyllenhaal be...</td>\n",
       "      <td>1</td>\n",
       "      <td>movies</td>\n",
       "      <td>count</td>\n",
       "      <td>[{'name': 'Q133313', 'entityType': 'entity', '...</td>\n",
       "      <td>[{'name': 'Q106291', 'label': 'Academy Award f...</td>\n",
       "      <td>[1, 2, 3, 4, 5, 11, 6, 0, 8, 7, 9, 10, 13, 12,...</td>\n",
       "      <td>[-0.6568749547, -0.7941160798, -0.851152122, -...</td>\n",
       "      <td>[1, 2, 3, 4, 5, 11, 6, 0, 8, 7, 9, 10, 13, 12,...</td>\n",
       "      <td>Number</td>\n",
       "      <td>[1, 2, 3, 4, 5, 11, 6, 0, 8, 7, 9, 10, 13, 12,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>d2a03f72</td>\n",
       "      <td>en</td>\n",
       "      <td>Who is older, The Weeknd or Drake?</td>\n",
       "      <td>Drake</td>\n",
       "      <td>music</td>\n",
       "      <td>comparative</td>\n",
       "      <td>[{'name': 'Q2121062', 'entityType': 'entity', ...</td>\n",
       "      <td>[{'name': 'Q33240', 'label': 'Drake'}]</td>\n",
       "      <td>[Drake, The Weeknd, Cody Jarrett, Dwight D. Ei...</td>\n",
       "      <td>[-0.0174380932, -0.8993775845, -1.415274024, -...</td>\n",
       "      <td>[Q7559, Q2121062, Q5140439, Q9916, Q713099, Q5...</td>\n",
       "      <td>Q5</td>\n",
       "      <td>[Q2121062, Q5140439, Q9916, Q713099, Q513019, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9a296167</td>\n",
       "      <td>en</td>\n",
       "      <td>How many children did Donald Trump have?</td>\n",
       "      <td>5</td>\n",
       "      <td>history</td>\n",
       "      <td>count</td>\n",
       "      <td>[{'name': 'Q22686', 'entityType': 'entity', 'l...</td>\n",
       "      <td>[{'name': 'Q3713655', 'label': 'Donald Trump J...</td>\n",
       "      <td>[2, 3, 4, 5, 6, 1, 8, 9, 0, 7, 11, 10, 6 child...</td>\n",
       "      <td>[-0.49233829980000005, -1.0202715397, -1.06337...</td>\n",
       "      <td>[2, 3, 4, 5, 6, 1, 8, 9, 0, 7, 11, 10, Q348559...</td>\n",
       "      <td>Number</td>\n",
       "      <td>[2, 3, 4, 5, 6, 1, 8, 9, 0, 7, 11, 10, 13]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>e343ad26</td>\n",
       "      <td>en</td>\n",
       "      <td>Is the main hero in Final Fantasy IX named Kuja?</td>\n",
       "      <td>No</td>\n",
       "      <td>videogames</td>\n",
       "      <td>yesno</td>\n",
       "      <td>[{'name': 'Q474573', 'entityType': 'entity', '...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[Yes, No, Yuna, Yuna, Yuna, Yuna and Kuja are ...</td>\n",
       "      <td>[-0.3390540481, -0.3550684452, -1.4538880587, ...</td>\n",
       "      <td>[True, False, None, None, None, None, None, No...</td>\n",
       "      <td>yesno</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id lang                                           question   \n",
       "0  fae46b21   en  What man was a famous American author and also...  \\\n",
       "1  bc8713cc   en  How many Academy Awards has Jake Gyllenhaal be...   \n",
       "2  d2a03f72   en                 Who is older, The Weeknd or Drake?   \n",
       "3  9a296167   en           How many children did Donald Trump have?   \n",
       "4  e343ad26   en   Is the main hero in Final Fantasy IX named Kuja?   \n",
       "\n",
       "   answerText    category complexityType   \n",
       "0  Mark Twain     history   intersection  \\\n",
       "1           1      movies          count   \n",
       "2       Drake       music    comparative   \n",
       "3           5     history          count   \n",
       "4          No  videogames          yesno   \n",
       "\n",
       "                                      questionEntity   \n",
       "0  [{'name': 'Q1497', 'entityType': 'entity', 'la...  \\\n",
       "1  [{'name': 'Q133313', 'entityType': 'entity', '...   \n",
       "2  [{'name': 'Q2121062', 'entityType': 'entity', ...   \n",
       "3  [{'name': 'Q22686', 'entityType': 'entity', 'l...   \n",
       "4  [{'name': 'Q474573', 'entityType': 'entity', '...   \n",
       "\n",
       "                                        answerEntity   \n",
       "0         [{'name': 'Q7245', 'label': 'Mark Twain'}]  \\\n",
       "1  [{'name': 'Q106291', 'label': 'Academy Award f...   \n",
       "2             [{'name': 'Q33240', 'label': 'Drake'}]   \n",
       "3  [{'name': 'Q3713655', 'label': 'Donald Trump J...   \n",
       "4                                                 []   \n",
       "\n",
       "                                      generated_text   \n",
       "0  [Edgar Allan Poe, Ernest Hemingway, Charles Di...  \\\n",
       "1  [1, 2, 3, 4, 5, 11, 6, 0, 8, 7, 9, 10, 13, 12,...   \n",
       "2  [Drake, The Weeknd, Cody Jarrett, Dwight D. Ei...   \n",
       "3  [2, 3, 4, 5, 6, 1, 8, 9, 0, 7, 11, 10, 6 child...   \n",
       "4  [Yes, No, Yuna, Yuna, Yuna, Yuna and Kuja are ...   \n",
       "\n",
       "                                    sequences_scores   \n",
       "0  [-0.2734780908, -0.3756849766, -0.418252229700...  \\\n",
       "1  [-0.6568749547, -0.7941160798, -0.851152122, -...   \n",
       "2  [-0.0174380932, -0.8993775845, -1.415274024, -...   \n",
       "3  [-0.49233829980000005, -1.0202715397, -1.06337...   \n",
       "4  [-0.3390540481, -0.3550684452, -1.4538880587, ...   \n",
       "\n",
       "                                  generated_entities answerRetrievedType   \n",
       "0  [Q16867, Q23434, Q5686, Q131149, Q34597, Q3616...                  Q5  \\\n",
       "1  [1, 2, 3, 4, 5, 11, 6, 0, 8, 7, 9, 10, 13, 12,...              Number   \n",
       "2  [Q7559, Q2121062, Q5140439, Q9916, Q713099, Q5...                  Q5   \n",
       "3  [2, 3, 4, 5, 6, 1, 8, 9, 0, 7, 11, 10, Q348559...              Number   \n",
       "4  [True, False, None, None, None, None, None, No...               yesno   \n",
       "\n",
       "                              filtered_by_type_preds  \n",
       "0  [Q16867, Q23434, Q5686, Q131149, Q34597, Q3616...  \n",
       "1  [1, 2, 3, 4, 5, 11, 6, 0, 8, 7, 9, 10, 13, 12,...  \n",
       "2  [Q2121062, Q5140439, Q9916, Q713099, Q513019, ...  \n",
       "3         [2, 3, 4, 5, 6, 1, 8, 9, 0, 7, 11, 10, 13]  \n",
       "4                                                 []  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = pd.read_json('test_beam_search_preds_mintaka_with_types.json')\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "answerRetrievedType\n",
       "Q5          1008\n",
       "Number       820\n",
       "yesno        544\n",
       "Q11424       244\n",
       "Q7889        185\n",
       "Q3624078      87\n",
       "Q35657        79\n",
       "Q482994       69\n",
       "Q7725634      65\n",
       "Q1093829      52\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df['answerRetrievedType'].value_counts().head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rerank_candidates_by_biggraph(candidates, question_entities):\n",
    "    if len(candidates) <= 0:\n",
    "        return []\n",
    "\n",
    "    scores = []\n",
    "    for candidate_id in candidates:\n",
    "        vecid = biggraph_name2id.get(candidate_id)\n",
    "        dot_product_score = 0\n",
    "        if vecid is not None:\n",
    "            for question_entity in question_entities:\n",
    "                if question_entity['entityType'] != 'entity':\n",
    "                    continue\n",
    "                question_entity_id = question_entity['name']\n",
    "                qvecid = biggraph_name2id.get(question_entity_id)\n",
    "\n",
    "                if qvecid is not None:\n",
    "                    dot_product_score += np.dot(\n",
    "                        biggraph_vectors[vecid],\n",
    "                        biggraph_vectors[qvecid],\n",
    "                    )\n",
    "        scores.append(dot_product_score)\n",
    "\n",
    "    return np.array(candidates)[np.argsort(scores)[::-1]].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No config specified, defaulting to: mintaka/en\n",
      "Found cached dataset mintaka (/root/.cache/huggingface/datasets/AmazonScience___mintaka/en/1.0.0/bb35d95f07aed78fa590601245009c5f585efe909dbd4a8f2a4025ccf65bb11d)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "afd72c75d17f4e2ca8666125d0159ec8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset_split = 'test'\n",
    "dataset = datasets.load_dataset('AmazonScience/mintaka')\n",
    "\n",
    "def print_eval(generated_answers=None, mode='kg', df=None, groupbycols=['complexityType']):\n",
    "    if df is None:\n",
    "        if not isinstance(generated_answers, dict):\n",
    "            answers = dict(zip(dataset[dataset_split]['id'], generated_answers))\n",
    "        else:\n",
    "            answers = generated_answers\n",
    "\n",
    "        results_kg = evaluate_mintaka(\n",
    "            predictions=answers,\n",
    "            split=dataset_split,\n",
    "            mode=mode,\n",
    "        )\n",
    "    else:\n",
    "        results_kg = evaluate_mintaka(\n",
    "            df_with_predictions=df,\n",
    "            split=dataset_split,\n",
    "            mode=mode,\n",
    "            groupbycols=groupbycols,\n",
    "        )\n",
    "    \n",
    "    if 'answerRetrievedType' in results_kg:\n",
    "        items = sorted(\n",
    "            results_kg['answerRetrievedType'].items(),\n",
    "            key=lambda item: -item[1]['hits1 Number Correct Answer Of'][1]\n",
    "        )[:10]\n",
    "        # items = [(f\"{key} ({Entity(key).label if 'Q' in key[:1] else ''})\", val) for key, val in items]\n",
    "        results_kg['answerRetrievedType'] = dict(items)\n",
    "\n",
    "    print(f\"{'Group':13s}  {'Hits@1':6s} (Correct Of Total)\")\n",
    "    print(f\"{'All':13s}= {results_kg['All']['hits1']:2.4f} ({results_kg['All']['hits1 Number Correct Answer Of'][0]:4d} Of {results_kg['All']['hits1 Number Correct Answer Of'][1]:4d})\", end='\\n\\n')\n",
    "    for key in results_kg.keys():\n",
    "        if 'All' == key:\n",
    "            continue\n",
    "\n",
    "        for key, val in results_kg[key].items():\n",
    "            print(f\"{key:13s}= {val['hits1']:2.4f} ({val['hits1 Number Correct Answer Of'][0]:4d} Of {val['hits1 Number Correct Answer Of'][1]:4d})\")\n",
    "        print('')\n",
    "    return results_kg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f14394ee0df84b39a716cfc6a9bb55aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Group          Hits@1 (Correct Of Total)\n",
      "All          = 0.1757 ( 703 Of 4000)\n",
      "\n",
      "comparative  = 0.4500 ( 180 Of  400)\n",
      "count        = 0.0225 (   9 Of  400)\n",
      "difference   = 0.1175 (  47 Of  400)\n",
      "generic      = 0.1300 ( 104 Of  800)\n",
      "intersection = 0.1900 (  76 Of  400)\n",
      "multihop     = 0.0525 (  21 Of  400)\n",
      "ordinal      = 0.0550 (  22 Of  400)\n",
      "superlative  = 0.1300 (  52 Of  400)\n",
      "yesno        = 0.4800 ( 192 Of  400)\n",
      "\n",
      "Q5           = 0.1915 ( 193 Of 1008)\n",
      "Number       = 0.0341 (  28 Of  820)\n",
      "yesno        = 0.4651 ( 253 Of  544)\n",
      "Q11424       = 0.1066 (  26 Of  244)\n",
      "Q7889        = 0.0865 (  16 Of  185)\n",
      "Q3624078     = 0.2299 (  20 Of   87)\n",
      "Q35657       = 0.2532 (  20 Of   79)\n",
      "Q482994      = 0.0145 (   1 Of   69)\n",
      "Q7725634     = 0.0615 (   4 Of   65)\n",
      "Q1093829     = 0.2692 (  14 Of   52)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_df['isAnswerEntity'] = test_df['answerEntity'].apply(lambda entities: len(entities) > 0)\n",
    "\n",
    "preds = test_df.progress_apply(\n",
    "    lambda row: rerank_candidates_by_biggraph(row['generated_entities'], row['questionEntity'])[0] if row['isAnswerEntity'] else row['generated_entities'][0],\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "df = calculate_metrics_for_prediction(\n",
    "    dict(zip(dataset[dataset_split]['id'], preds)),\n",
    "    dataset_split,\n",
    "    'kg',\n",
    ")\n",
    "df['answerRetrievedType'] = test_df['answerRetrievedType']\n",
    "results_kg = print_eval(df=df, groupbycols=['complexityType', 'answerRetrievedType'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20bfb5976512476bb657702863727232",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Group          Hits@1 (Correct Of Total)\n",
      "All          = 0.1872 ( 749 Of 4000)\n",
      "\n",
      "comparative  = 0.4250 ( 170 Of  400)\n",
      "count        = 0.0350 (  14 Of  400)\n",
      "difference   = 0.1200 (  48 Of  400)\n",
      "generic      = 0.1525 ( 122 Of  800)\n",
      "intersection = 0.1950 (  78 Of  400)\n",
      "multihop     = 0.0600 (  24 Of  400)\n",
      "ordinal      = 0.0825 (  33 Of  400)\n",
      "superlative  = 0.1700 (  68 Of  400)\n",
      "yesno        = 0.4800 ( 192 Of  400)\n",
      "\n",
      "Q5           = 0.1974 ( 199 Of 1008)\n",
      "Number       = 0.0402 (  33 Of  820)\n",
      "yesno        = 0.4651 ( 253 Of  544)\n",
      "Q11424       = 0.1025 (  25 Of  244)\n",
      "Q7889        = 0.1297 (  24 Of  185)\n",
      "Q3624078     = 0.2759 (  24 Of   87)\n",
      "Q35657       = 0.3165 (  25 Of   79)\n",
      "Q482994      = 0.0580 (   4 Of   69)\n",
      "Q7725634     = 0.0923 (   6 Of   65)\n",
      "Q1093829     = 0.2308 (  12 Of   52)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "preds = test_df.progress_apply(\n",
    "    lambda row: rerank_candidates_by_biggraph(row['filtered_by_type_preds'], row['questionEntity'])[0] if row['isAnswerEntity'] else row['generated_entities'][0],\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "df = calculate_metrics_for_prediction(\n",
    "    dict(zip(dataset[dataset_split]['id'], preds)),\n",
    "    dataset_split,\n",
    "    'kg',\n",
    ")\n",
    "df['answerRetrievedType'] = test_df['answerRetrievedType']\n",
    "results_kg = print_eval(df=df, groupbycols=['complexityType', 'answerRetrievedType'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
