{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Working on tasks \n",
    "* https://www.notion.so/msalnikov/b0b68b3db11b4c40a4bada127bfde310?v=635216a0f3d646d58fde31f60cc9e4c9&p=82caba2f68c94f4ea320134e855e7bb4&pm=c\n",
    "* https://www.notion.so/msalnikov/b0b68b3db11b4c40a4bada127bfde310?v=635216a0f3d646d58fde31f60cc9e4c9&p=0cb24ac3b2804a0798e08a3f3e0f0526&pm=c\n",
    "* https://www.notion.so/msalnikov/b0b68b3db11b4c40a4bada127bfde310?v=635216a0f3d646d58fde31f60cc9e4c9&p=4b768d2e96aa4a9a8cc6c8d12267976a&pm=c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers\n",
    "import datasets\n",
    "import requests\n",
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "from pywikidata import Entity\n",
    "from joblib import Memory\n",
    "import pandas as pd\n",
    "from tqdm.auto import tqdm\n",
    "from torch.utils.data import DataLoader\n",
    "import ujson\n",
    "import os\n",
    "\n",
    "from kbqa.seq2seq.utils import convert_to_features\n",
    "\n",
    "from typing import Union\n",
    "from collections import defaultdict, OrderedDict\n",
    "\n",
    "\n",
    "from evaluateqa.mintaka import evaluate as evaluate_mintaka\n",
    "from evaluateqa.mintaka import calculate_metrics_for_prediction\n",
    "from evaluateqa.mintaka.evaluate import normalize_and_tokenize_text\n",
    "\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['CUDA_VISIBLE_DEVICES'] = '1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(8)\n",
    "random.seed(8)\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = Memory('/tmp/cache', verbose=0)\n",
    "\n",
    "@memory.cache\n",
    "def get_wd_search_results(\n",
    "    search_string: str,\n",
    "    max_results: int = 500,\n",
    "    language: str = 'en',\n",
    "    mediawiki_api_url: str = \"https://www.wikidata.org/w/api.php\",\n",
    "    user_agent: str = None,\n",
    ") -> list:\n",
    "    params = {\n",
    "        'action': 'wbsearchentities',\n",
    "        'language': language,\n",
    "        'search': search_string,\n",
    "        'format': 'json',\n",
    "        'limit': 50\n",
    "    }\n",
    "\n",
    "    user_agent = \"pywikidata\" if user_agent is None else user_agent\n",
    "    headers = {\n",
    "        'User-Agent': user_agent\n",
    "    }\n",
    "\n",
    "    cont_count = 1\n",
    "    results = []\n",
    "    while cont_count > 0:\n",
    "        params.update({'continue': 0 if cont_count == 1 else cont_count})\n",
    "\n",
    "        reply = requests.get(mediawiki_api_url, params=params, headers=headers)\n",
    "        reply.raise_for_status()\n",
    "        search_results = reply.json()\n",
    "\n",
    "        if 'success' not in search_results or search_results['success'] != 1:\n",
    "            raise Exception('WD search failed')\n",
    "        else:\n",
    "            for i in search_results['search']:\n",
    "                results.append(i['id'])\n",
    "\n",
    "        if 'search-continue' not in search_results:\n",
    "            cont_count = 0\n",
    "        else:\n",
    "            cont_count = search_results['search-continue']\n",
    "\n",
    "        if cont_count > max_results:\n",
    "            break\n",
    "\n",
    "    return results"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset: MINTAKA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No config specified, defaulting to: mintaka/en\n",
      "Found cached dataset mintaka (/root/.cache/huggingface/datasets/AmazonScience___mintaka/en/1.0.0/bb35d95f07aed78fa590601245009c5f585efe909dbd4a8f2a4025ccf65bb11d)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb1a9879725c4393a41a1ca5f2bd2b2d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['id', 'lang', 'question', 'answerText', 'category', 'complexityType', 'questionEntity', 'answerEntity'],\n",
       "        num_rows: 14000\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['id', 'lang', 'question', 'answerText', 'category', 'complexityType', 'questionEntity', 'answerEntity'],\n",
       "        num_rows: 2000\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['id', 'lang', 'question', 'answerText', 'category', 'complexityType', 'questionEntity', 'answerEntity'],\n",
       "        num_rows: 4000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = datasets.load_dataset('AmazonScience/mintaka')\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>lang</th>\n",
       "      <th>question</th>\n",
       "      <th>answerText</th>\n",
       "      <th>category</th>\n",
       "      <th>complexityType</th>\n",
       "      <th>questionEntity</th>\n",
       "      <th>answerEntity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9ace9041</td>\n",
       "      <td>en</td>\n",
       "      <td>What is the fourth book in the Twilight series?</td>\n",
       "      <td>Breaking Dawn</td>\n",
       "      <td>books</td>\n",
       "      <td>ordinal</td>\n",
       "      <td>[{'name': 'Q44523', 'entityType': 'entity', 'l...</td>\n",
       "      <td>[{'name': 'Q53945', 'label': 'Breaking Dawn'}]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>88bdb808</td>\n",
       "      <td>en</td>\n",
       "      <td>How many games are in the Uncharted series?</td>\n",
       "      <td>6</td>\n",
       "      <td>videogames</td>\n",
       "      <td>count</td>\n",
       "      <td>[{'name': 'Q1064135', 'entityType': 'entity', ...</td>\n",
       "      <td>[{'name': 'Q17150', 'label': 'Uncharted: Drake...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ecfd471d</td>\n",
       "      <td>en</td>\n",
       "      <td>As of 2015, which group held the record for th...</td>\n",
       "      <td>U2</td>\n",
       "      <td>music</td>\n",
       "      <td>generic</td>\n",
       "      <td>[{'name': 'Q41254', 'entityType': 'entity', 'l...</td>\n",
       "      <td>[{'name': 'Q396', 'label': 'U2'}]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5d8dc3ff</td>\n",
       "      <td>en</td>\n",
       "      <td>Who is the oldest person to ever win an Academ...</td>\n",
       "      <td>James Ivory</td>\n",
       "      <td>movies</td>\n",
       "      <td>superlative</td>\n",
       "      <td>[{'name': 'Q19020', 'entityType': 'entity', 'l...</td>\n",
       "      <td>[{'name': 'Q51577', 'label': 'James Ivory'}]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>118daa85</td>\n",
       "      <td>en</td>\n",
       "      <td>Which Mario Kart games do not feature Link as ...</td>\n",
       "      <td>Super Mario Kart, Mario Kart 64, Mario Kart: S...</td>\n",
       "      <td>videogames</td>\n",
       "      <td>difference</td>\n",
       "      <td>[{'name': 'Q188196', 'entityType': 'entity', '...</td>\n",
       "      <td>[{'name': 'Q1061560', 'label': 'Super Mario Ka...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id lang                                           question   \n",
       "0  9ace9041   en    What is the fourth book in the Twilight series?  \\\n",
       "1  88bdb808   en        How many games are in the Uncharted series?   \n",
       "2  ecfd471d   en  As of 2015, which group held the record for th...   \n",
       "3  5d8dc3ff   en  Who is the oldest person to ever win an Academ...   \n",
       "4  118daa85   en  Which Mario Kart games do not feature Link as ...   \n",
       "\n",
       "                                          answerText    category   \n",
       "0                                      Breaking Dawn       books  \\\n",
       "1                                                  6  videogames   \n",
       "2                                                 U2       music   \n",
       "3                                        James Ivory      movies   \n",
       "4  Super Mario Kart, Mario Kart 64, Mario Kart: S...  videogames   \n",
       "\n",
       "  complexityType                                     questionEntity   \n",
       "0        ordinal  [{'name': 'Q44523', 'entityType': 'entity', 'l...  \\\n",
       "1          count  [{'name': 'Q1064135', 'entityType': 'entity', ...   \n",
       "2        generic  [{'name': 'Q41254', 'entityType': 'entity', 'l...   \n",
       "3    superlative  [{'name': 'Q19020', 'entityType': 'entity', 'l...   \n",
       "4     difference  [{'name': 'Q188196', 'entityType': 'entity', '...   \n",
       "\n",
       "                                        answerEntity  \n",
       "0     [{'name': 'Q53945', 'label': 'Breaking Dawn'}]  \n",
       "1  [{'name': 'Q17150', 'label': 'Uncharted: Drake...  \n",
       "2                  [{'name': 'Q396', 'label': 'U2'}]  \n",
       "3       [{'name': 'Q51577', 'label': 'James Ivory'}]  \n",
       "4  [{'name': 'Q1061560', 'label': 'Super Mario Ka...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['validation'].to_pandas().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['ordinal', 'intersection', 'generic', 'superlative', 'yesno',\n",
       "       'comparative', 'multihop', 'difference', 'count'], dtype=object)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['train'].to_pandas()['complexityType'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_checkpoint = 'google/t5-3b-ssm'\n",
    "# model_checkpoint = 'google/t5-large-ssm'\n",
    "model_checkpoint = '/mnt/storage/QA_System_Project/seq2seq_runs/mintaka_only_experiments_mintaka_tunned/model_t5_large_ssm_nq/models/checkpoint-7000/'\n",
    "device = torch.device('cuda')\n",
    "batch_size = 8\n",
    "dataset_split = 'test'\n",
    "\n",
    "model = transformers.AutoModelForSeq2SeqLM.from_pretrained(model_checkpoint).to(device)\n",
    "tokenizer = transformers.AutoTokenizer.from_pretrained(model_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /root/.cache/huggingface/datasets/AmazonScience___mintaka/en/1.0.0/bb35d95f07aed78fa590601245009c5f585efe909dbd4a8f2a4025ccf65bb11d/cache-d82ee0eb58e1802d.arrow\n",
      "Loading cached processed dataset at /root/.cache/huggingface/datasets/AmazonScience___mintaka/en/1.0.0/bb35d95f07aed78fa590601245009c5f585efe909dbd4a8f2a4025ccf65bb11d/cache-c8955b1d3baff169.arrow\n",
      "Loading cached processed dataset at /root/.cache/huggingface/datasets/AmazonScience___mintaka/en/1.0.0/bb35d95f07aed78fa590601245009c5f585efe909dbd4a8f2a4025ccf65bb11d/cache-66fb802b880b6e11.arrow\n"
     ]
    }
   ],
   "source": [
    "dataset = dataset.map(\n",
    "    lambda batch: convert_to_features(\n",
    "        batch, tokenizer, label_feature_name=\"answerText\"\n",
    "    ),\n",
    "    batched=True,\n",
    ")\n",
    "\n",
    "columns = [\n",
    "    \"input_ids\",\n",
    "    \"labels\",\n",
    "    \"attention_mask\",\n",
    "]\n",
    "dataset.set_format(type=\"torch\", columns=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AnswerItem():\n",
    "    def __init__(self, answer: Union[Entity, int, float, bool]):\n",
    "        if isinstance(answer, str):\n",
    "            self.answer = AnswerItem.text_to_answer(answer)\n",
    "        else:\n",
    "            self.answer = answer\n",
    "\n",
    "        self._type = None\n",
    "    \n",
    "    @property\n",
    "    def type(self):\n",
    "        if self._type is None:\n",
    "            self._type = AnswerItem.extract_answer_type(self.answer)\n",
    "        return self._type\n",
    "    \n",
    "    @classmethod\n",
    "    def extract_answer_type(cls, answer):\n",
    "        if isinstance(answer, bool):\n",
    "            return 'yesno'\n",
    "        elif isinstance(answer, str) and Entity._validate_entity_id(answer):\n",
    "            answer_entity = Entity(answer)\n",
    "            return answer_entity.instance_of + answer_entity.subclass_of\n",
    "        elif isinstance(answer, (int, float)):\n",
    "            return  'Number'\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "    @classmethod\n",
    "    def text_to_answer(cls, text): #text to answer that can be entity_id, Number or yesno\n",
    "        if text is None:\n",
    "            return None\n",
    "\n",
    "        if isinstance(text, str):\n",
    "            _text = text.replace('.', '')\n",
    "            if _text.lower() in ['yes', 'true']:\n",
    "                return True\n",
    "            elif _text.lower() in ['no', 'false']:\n",
    "                return False\n",
    "\n",
    "        try:\n",
    "            entity = float(text)\n",
    "            if int(entity) == entity:\n",
    "                entity = int(entity)\n",
    "        except:\n",
    "            results = get_wd_search_results(text.replace('.', ''), max_results=1)\n",
    "            if len(results) > 0:\n",
    "                entity = results[0]\n",
    "            else:\n",
    "                entity = None\n",
    "        return entity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 13\n",
    "torch.manual_seed(seed)\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "\n",
    "test_df = dataset['test'].to_pandas().drop(['input_ids', 'attention_mask', 'labels'], axis=1)\n",
    "\n",
    "generated_text = []\n",
    "generated_entities = []\n",
    "for row in tqdm(dataset['test']):\n",
    "    generated_ids = model.generate(\n",
    "        row[\"input_ids\"].view(1, -1).to(device),\n",
    "        num_beams=200,\n",
    "        num_return_sequences=200,\n",
    "        num_beam_groups=20,\n",
    "        diversity_penalty=-0.1,\n",
    "    )\n",
    "    generated_decoded_batch = tokenizer.batch_decode(\n",
    "        generated_ids,\n",
    "        skip_special_tokens=True,\n",
    "        clean_up_tokenization_spaces=False,\n",
    "    )\n",
    "    generated_text.append(list(dict.fromkeys(generated_decoded_batch).keys()))\n",
    "    generated_entities.append([\n",
    "        AnswerItem.text_to_answer(answer)\n",
    "        for answer in generated_text[-1]\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generated_entities_to_type(generated_entities):\n",
    "    types_freq = defaultdict(int)\n",
    "    for answer in generated_entities:\n",
    "        answer_item = AnswerItem(answer)\n",
    "        if isinstance(answer_item.type, list):\n",
    "            for answer_type in answer_item.type:\n",
    "                if isinstance(answer_type, str):\n",
    "                    answer_type_lbl = answer_type\n",
    "                else:\n",
    "                    answer_type_lbl = answer_type.idx\n",
    "                types_freq[answer_type_lbl] += 1\n",
    "        else:\n",
    "            types_freq[answer_item.type] += 1\n",
    "\n",
    "    answer_tetrieved_type = sorted(types_freq.items(), key=lambda item: -item[1])[0][0]\n",
    "    return answer_tetrieved_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_json('test_beam_search_preds_mintaka_with_types.json')\n",
    "\n",
    "generated_kg_answers = test_df['generated_entities'].apply(lambda lst: lst[0]).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_eval(generated_answers=None, mode='kg', df=None, groupbycols=['complexityType']):\n",
    "    if df is None:\n",
    "        if not isinstance(generated_answers, dict):\n",
    "            answers = dict(zip(dataset[dataset_split]['id'], generated_answers))\n",
    "        else:\n",
    "            answers = generated_answers\n",
    "\n",
    "        results_kg = evaluate_mintaka(\n",
    "            predictions=answers,\n",
    "            split=dataset_split,\n",
    "            mode=mode,\n",
    "        )\n",
    "    else:\n",
    "        results_kg = evaluate_mintaka(\n",
    "            df_with_predictions=df,\n",
    "            split=dataset_split,\n",
    "            mode=mode,\n",
    "            groupbycols=groupbycols,\n",
    "        )\n",
    "    \n",
    "    if 'answerRetrievedType' in results_kg:\n",
    "        items = sorted(\n",
    "            results_kg['answerRetrievedType'].items(),\n",
    "            key=lambda item: -item[1]['hits1 Number Correct Answer Of'][1]\n",
    "        )[:10]\n",
    "        # items = [(f\"{key} ({Entity(key).label if 'Q' in key[:1] else ''})\", val) for key, val in items]\n",
    "        results_kg['answerRetrievedType'] = dict(items)\n",
    "\n",
    "    print(f\"{'Group':13s}  {'Hits@1':6s} (Correct Of Total)\")\n",
    "    print(f\"{'All':13s}= {results_kg['All']['hits1']:2.4f} ({results_kg['All']['hits1 Number Correct Answer Of'][0]:4d} Of {results_kg['All']['hits1 Number Correct Answer Of'][1]:4d})\", end='\\n\\n')\n",
    "    for key in results_kg.keys():\n",
    "        if 'All' == key:\n",
    "            continue\n",
    "\n",
    "        for key, val in results_kg[key].items():\n",
    "            print(f\"{key:13s}= {val['hits1']:2.4f} ({val['hits1 Number Correct Answer Of'][0]:4d} Of {val['hits1 Number Correct Answer Of'][1]:4d})\")\n",
    "        print('')\n",
    "    return results_kg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Group          Hits@1 (Correct Of Total)\n",
      "All          = 0.2740 (1096 Of 4000)\n",
      "\n",
      "comparative  = 0.4575 ( 183 Of  400)\n",
      "count        = 0.2700 ( 108 Of  400)\n",
      "difference   = 0.1725 (  69 Of  400)\n",
      "generic      = 0.2075 ( 166 Of  800)\n",
      "intersection = 0.2900 ( 116 Of  400)\n",
      "multihop     = 0.1025 (  41 Of  400)\n",
      "ordinal      = 0.1600 (  64 Of  400)\n",
      "superlative  = 0.3925 ( 157 Of  400)\n",
      "yesno        = 0.4800 ( 192 Of  400)\n",
      "\n",
      "Q5           = 0.3214 ( 324 Of 1008)\n",
      "Number       = 0.1549 ( 127 Of  820)\n",
      "yesno        = 0.4651 ( 253 Of  544)\n",
      "Q11424       = 0.1475 (  36 Of  244)\n",
      "Q7889        = 0.2703 (  50 Of  185)\n",
      "Q3624078     = 0.3793 (  33 Of   87)\n",
      "Q35657       = 0.3671 (  29 Of   79)\n",
      "Q482994      = 0.0725 (   5 Of   69)\n",
      "Q7725634     = 0.1692 (  11 Of   65)\n",
      "Q1093829     = 0.3462 (  18 Of   52)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = calculate_metrics_for_prediction(\n",
    "    dict(zip(dataset[dataset_split]['id'], generated_kg_answers)),\n",
    "    dataset_split,\n",
    "    'kg',\n",
    ")\n",
    "df['answerRetrievedType'] = test_df['answerRetrievedType']\n",
    "results_kg = print_eval(df=df, groupbycols=['complexityType', 'answerRetrievedType'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93458cd6dfbb4e899b65ec5458b01a59",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.77575"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_answers_type(answers: list) -> set:\n",
    "    final_type = []\n",
    "    for pred in answers:\n",
    "        pred_type = AnswerItem(pred).type\n",
    "        if isinstance(pred_type, list):\n",
    "            final_type.extend(pred_type)\n",
    "        else:\n",
    "            final_type.append(pred_type)\n",
    "    return final_type\n",
    "\n",
    "def is_type_matched(row):\n",
    "    if row['answer'] is not None and isinstance(row['answer'], list):\n",
    "        answer_types = set(get_answers_type(row['answer']))\n",
    "    else:\n",
    "        answer_types = set()\n",
    "\n",
    "    if row['pred'] is not None and isinstance(row['pred'], list):\n",
    "        pred_types   = set(get_answers_type(row['pred']))\n",
    "    else:\n",
    "        pred_types = set()\n",
    "\n",
    "    return len(answer_types.intersection(pred_types)) > 0\n",
    "\n",
    "df['type_match'] = df.progress_apply(is_type_matched, axis=1)\n",
    "df['type_match'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proportion of errors with incorrect type                = 0.3033746556473829\n",
      "\n",
      "Proportion of errors with incorrect type (comparative ) = 0.2304147465437788\n",
      "Proportion of errors with incorrect type (count       ) = 0.010273972602739725\n",
      "Proportion of errors with incorrect type (difference  ) = 0.4984894259818731\n",
      "Proportion of errors with incorrect type (generic     ) = 0.3911671924290221\n",
      "Proportion of errors with incorrect type (intersection) = 0.23943661971830985\n",
      "Proportion of errors with incorrect type (multihop    ) = 0.4011142061281337\n",
      "Proportion of errors with incorrect type (ordinal     ) = 0.3125\n",
      "Proportion of errors with incorrect type (superlative ) = 0.3991769547325103\n",
      "Proportion of errors with incorrect type (yesno       ) = 0.004807692307692308\n",
      "\n",
      "Proportion of errors with incorrect type (books       ) = 0.39655172413793105\n",
      "Proportion of errors with incorrect type (geography   ) = 0.3911671924290221\n",
      "Proportion of errors with incorrect type (history     ) = 0.26851851851851855\n",
      "Proportion of errors with incorrect type (movies      ) = 0.2825\n",
      "Proportion of errors with incorrect type (music       ) = 0.36658354114713215\n",
      "Proportion of errors with incorrect type (politics    ) = 0.19692307692307692\n",
      "Proportion of errors with incorrect type (sports      ) = 0.13802816901408452\n",
      "Proportion of errors with incorrect type (videogames  ) = 0.3617021276595745\n"
     ]
    }
   ],
   "source": [
    "df['is_hit'] = df['hits1'].astype(bool)\n",
    "\n",
    "print(\n",
    "    'Proportion of errors with incorrect type                =',\n",
    "    df[(~df['type_match']) & (~df['is_hit'])].index.size / df[~df['is_hit']].index.size,\n",
    "    end='\\n\\n'\n",
    ")\n",
    "\n",
    "for complexity_type, group in df.groupby('complexityType'):\n",
    "    print(\n",
    "        f'Proportion of errors with incorrect type ({complexity_type:12s}) =',\n",
    "        group[(~group['type_match']) & (~group['is_hit'])].index.size / group[~group['is_hit']].index.size\n",
    "    )\n",
    "\n",
    "print('')\n",
    "for category, group in df.groupby('category'):\n",
    "    print(\n",
    "        f'Proportion of errors with incorrect type ({category:12s}) =',\n",
    "        group[(~group['type_match']) & (~group['is_hit'])].index.size / group[~group['is_hit']].index.size\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_answer_type_from_candidates(answers, return_types_count=False):\n",
    "    types_count = defaultdict(int)\n",
    "    for answer in answers:\n",
    "        answer_type = AnswerItem(answer).type\n",
    "        if isinstance(answer_type, list):\n",
    "            for entity in answer_type:\n",
    "                types_count[entity] += 1\n",
    "        else:\n",
    "            types_count[answer_type] += 1\n",
    "    \n",
    "    if len(types_count) == 0:\n",
    "        return None\n",
    "\n",
    "    sorted_types_count = sorted(types_count.items(), key=lambda x: -x[1])\n",
    "    final_type = sorted_types_count[0][0]\n",
    "    if final_type is None and len(sorted_types_count) > 1:\n",
    "        final_type = sorted_types_count[1][0]\n",
    "\n",
    "    if isinstance(final_type, Entity):\n",
    "        final_type = final_type.idx\n",
    "    \n",
    "    if return_types_count:\n",
    "        return final_type, OrderedDict(sorted_types_count)\n",
    "    else:\n",
    "        return final_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>lang</th>\n",
       "      <th>question</th>\n",
       "      <th>answerText</th>\n",
       "      <th>category</th>\n",
       "      <th>complexityType</th>\n",
       "      <th>questionEntity</th>\n",
       "      <th>answerEntity</th>\n",
       "      <th>generated_text</th>\n",
       "      <th>sequences_scores</th>\n",
       "      <th>generated_entities</th>\n",
       "      <th>answerRetrievedType</th>\n",
       "      <th>filtered_by_type_preds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>fae46b21</td>\n",
       "      <td>en</td>\n",
       "      <td>What man was a famous American author and also...</td>\n",
       "      <td>Mark Twain</td>\n",
       "      <td>history</td>\n",
       "      <td>intersection</td>\n",
       "      <td>[{'name': 'Q1497', 'entityType': 'entity', 'la...</td>\n",
       "      <td>[{'name': 'Q7245', 'label': 'Mark Twain'}]</td>\n",
       "      <td>[Edgar Allan Poe, Ernest Hemingway, Charles Di...</td>\n",
       "      <td>[-0.2734780908, -0.3756849766, -0.418252229700...</td>\n",
       "      <td>[Q16867, Q23434, Q5686, Q131149, Q34597, Q3616...</td>\n",
       "      <td>Q5</td>\n",
       "      <td>[Q16867, Q23434, Q5686, Q131149, Q34597, Q3616...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bc8713cc</td>\n",
       "      <td>en</td>\n",
       "      <td>How many Academy Awards has Jake Gyllenhaal be...</td>\n",
       "      <td>1</td>\n",
       "      <td>movies</td>\n",
       "      <td>count</td>\n",
       "      <td>[{'name': 'Q133313', 'entityType': 'entity', '...</td>\n",
       "      <td>[{'name': 'Q106291', 'label': 'Academy Award f...</td>\n",
       "      <td>[1, 2, 3, 4, 5, 11, 6, 0, 8, 7, 9, 10, 13, 12,...</td>\n",
       "      <td>[-0.6568749547, -0.7941160798, -0.851152122, -...</td>\n",
       "      <td>[1, 2, 3, 4, 5, 11, 6, 0, 8, 7, 9, 10, 13, 12,...</td>\n",
       "      <td>Number</td>\n",
       "      <td>[1, 2, 3, 4, 5, 11, 6, 0, 8, 7, 9, 10, 13, 12,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>d2a03f72</td>\n",
       "      <td>en</td>\n",
       "      <td>Who is older, The Weeknd or Drake?</td>\n",
       "      <td>Drake</td>\n",
       "      <td>music</td>\n",
       "      <td>comparative</td>\n",
       "      <td>[{'name': 'Q2121062', 'entityType': 'entity', ...</td>\n",
       "      <td>[{'name': 'Q33240', 'label': 'Drake'}]</td>\n",
       "      <td>[Drake, The Weeknd, Cody Jarrett, Dwight D. Ei...</td>\n",
       "      <td>[-0.0174380932, -0.8993775845, -1.415274024, -...</td>\n",
       "      <td>[Q7559, Q2121062, Q5140439, Q9916, Q713099, Q5...</td>\n",
       "      <td>Q5</td>\n",
       "      <td>[Q2121062, Q5140439, Q9916, Q713099, Q513019, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9a296167</td>\n",
       "      <td>en</td>\n",
       "      <td>How many children did Donald Trump have?</td>\n",
       "      <td>5</td>\n",
       "      <td>history</td>\n",
       "      <td>count</td>\n",
       "      <td>[{'name': 'Q22686', 'entityType': 'entity', 'l...</td>\n",
       "      <td>[{'name': 'Q3713655', 'label': 'Donald Trump J...</td>\n",
       "      <td>[2, 3, 4, 5, 6, 1, 8, 9, 0, 7, 11, 10, 6 child...</td>\n",
       "      <td>[-0.49233829980000005, -1.0202715397, -1.06337...</td>\n",
       "      <td>[2, 3, 4, 5, 6, 1, 8, 9, 0, 7, 11, 10, Q348559...</td>\n",
       "      <td>Number</td>\n",
       "      <td>[2, 3, 4, 5, 6, 1, 8, 9, 0, 7, 11, 10, 13]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>e343ad26</td>\n",
       "      <td>en</td>\n",
       "      <td>Is the main hero in Final Fantasy IX named Kuja?</td>\n",
       "      <td>No</td>\n",
       "      <td>videogames</td>\n",
       "      <td>yesno</td>\n",
       "      <td>[{'name': 'Q474573', 'entityType': 'entity', '...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[Yes, No, Yuna, Yuna, Yuna, Yuna and Kuja are ...</td>\n",
       "      <td>[-0.3390540481, -0.3550684452, -1.4538880587, ...</td>\n",
       "      <td>[True, False, None, None, None, None, None, No...</td>\n",
       "      <td>yesno</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id lang                                           question   \n",
       "0  fae46b21   en  What man was a famous American author and also...  \\\n",
       "1  bc8713cc   en  How many Academy Awards has Jake Gyllenhaal be...   \n",
       "2  d2a03f72   en                 Who is older, The Weeknd or Drake?   \n",
       "3  9a296167   en           How many children did Donald Trump have?   \n",
       "4  e343ad26   en   Is the main hero in Final Fantasy IX named Kuja?   \n",
       "\n",
       "   answerText    category complexityType   \n",
       "0  Mark Twain     history   intersection  \\\n",
       "1           1      movies          count   \n",
       "2       Drake       music    comparative   \n",
       "3           5     history          count   \n",
       "4          No  videogames          yesno   \n",
       "\n",
       "                                      questionEntity   \n",
       "0  [{'name': 'Q1497', 'entityType': 'entity', 'la...  \\\n",
       "1  [{'name': 'Q133313', 'entityType': 'entity', '...   \n",
       "2  [{'name': 'Q2121062', 'entityType': 'entity', ...   \n",
       "3  [{'name': 'Q22686', 'entityType': 'entity', 'l...   \n",
       "4  [{'name': 'Q474573', 'entityType': 'entity', '...   \n",
       "\n",
       "                                        answerEntity   \n",
       "0         [{'name': 'Q7245', 'label': 'Mark Twain'}]  \\\n",
       "1  [{'name': 'Q106291', 'label': 'Academy Award f...   \n",
       "2             [{'name': 'Q33240', 'label': 'Drake'}]   \n",
       "3  [{'name': 'Q3713655', 'label': 'Donald Trump J...   \n",
       "4                                                 []   \n",
       "\n",
       "                                      generated_text   \n",
       "0  [Edgar Allan Poe, Ernest Hemingway, Charles Di...  \\\n",
       "1  [1, 2, 3, 4, 5, 11, 6, 0, 8, 7, 9, 10, 13, 12,...   \n",
       "2  [Drake, The Weeknd, Cody Jarrett, Dwight D. Ei...   \n",
       "3  [2, 3, 4, 5, 6, 1, 8, 9, 0, 7, 11, 10, 6 child...   \n",
       "4  [Yes, No, Yuna, Yuna, Yuna, Yuna and Kuja are ...   \n",
       "\n",
       "                                    sequences_scores   \n",
       "0  [-0.2734780908, -0.3756849766, -0.418252229700...  \\\n",
       "1  [-0.6568749547, -0.7941160798, -0.851152122, -...   \n",
       "2  [-0.0174380932, -0.8993775845, -1.415274024, -...   \n",
       "3  [-0.49233829980000005, -1.0202715397, -1.06337...   \n",
       "4  [-0.3390540481, -0.3550684452, -1.4538880587, ...   \n",
       "\n",
       "                                  generated_entities answerRetrievedType   \n",
       "0  [Q16867, Q23434, Q5686, Q131149, Q34597, Q3616...                  Q5  \\\n",
       "1  [1, 2, 3, 4, 5, 11, 6, 0, 8, 7, 9, 10, 13, 12,...              Number   \n",
       "2  [Q7559, Q2121062, Q5140439, Q9916, Q713099, Q5...                  Q5   \n",
       "3  [2, 3, 4, 5, 6, 1, 8, 9, 0, 7, 11, 10, Q348559...              Number   \n",
       "4  [True, False, None, None, None, None, None, No...               yesno   \n",
       "\n",
       "                              filtered_by_type_preds  \n",
       "0  [Q16867, Q23434, Q5686, Q131149, Q34597, Q3616...  \n",
       "1  [1, 2, 3, 4, 5, 11, 6, 0, 8, 7, 9, 10, 13, 12,...  \n",
       "2  [Q2121062, Q5140439, Q9916, Q713099, Q513019, ...  \n",
       "3         [2, 3, 4, 5, 6, 1, 8, 9, 0, 7, 11, 10, 13]  \n",
       "4                                                 []  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = pd.read_json('test_beam_search_preds_mintaka_with_types.json')\n",
    "\n",
    "# test_df['answerRetrievedType'] = test_df['generated_entities'].progress_apply(retrieve_answer_type_from_candidates)\n",
    "# test_df.to_json('test_beam_search_preds_mintaka_with_types.json')\n",
    "\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ACT Selection (from prev paper)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35cfef00bb074c65a4af173d7a89336e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Group          Hits@1 (Correct Of Total)\n",
      "All          = 0.1615 ( 646 Of 4000)\n",
      "\n",
      "comparative  = 0.1500 (  60 Of  400)\n",
      "count        = 0.1750 (  70 Of  400)\n",
      "difference   = 0.1325 (  53 Of  400)\n",
      "generic      = 0.1787 ( 143 Of  800)\n",
      "intersection = 0.2450 (  98 Of  400)\n",
      "multihop     = 0.0300 (  12 Of  400)\n",
      "ordinal      = 0.0850 (  34 Of  400)\n",
      "superlative  = 0.2025 (  81 Of  400)\n",
      "yesno        = 0.2375 (  95 Of  400)\n",
      "\n",
      "Q5           = 0.1518 ( 153 Of 1008)\n",
      "Number       = 0.1024 (  84 Of  820)\n",
      "yesno        = 0.2408 ( 131 Of  544)\n",
      "Q11424       = 0.1311 (  32 Of  244)\n",
      "Q7889        = 0.1892 (  35 Of  185)\n",
      "Q3624078     = 0.2644 (  23 Of   87)\n",
      "Q35657       = 0.2532 (  20 Of   79)\n",
      "Q482994      = 0.0000 (   0 Of   69)\n",
      "Q7725634     = 0.1692 (  11 Of   65)\n",
      "Q1093829     = 0.1923 (  10 Of   52)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from kbqa.candidate_selection.question_to_rank_by_instance_of import QuestionToRankInstanceOf\n",
    "\n",
    "\n",
    "reranked_preds = []\n",
    "for _, row in tqdm(test_df.iterrows(), total=test_df.index.size):\n",
    "    answers_candidates = [e for e in row['generated_entities'] if e is not None and isinstance(e, str) and 'Q' == e[0]]\n",
    "    if len(answers_candidates) == 0:\n",
    "        reranked_answer = row['generated_entities'][0]\n",
    "    else:\n",
    "        reranked_answer = QuestionToRankInstanceOf(\n",
    "            question=row['question'],\n",
    "            question_entities=[e['name'] for e in row['questionEntity'] if e['entityType'] == 'entity' and 'Q' == e['name'][0]],\n",
    "            answers_candidates=answers_candidates,\n",
    "            only_forward_one_hop=True,\n",
    "        ).final_answers()[0][1].idx\n",
    "\n",
    "    reranked_preds.append(reranked_answer)\n",
    "\n",
    "\n",
    "df = calculate_metrics_for_prediction(\n",
    "    dict(zip(dataset[dataset_split]['id'], reranked_preds)),\n",
    "    dataset_split,\n",
    "    'kg',\n",
    ")\n",
    "df['answerRetrievedType'] = test_df['answerRetrievedType']\n",
    "results_kg = print_eval(df=df, groupbycols=['complexityType', 'answerRetrievedType'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtered by type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea8fa2b0416a40acb66d8796c8926684",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Group          Hits@1 (Correct Of Total)\n",
      "All          = 0.2675 (1070 Of 4000)\n",
      "\n",
      "comparative  = 0.4550 ( 182 Of  400)\n",
      "count        = 0.2725 ( 109 Of  400)\n",
      "difference   = 0.1975 (  79 Of  400)\n",
      "generic      = 0.1925 ( 154 Of  800)\n",
      "intersection = 0.2825 ( 113 Of  400)\n",
      "multihop     = 0.1050 (  42 Of  400)\n",
      "ordinal      = 0.1525 (  61 Of  400)\n",
      "superlative  = 0.3800 ( 152 Of  400)\n",
      "yesno        = 0.4450 ( 178 Of  400)\n",
      "\n",
      "Q5           = 0.3145 ( 317 Of 1008)\n",
      "Number       = 0.1573 ( 129 Of  820)\n",
      "yesno        = 0.4651 ( 253 Of  544)\n",
      "Q11424       = 0.1066 (  26 Of  244)\n",
      "Q7889        = 0.2486 (  46 Of  185)\n",
      "Q3624078     = 0.4368 (  38 Of   87)\n",
      "Q35657       = 0.3924 (  31 Of   79)\n",
      "Q482994      = 0.1304 (   9 Of   69)\n",
      "Q7725634     = 0.1692 (  11 Of   65)\n",
      "Q1093829     = 0.2692 (  14 Of   52)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def filter_generated_answers_by_type(generated_entities, answer_retrieved_type):\n",
    "    for _answer in generated_entities:\n",
    "        answer = AnswerItem(_answer)\n",
    "        if isinstance(answer.type, list) and answer_retrieved_type in [e.idx for e in answer.type]:\n",
    "                yield _answer\n",
    "        else:\n",
    "            if answer.type == answer_retrieved_type:\n",
    "                yield _answer\n",
    "\n",
    "test_df['filtered_by_type_preds'] = test_df.progress_apply(\n",
    "     lambda row: list(filter_generated_answers_by_type(row['generated_entities'], row['answerRetrievedType'])),\n",
    "     axis=1\n",
    ")\n",
    "\n",
    "df = calculate_metrics_for_prediction(\n",
    "    dict(zip(dataset[dataset_split]['id'], test_df['filtered_by_type_preds'].apply(lambda lst: lst[0]).values)),\n",
    "    dataset_split,\n",
    "    'kg',\n",
    ")\n",
    "df['answerRetrievedType'] = test_df['answerRetrievedType']\n",
    "results_kg = print_eval(df=df, groupbycols=['complexityType', 'answerRetrievedType'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb4628a1e95740e5a38db3221698d548",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proportion of errors with incorrect type                = 0.22252559726962456\n",
      "\n",
      "Proportion of errors with incorrect type (comparative ) = 0.24770642201834864\n",
      "Proportion of errors with incorrect type (count       ) = 0.010309278350515464\n",
      "Proportion of errors with incorrect type (difference  ) = 0.2803738317757009\n",
      "Proportion of errors with incorrect type (generic     ) = 0.29876160990712075\n",
      "Proportion of errors with incorrect type (intersection) = 0.18466898954703834\n",
      "Proportion of errors with incorrect type (multihop    ) = 0.2430167597765363\n",
      "Proportion of errors with incorrect type (ordinal     ) = 0.2182890855457227\n",
      "Proportion of errors with incorrect type (superlative ) = 0.3024193548387097\n",
      "Proportion of errors with incorrect type (yesno       ) = 0.1036036036036036\n",
      "\n",
      "Proportion of errors with incorrect type (books       ) = 0.37799043062200954\n",
      "Proportion of errors with incorrect type (geography   ) = 0.2946708463949843\n",
      "Proportion of errors with incorrect type (history     ) = 0.20909090909090908\n",
      "Proportion of errors with incorrect type (movies      ) = 0.15346534653465346\n",
      "Proportion of errors with incorrect type (music       ) = 0.235\n",
      "Proportion of errors with incorrect type (politics    ) = 0.11801242236024845\n",
      "Proportion of errors with incorrect type (sports      ) = 0.09295774647887324\n",
      "Proportion of errors with incorrect type (videogames  ) = 0.27225130890052357\n"
     ]
    }
   ],
   "source": [
    "df['pred'] = test_df['filtered_by_type_preds'].apply(lambda preds: [preds[0]] if isinstance(preds, list) else preds)\n",
    "df['type_match'] = df.progress_apply(is_type_matched, axis=1)\n",
    "\n",
    "df['is_hit'] = df['hits1'].astype(bool)\n",
    "\n",
    "print(\n",
    "    'Proportion of errors with incorrect type                =',\n",
    "    df[(~df['type_match']) & (~df['is_hit'])].index.size / df[~df['is_hit']].index.size,\n",
    "    end='\\n\\n'\n",
    ")\n",
    "\n",
    "for complexity_type, group in df.groupby('complexityType'):\n",
    "    print(\n",
    "        f'Proportion of errors with incorrect type ({complexity_type:12s}) =',\n",
    "        group[(~group['type_match']) & (~group['is_hit'])].index.size / group[~group['is_hit']].index.size\n",
    "    )\n",
    "\n",
    "print('')\n",
    "for category, group in df.groupby('category'):\n",
    "    print(\n",
    "        f'Proportion of errors with incorrect type ({category:12s}) =',\n",
    "        group[(~group['type_match']) & (~group['is_hit'])].index.size / group[~group['is_hit']].index.size\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.837"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['type_match'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9644e951a9064c04ae654b0802e7c7d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>lang</th>\n",
       "      <th>question</th>\n",
       "      <th>answerText</th>\n",
       "      <th>category</th>\n",
       "      <th>complexityType</th>\n",
       "      <th>questionEntity</th>\n",
       "      <th>answerEntity</th>\n",
       "      <th>generated_text</th>\n",
       "      <th>sequences_scores</th>\n",
       "      <th>generated_entities</th>\n",
       "      <th>answerRetrievedType</th>\n",
       "      <th>filtered_by_type_preds</th>\n",
       "      <th>goldAnswerRetrievedType</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>fae46b21</td>\n",
       "      <td>en</td>\n",
       "      <td>What man was a famous American author and also...</td>\n",
       "      <td>Mark Twain</td>\n",
       "      <td>history</td>\n",
       "      <td>intersection</td>\n",
       "      <td>[{'name': 'Q1497', 'entityType': 'entity', 'la...</td>\n",
       "      <td>[{'name': 'Q7245', 'label': 'Mark Twain'}]</td>\n",
       "      <td>[Edgar Allan Poe, Ernest Hemingway, Charles Di...</td>\n",
       "      <td>[-0.2734780908, -0.3756849766, -0.418252229700...</td>\n",
       "      <td>[Q16867, Q23434, Q5686, Q131149, Q34597, Q3616...</td>\n",
       "      <td>Q5</td>\n",
       "      <td>[Q16867, Q23434, Q5686, Q131149, Q34597, Q3616...</td>\n",
       "      <td>Q5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bc8713cc</td>\n",
       "      <td>en</td>\n",
       "      <td>How many Academy Awards has Jake Gyllenhaal be...</td>\n",
       "      <td>1</td>\n",
       "      <td>movies</td>\n",
       "      <td>count</td>\n",
       "      <td>[{'name': 'Q133313', 'entityType': 'entity', '...</td>\n",
       "      <td>[{'name': 'Q106291', 'label': 'Academy Award f...</td>\n",
       "      <td>[1, 2, 3, 4, 5, 11, 6, 0, 8, 7, 9, 10, 13, 12,...</td>\n",
       "      <td>[-0.6568749547, -0.7941160798, -0.851152122, -...</td>\n",
       "      <td>[1, 2, 3, 4, 5, 11, 6, 0, 8, 7, 9, 10, 13, 12,...</td>\n",
       "      <td>Number</td>\n",
       "      <td>[1, 2, 3, 4, 5, 11, 6, 0, 8, 7, 9, 10, 13, 12,...</td>\n",
       "      <td>Number</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>d2a03f72</td>\n",
       "      <td>en</td>\n",
       "      <td>Who is older, The Weeknd or Drake?</td>\n",
       "      <td>Drake</td>\n",
       "      <td>music</td>\n",
       "      <td>comparative</td>\n",
       "      <td>[{'name': 'Q2121062', 'entityType': 'entity', ...</td>\n",
       "      <td>[{'name': 'Q33240', 'label': 'Drake'}]</td>\n",
       "      <td>[Drake, The Weeknd, Cody Jarrett, Dwight D. Ei...</td>\n",
       "      <td>[-0.0174380932, -0.8993775845, -1.415274024, -...</td>\n",
       "      <td>[Q7559, Q2121062, Q5140439, Q9916, Q713099, Q5...</td>\n",
       "      <td>Q5</td>\n",
       "      <td>[Q2121062, Q5140439, Q9916, Q713099, Q513019, ...</td>\n",
       "      <td>Q5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9a296167</td>\n",
       "      <td>en</td>\n",
       "      <td>How many children did Donald Trump have?</td>\n",
       "      <td>5</td>\n",
       "      <td>history</td>\n",
       "      <td>count</td>\n",
       "      <td>[{'name': 'Q22686', 'entityType': 'entity', 'l...</td>\n",
       "      <td>[{'name': 'Q3713655', 'label': 'Donald Trump J...</td>\n",
       "      <td>[2, 3, 4, 5, 6, 1, 8, 9, 0, 7, 11, 10, 6 child...</td>\n",
       "      <td>[-0.49233829980000005, -1.0202715397, -1.06337...</td>\n",
       "      <td>[2, 3, 4, 5, 6, 1, 8, 9, 0, 7, 11, 10, Q348559...</td>\n",
       "      <td>Number</td>\n",
       "      <td>[2, 3, 4, 5, 6, 1, 8, 9, 0, 7, 11, 10, 13]</td>\n",
       "      <td>Number</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>e343ad26</td>\n",
       "      <td>en</td>\n",
       "      <td>Is the main hero in Final Fantasy IX named Kuja?</td>\n",
       "      <td>No</td>\n",
       "      <td>videogames</td>\n",
       "      <td>yesno</td>\n",
       "      <td>[{'name': 'Q474573', 'entityType': 'entity', '...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[Yes, No, Yuna, Yuna, Yuna, Yuna and Kuja are ...</td>\n",
       "      <td>[-0.3390540481, -0.3550684452, -1.4538880587, ...</td>\n",
       "      <td>[True, False, None, None, None, None, None, No...</td>\n",
       "      <td>yesno</td>\n",
       "      <td>[True, False]</td>\n",
       "      <td>yesno</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id lang                                           question   \n",
       "0  fae46b21   en  What man was a famous American author and also...  \\\n",
       "1  bc8713cc   en  How many Academy Awards has Jake Gyllenhaal be...   \n",
       "2  d2a03f72   en                 Who is older, The Weeknd or Drake?   \n",
       "3  9a296167   en           How many children did Donald Trump have?   \n",
       "4  e343ad26   en   Is the main hero in Final Fantasy IX named Kuja?   \n",
       "\n",
       "   answerText    category complexityType   \n",
       "0  Mark Twain     history   intersection  \\\n",
       "1           1      movies          count   \n",
       "2       Drake       music    comparative   \n",
       "3           5     history          count   \n",
       "4          No  videogames          yesno   \n",
       "\n",
       "                                      questionEntity   \n",
       "0  [{'name': 'Q1497', 'entityType': 'entity', 'la...  \\\n",
       "1  [{'name': 'Q133313', 'entityType': 'entity', '...   \n",
       "2  [{'name': 'Q2121062', 'entityType': 'entity', ...   \n",
       "3  [{'name': 'Q22686', 'entityType': 'entity', 'l...   \n",
       "4  [{'name': 'Q474573', 'entityType': 'entity', '...   \n",
       "\n",
       "                                        answerEntity   \n",
       "0         [{'name': 'Q7245', 'label': 'Mark Twain'}]  \\\n",
       "1  [{'name': 'Q106291', 'label': 'Academy Award f...   \n",
       "2             [{'name': 'Q33240', 'label': 'Drake'}]   \n",
       "3  [{'name': 'Q3713655', 'label': 'Donald Trump J...   \n",
       "4                                                 []   \n",
       "\n",
       "                                      generated_text   \n",
       "0  [Edgar Allan Poe, Ernest Hemingway, Charles Di...  \\\n",
       "1  [1, 2, 3, 4, 5, 11, 6, 0, 8, 7, 9, 10, 13, 12,...   \n",
       "2  [Drake, The Weeknd, Cody Jarrett, Dwight D. Ei...   \n",
       "3  [2, 3, 4, 5, 6, 1, 8, 9, 0, 7, 11, 10, 6 child...   \n",
       "4  [Yes, No, Yuna, Yuna, Yuna, Yuna and Kuja are ...   \n",
       "\n",
       "                                    sequences_scores   \n",
       "0  [-0.2734780908, -0.3756849766, -0.418252229700...  \\\n",
       "1  [-0.6568749547, -0.7941160798, -0.851152122, -...   \n",
       "2  [-0.0174380932, -0.8993775845, -1.415274024, -...   \n",
       "3  [-0.49233829980000005, -1.0202715397, -1.06337...   \n",
       "4  [-0.3390540481, -0.3550684452, -1.4538880587, ...   \n",
       "\n",
       "                                  generated_entities answerRetrievedType   \n",
       "0  [Q16867, Q23434, Q5686, Q131149, Q34597, Q3616...                  Q5  \\\n",
       "1  [1, 2, 3, 4, 5, 11, 6, 0, 8, 7, 9, 10, 13, 12,...              Number   \n",
       "2  [Q7559, Q2121062, Q5140439, Q9916, Q713099, Q5...                  Q5   \n",
       "3  [2, 3, 4, 5, 6, 1, 8, 9, 0, 7, 11, 10, Q348559...              Number   \n",
       "4  [True, False, None, None, None, None, None, No...               yesno   \n",
       "\n",
       "                              filtered_by_type_preds goldAnswerRetrievedType  \n",
       "0  [Q16867, Q23434, Q5686, Q131149, Q34597, Q3616...                      Q5  \n",
       "1  [1, 2, 3, 4, 5, 11, 6, 0, 8, 7, 9, 10, 13, 12,...                  Number  \n",
       "2  [Q2121062, Q5140439, Q9916, Q713099, Q513019, ...                      Q5  \n",
       "3         [2, 3, 4, 5, 6, 1, 8, 9, 0, 7, 11, 10, 13]                  Number  \n",
       "4                                      [True, False]                   yesno  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df['goldAnswerRetrievedType'] = df['answer'].progress_apply(\n",
    "    lambda answer: retrieve_answer_type_from_candidates(answer) if answer is not None else None\n",
    ")\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>lang</th>\n",
       "      <th>question</th>\n",
       "      <th>answerText</th>\n",
       "      <th>category</th>\n",
       "      <th>complexityType</th>\n",
       "      <th>questionEntity</th>\n",
       "      <th>answerEntity</th>\n",
       "      <th>generated_text</th>\n",
       "      <th>sequences_scores</th>\n",
       "      <th>generated_entities</th>\n",
       "      <th>answerRetrievedType</th>\n",
       "      <th>filtered_by_type_preds</th>\n",
       "      <th>goldAnswerRetrievedType</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>b41ae115</td>\n",
       "      <td>en</td>\n",
       "      <td>Who performed at the Super Bowl XXIII halftime...</td>\n",
       "      <td>Elvis Presto</td>\n",
       "      <td>sports</td>\n",
       "      <td>generic</td>\n",
       "      <td>[{'name': 'Q1307150', 'entityType': 'entity', ...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[Coldplay, Justin Timberlake, Lady Gaga, The B...</td>\n",
       "      <td>[-0.1100655422, -0.6572936773, -0.6655324101, ...</td>\n",
       "      <td>[Q45188, Q43432, Q19848, Q134541, Q29564107, Q...</td>\n",
       "      <td>Q5</td>\n",
       "      <td>[Q43432, Q19848, Q29564107, Q73437, Q121507, Q...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>7ed1858c</td>\n",
       "      <td>en</td>\n",
       "      <td>Which movie, starring Al Jolson, is generally ...</td>\n",
       "      <td>The Jazz Singer</td>\n",
       "      <td>movies</td>\n",
       "      <td>ordinal</td>\n",
       "      <td>[{'name': 'Q128532', 'entityType': 'entity', '...</td>\n",
       "      <td>[{'name': 'Q465087', 'label': 'The Jazz Singer'}]</td>\n",
       "      <td>[The Jazz Singer, On Stranger Tides, It's a Wo...</td>\n",
       "      <td>[-0.14734335240000002, -0.7283437252, -0.73821...</td>\n",
       "      <td>[Q465087, Q1660753, Q204191, Q778696, Q669749,...</td>\n",
       "      <td>Q11424</td>\n",
       "      <td>[Q204191, Q778696, Q669749, Q777776, Q3110003,...</td>\n",
       "      <td>Q24869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>dbc6f3e8</td>\n",
       "      <td>en</td>\n",
       "      <td>Which movie came out first, Monsters, Inc. or ...</td>\n",
       "      <td>Monsters Inc</td>\n",
       "      <td>movies</td>\n",
       "      <td>comparative</td>\n",
       "      <td>[{'name': 'Q36092', 'entityType': 'entity', 'l...</td>\n",
       "      <td>[{'name': 'Q187726', 'label': 'Monsters, Inc.'}]</td>\n",
       "      <td>[Lilo and Stitch, Monsters, Inc., Lilo &amp; Stitc...</td>\n",
       "      <td>[-0.1103270054, -0.1441309899, -0.2825240791, ...</td>\n",
       "      <td>[Q590166, Q187726, Q590166, None, None, Q59016...</td>\n",
       "      <td>Q261636</td>\n",
       "      <td>[Q590166, Q590166, Q590166, Q590166]</td>\n",
       "      <td>Q229390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>f5ef3179</td>\n",
       "      <td>en</td>\n",
       "      <td>Which movie had a bigger budget, Avatar or Tra...</td>\n",
       "      <td>Avatar</td>\n",
       "      <td>movies</td>\n",
       "      <td>comparative</td>\n",
       "      <td>[{'name': 'Q24871', 'entityType': 'entity', 'l...</td>\n",
       "      <td>[{'name': 'Q24871', 'label': 'Avatar'}]</td>\n",
       "      <td>[Avatar, Training Day, Voyage of the Dawn Trea...</td>\n",
       "      <td>[-0.032006066300000004, -0.7113320231, -1.1629...</td>\n",
       "      <td>[Q11572, Q308929, Q331656, None, None, Q123760...</td>\n",
       "      <td>Q11424</td>\n",
       "      <td>[Q308929, Q19590955, Q174284, Q51882895, Q284917]</td>\n",
       "      <td>Q229390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>44b1cebb</td>\n",
       "      <td>en</td>\n",
       "      <td>Which movie sold more tickets: Titanic or Avatar?</td>\n",
       "      <td>Avatar</td>\n",
       "      <td>movies</td>\n",
       "      <td>comparative</td>\n",
       "      <td>[{'name': 'Q24871', 'entityType': 'entity', 'l...</td>\n",
       "      <td>[{'name': 'Q24871', 'label': 'Avatar'}]</td>\n",
       "      <td>[Avatar, Titanic, Titanic, Avatar, Avatar, Tit...</td>\n",
       "      <td>[-0.1260389686, -0.30949947240000003, -1.29978...</td>\n",
       "      <td>[Q11572, Q25173, None, None, None, Q331656, No...</td>\n",
       "      <td>Q5398426</td>\n",
       "      <td>[Q11572, Q11572, Q123760]</td>\n",
       "      <td>Q229390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3981</th>\n",
       "      <td>e94b4483</td>\n",
       "      <td>en</td>\n",
       "      <td>What's one of Yoshi's unique superpowers?</td>\n",
       "      <td>He can turn the enemies that he eats into eggs...</td>\n",
       "      <td>videogames</td>\n",
       "      <td>generic</td>\n",
       "      <td>[{'name': 'Q214174', 'entityType': 'entity', '...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[Transcendence, Magician's Touch, able to see ...</td>\n",
       "      <td>[-0.9820313454, -1.0229785442, -1.0529767275, ...</td>\n",
       "      <td>[Q193359, None, None, None, None, Q105854041, ...</td>\n",
       "      <td>Q1751513</td>\n",
       "      <td>[Q2107094, Q2107094]</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3982</th>\n",
       "      <td>9b9a14d0</td>\n",
       "      <td>en</td>\n",
       "      <td>What was the name of Final Fantasy 4's main pr...</td>\n",
       "      <td>Cecil</td>\n",
       "      <td>videogames</td>\n",
       "      <td>generic</td>\n",
       "      <td>[{'name': 'Q911226', 'entityType': 'entity', '...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[Talion, Squall Leonhart, Sora, Kiritsugu, Clo...</td>\n",
       "      <td>[-0.6161286235, -0.7360379696, -0.7670309544, ...</td>\n",
       "      <td>[Q15730974, Q2607464, Q117382, Q4925676, Q1798...</td>\n",
       "      <td>Q15632617</td>\n",
       "      <td>[Q2607464, Q4925676, Q1798592, Q12902673, Q226...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3984</th>\n",
       "      <td>d0336c26</td>\n",
       "      <td>en</td>\n",
       "      <td>Who is the protagonist of Fallout 4?</td>\n",
       "      <td>The Sole Survivor</td>\n",
       "      <td>videogames</td>\n",
       "      <td>generic</td>\n",
       "      <td>[{'name': 'Q10493813', 'entityType': 'entity',...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[the \"Sole Survivor\", Bethesda, Geralt of Rivi...</td>\n",
       "      <td>[-0.7761734128000001, -0.8043124676000001, -0....</td>\n",
       "      <td>[None, Q584451, Q2492923, Q192469, Q12400, Non...</td>\n",
       "      <td>Q5</td>\n",
       "      <td>[Q58444, Q438820, Q460572, Q460240, Q44024, Q9...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3990</th>\n",
       "      <td>af4462a9</td>\n",
       "      <td>en</td>\n",
       "      <td>What game was released by Impressions Games an...</td>\n",
       "      <td>Cleopatra: Queen of the Nile</td>\n",
       "      <td>videogames</td>\n",
       "      <td>intersection</td>\n",
       "      <td>[{'name': 'Q37110', 'entityType': 'entity', 'l...</td>\n",
       "      <td>[{'name': 'Q2980768', 'label': 'Cleopatra: Que...</td>\n",
       "      <td>[Pharaoh II, Pharaoh 2, Pharaoh: New Horizons,...</td>\n",
       "      <td>[-0.3500819206, -0.4563730657, -0.4766887128, ...</td>\n",
       "      <td>[None, None, None, None, None, None, None, Non...</td>\n",
       "      <td>Q11424</td>\n",
       "      <td>[Q181795, Q15845551]</td>\n",
       "      <td>Q209163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3997</th>\n",
       "      <td>58727fb0</td>\n",
       "      <td>en</td>\n",
       "      <td>How long was the 53rd mayor of Boston in office?</td>\n",
       "      <td>20 years, 6 months</td>\n",
       "      <td>politics</td>\n",
       "      <td>ordinal</td>\n",
       "      <td>[{'name': 'Q100', 'entityType': 'entity', 'lab...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[5 years, 6 years, 4 years, 20 years, 25 years...</td>\n",
       "      <td>[-0.8029176593, -0.8521545529000001, -0.856678...</td>\n",
       "      <td>[Q654585, Q18703052, Q4639116, Q60254333, Q463...</td>\n",
       "      <td>Q482994</td>\n",
       "      <td>[Q654585, Q4632187, Q260948, Q463322, Q654585,...</td>\n",
       "      <td>Number</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>943 rows  14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            id lang                                           question   \n",
       "5     b41ae115   en  Who performed at the Super Bowl XXIII halftime...  \\\n",
       "9     7ed1858c   en  Which movie, starring Al Jolson, is generally ...   \n",
       "11    dbc6f3e8   en  Which movie came out first, Monsters, Inc. or ...   \n",
       "15    f5ef3179   en  Which movie had a bigger budget, Avatar or Tra...   \n",
       "16    44b1cebb   en  Which movie sold more tickets: Titanic or Avatar?   \n",
       "...        ...  ...                                                ...   \n",
       "3981  e94b4483   en          What's one of Yoshi's unique superpowers?   \n",
       "3982  9b9a14d0   en  What was the name of Final Fantasy 4's main pr...   \n",
       "3984  d0336c26   en               Who is the protagonist of Fallout 4?   \n",
       "3990  af4462a9   en  What game was released by Impressions Games an...   \n",
       "3997  58727fb0   en   How long was the 53rd mayor of Boston in office?   \n",
       "\n",
       "                                             answerText    category   \n",
       "5                                          Elvis Presto      sports  \\\n",
       "9                                       The Jazz Singer      movies   \n",
       "11                                         Monsters Inc      movies   \n",
       "15                                               Avatar      movies   \n",
       "16                                               Avatar      movies   \n",
       "...                                                 ...         ...   \n",
       "3981  He can turn the enemies that he eats into eggs...  videogames   \n",
       "3982                                              Cecil  videogames   \n",
       "3984                                  The Sole Survivor  videogames   \n",
       "3990                       Cleopatra: Queen of the Nile  videogames   \n",
       "3997                                 20 years, 6 months    politics   \n",
       "\n",
       "     complexityType                                     questionEntity   \n",
       "5           generic  [{'name': 'Q1307150', 'entityType': 'entity', ...  \\\n",
       "9           ordinal  [{'name': 'Q128532', 'entityType': 'entity', '...   \n",
       "11      comparative  [{'name': 'Q36092', 'entityType': 'entity', 'l...   \n",
       "15      comparative  [{'name': 'Q24871', 'entityType': 'entity', 'l...   \n",
       "16      comparative  [{'name': 'Q24871', 'entityType': 'entity', 'l...   \n",
       "...             ...                                                ...   \n",
       "3981        generic  [{'name': 'Q214174', 'entityType': 'entity', '...   \n",
       "3982        generic  [{'name': 'Q911226', 'entityType': 'entity', '...   \n",
       "3984        generic  [{'name': 'Q10493813', 'entityType': 'entity',...   \n",
       "3990   intersection  [{'name': 'Q37110', 'entityType': 'entity', 'l...   \n",
       "3997        ordinal  [{'name': 'Q100', 'entityType': 'entity', 'lab...   \n",
       "\n",
       "                                           answerEntity   \n",
       "5                                                    []  \\\n",
       "9     [{'name': 'Q465087', 'label': 'The Jazz Singer'}]   \n",
       "11     [{'name': 'Q187726', 'label': 'Monsters, Inc.'}]   \n",
       "15              [{'name': 'Q24871', 'label': 'Avatar'}]   \n",
       "16              [{'name': 'Q24871', 'label': 'Avatar'}]   \n",
       "...                                                 ...   \n",
       "3981                                                 []   \n",
       "3982                                                 []   \n",
       "3984                                                 []   \n",
       "3990  [{'name': 'Q2980768', 'label': 'Cleopatra: Que...   \n",
       "3997                                                 []   \n",
       "\n",
       "                                         generated_text   \n",
       "5     [Coldplay, Justin Timberlake, Lady Gaga, The B...  \\\n",
       "9     [The Jazz Singer, On Stranger Tides, It's a Wo...   \n",
       "11    [Lilo and Stitch, Monsters, Inc., Lilo & Stitc...   \n",
       "15    [Avatar, Training Day, Voyage of the Dawn Trea...   \n",
       "16    [Avatar, Titanic, Titanic, Avatar, Avatar, Tit...   \n",
       "...                                                 ...   \n",
       "3981  [Transcendence, Magician's Touch, able to see ...   \n",
       "3982  [Talion, Squall Leonhart, Sora, Kiritsugu, Clo...   \n",
       "3984  [the \"Sole Survivor\", Bethesda, Geralt of Rivi...   \n",
       "3990  [Pharaoh II, Pharaoh 2, Pharaoh: New Horizons,...   \n",
       "3997  [5 years, 6 years, 4 years, 20 years, 25 years...   \n",
       "\n",
       "                                       sequences_scores   \n",
       "5     [-0.1100655422, -0.6572936773, -0.6655324101, ...  \\\n",
       "9     [-0.14734335240000002, -0.7283437252, -0.73821...   \n",
       "11    [-0.1103270054, -0.1441309899, -0.2825240791, ...   \n",
       "15    [-0.032006066300000004, -0.7113320231, -1.1629...   \n",
       "16    [-0.1260389686, -0.30949947240000003, -1.29978...   \n",
       "...                                                 ...   \n",
       "3981  [-0.9820313454, -1.0229785442, -1.0529767275, ...   \n",
       "3982  [-0.6161286235, -0.7360379696, -0.7670309544, ...   \n",
       "3984  [-0.7761734128000001, -0.8043124676000001, -0....   \n",
       "3990  [-0.3500819206, -0.4563730657, -0.4766887128, ...   \n",
       "3997  [-0.8029176593, -0.8521545529000001, -0.856678...   \n",
       "\n",
       "                                     generated_entities answerRetrievedType   \n",
       "5     [Q45188, Q43432, Q19848, Q134541, Q29564107, Q...                  Q5  \\\n",
       "9     [Q465087, Q1660753, Q204191, Q778696, Q669749,...              Q11424   \n",
       "11    [Q590166, Q187726, Q590166, None, None, Q59016...             Q261636   \n",
       "15    [Q11572, Q308929, Q331656, None, None, Q123760...              Q11424   \n",
       "16    [Q11572, Q25173, None, None, None, Q331656, No...            Q5398426   \n",
       "...                                                 ...                 ...   \n",
       "3981  [Q193359, None, None, None, None, Q105854041, ...            Q1751513   \n",
       "3982  [Q15730974, Q2607464, Q117382, Q4925676, Q1798...           Q15632617   \n",
       "3984  [None, Q584451, Q2492923, Q192469, Q12400, Non...                  Q5   \n",
       "3990  [None, None, None, None, None, None, None, Non...              Q11424   \n",
       "3997  [Q654585, Q18703052, Q4639116, Q60254333, Q463...             Q482994   \n",
       "\n",
       "                                 filtered_by_type_preds   \n",
       "5     [Q43432, Q19848, Q29564107, Q73437, Q121507, Q...  \\\n",
       "9     [Q204191, Q778696, Q669749, Q777776, Q3110003,...   \n",
       "11                 [Q590166, Q590166, Q590166, Q590166]   \n",
       "15    [Q308929, Q19590955, Q174284, Q51882895, Q284917]   \n",
       "16                            [Q11572, Q11572, Q123760]   \n",
       "...                                                 ...   \n",
       "3981                               [Q2107094, Q2107094]   \n",
       "3982  [Q2607464, Q4925676, Q1798592, Q12902673, Q226...   \n",
       "3984  [Q58444, Q438820, Q460572, Q460240, Q44024, Q9...   \n",
       "3990                               [Q181795, Q15845551]   \n",
       "3997  [Q654585, Q4632187, Q260948, Q463322, Q654585,...   \n",
       "\n",
       "     goldAnswerRetrievedType  \n",
       "5                       None  \n",
       "9                     Q24869  \n",
       "11                   Q229390  \n",
       "15                   Q229390  \n",
       "16                   Q229390  \n",
       "...                      ...  \n",
       "3981                    None  \n",
       "3982                    None  \n",
       "3984                    None  \n",
       "3990                 Q209163  \n",
       "3997                  Number  \n",
       "\n",
       "[943 rows x 14 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df[test_df['goldAnswerRetrievedType'] != test_df['answerRetrievedType']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38.226"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.apply(\n",
    "    lambda row: len(row['generated_entities']) - len(row['filtered_by_type_preds']),\n",
    "    axis=1\n",
    ").mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "isAnswerEntity\n",
      "True     2816\n",
      "False    1184\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>lang</th>\n",
       "      <th>question</th>\n",
       "      <th>answerText</th>\n",
       "      <th>category</th>\n",
       "      <th>complexityType</th>\n",
       "      <th>questionEntity</th>\n",
       "      <th>answerEntity</th>\n",
       "      <th>generated_text</th>\n",
       "      <th>sequences_scores</th>\n",
       "      <th>generated_entities</th>\n",
       "      <th>answerRetrievedType</th>\n",
       "      <th>filtered_by_type_preds</th>\n",
       "      <th>goldAnswerRetrievedType</th>\n",
       "      <th>isAnswerEntity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>fae46b21</td>\n",
       "      <td>en</td>\n",
       "      <td>What man was a famous American author and also...</td>\n",
       "      <td>Mark Twain</td>\n",
       "      <td>history</td>\n",
       "      <td>intersection</td>\n",
       "      <td>[{'name': 'Q1497', 'entityType': 'entity', 'la...</td>\n",
       "      <td>[{'name': 'Q7245', 'label': 'Mark Twain'}]</td>\n",
       "      <td>[Edgar Allan Poe, Ernest Hemingway, Charles Di...</td>\n",
       "      <td>[-0.2734780908, -0.3756849766, -0.418252229700...</td>\n",
       "      <td>[Q16867, Q23434, Q5686, Q131149, Q34597, Q3616...</td>\n",
       "      <td>Q5</td>\n",
       "      <td>[Q16867, Q23434, Q5686, Q131149, Q34597, Q3616...</td>\n",
       "      <td>Q5</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bc8713cc</td>\n",
       "      <td>en</td>\n",
       "      <td>How many Academy Awards has Jake Gyllenhaal be...</td>\n",
       "      <td>1</td>\n",
       "      <td>movies</td>\n",
       "      <td>count</td>\n",
       "      <td>[{'name': 'Q133313', 'entityType': 'entity', '...</td>\n",
       "      <td>[{'name': 'Q106291', 'label': 'Academy Award f...</td>\n",
       "      <td>[1, 2, 3, 4, 5, 11, 6, 0, 8, 7, 9, 10, 13, 12,...</td>\n",
       "      <td>[-0.6568749547, -0.7941160798, -0.851152122, -...</td>\n",
       "      <td>[1, 2, 3, 4, 5, 11, 6, 0, 8, 7, 9, 10, 13, 12,...</td>\n",
       "      <td>Number</td>\n",
       "      <td>[1, 2, 3, 4, 5, 11, 6, 0, 8, 7, 9, 10, 13, 12,...</td>\n",
       "      <td>Number</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>d2a03f72</td>\n",
       "      <td>en</td>\n",
       "      <td>Who is older, The Weeknd or Drake?</td>\n",
       "      <td>Drake</td>\n",
       "      <td>music</td>\n",
       "      <td>comparative</td>\n",
       "      <td>[{'name': 'Q2121062', 'entityType': 'entity', ...</td>\n",
       "      <td>[{'name': 'Q33240', 'label': 'Drake'}]</td>\n",
       "      <td>[Drake, The Weeknd, Cody Jarrett, Dwight D. Ei...</td>\n",
       "      <td>[-0.0174380932, -0.8993775845, -1.415274024, -...</td>\n",
       "      <td>[Q7559, Q2121062, Q5140439, Q9916, Q713099, Q5...</td>\n",
       "      <td>Q5</td>\n",
       "      <td>[Q2121062, Q5140439, Q9916, Q713099, Q513019, ...</td>\n",
       "      <td>Q5</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9a296167</td>\n",
       "      <td>en</td>\n",
       "      <td>How many children did Donald Trump have?</td>\n",
       "      <td>5</td>\n",
       "      <td>history</td>\n",
       "      <td>count</td>\n",
       "      <td>[{'name': 'Q22686', 'entityType': 'entity', 'l...</td>\n",
       "      <td>[{'name': 'Q3713655', 'label': 'Donald Trump J...</td>\n",
       "      <td>[2, 3, 4, 5, 6, 1, 8, 9, 0, 7, 11, 10, 6 child...</td>\n",
       "      <td>[-0.49233829980000005, -1.0202715397, -1.06337...</td>\n",
       "      <td>[2, 3, 4, 5, 6, 1, 8, 9, 0, 7, 11, 10, Q348559...</td>\n",
       "      <td>Number</td>\n",
       "      <td>[2, 3, 4, 5, 6, 1, 8, 9, 0, 7, 11, 10, 13]</td>\n",
       "      <td>Number</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>e343ad26</td>\n",
       "      <td>en</td>\n",
       "      <td>Is the main hero in Final Fantasy IX named Kuja?</td>\n",
       "      <td>No</td>\n",
       "      <td>videogames</td>\n",
       "      <td>yesno</td>\n",
       "      <td>[{'name': 'Q474573', 'entityType': 'entity', '...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[Yes, No, Yuna, Yuna, Yuna, Yuna and Kuja are ...</td>\n",
       "      <td>[-0.3390540481, -0.3550684452, -1.4538880587, ...</td>\n",
       "      <td>[True, False, None, None, None, None, None, No...</td>\n",
       "      <td>yesno</td>\n",
       "      <td>[True, False]</td>\n",
       "      <td>yesno</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id lang                                           question   \n",
       "0  fae46b21   en  What man was a famous American author and also...  \\\n",
       "1  bc8713cc   en  How many Academy Awards has Jake Gyllenhaal be...   \n",
       "2  d2a03f72   en                 Who is older, The Weeknd or Drake?   \n",
       "3  9a296167   en           How many children did Donald Trump have?   \n",
       "4  e343ad26   en   Is the main hero in Final Fantasy IX named Kuja?   \n",
       "\n",
       "   answerText    category complexityType   \n",
       "0  Mark Twain     history   intersection  \\\n",
       "1           1      movies          count   \n",
       "2       Drake       music    comparative   \n",
       "3           5     history          count   \n",
       "4          No  videogames          yesno   \n",
       "\n",
       "                                      questionEntity   \n",
       "0  [{'name': 'Q1497', 'entityType': 'entity', 'la...  \\\n",
       "1  [{'name': 'Q133313', 'entityType': 'entity', '...   \n",
       "2  [{'name': 'Q2121062', 'entityType': 'entity', ...   \n",
       "3  [{'name': 'Q22686', 'entityType': 'entity', 'l...   \n",
       "4  [{'name': 'Q474573', 'entityType': 'entity', '...   \n",
       "\n",
       "                                        answerEntity   \n",
       "0         [{'name': 'Q7245', 'label': 'Mark Twain'}]  \\\n",
       "1  [{'name': 'Q106291', 'label': 'Academy Award f...   \n",
       "2             [{'name': 'Q33240', 'label': 'Drake'}]   \n",
       "3  [{'name': 'Q3713655', 'label': 'Donald Trump J...   \n",
       "4                                                 []   \n",
       "\n",
       "                                      generated_text   \n",
       "0  [Edgar Allan Poe, Ernest Hemingway, Charles Di...  \\\n",
       "1  [1, 2, 3, 4, 5, 11, 6, 0, 8, 7, 9, 10, 13, 12,...   \n",
       "2  [Drake, The Weeknd, Cody Jarrett, Dwight D. Ei...   \n",
       "3  [2, 3, 4, 5, 6, 1, 8, 9, 0, 7, 11, 10, 6 child...   \n",
       "4  [Yes, No, Yuna, Yuna, Yuna, Yuna and Kuja are ...   \n",
       "\n",
       "                                    sequences_scores   \n",
       "0  [-0.2734780908, -0.3756849766, -0.418252229700...  \\\n",
       "1  [-0.6568749547, -0.7941160798, -0.851152122, -...   \n",
       "2  [-0.0174380932, -0.8993775845, -1.415274024, -...   \n",
       "3  [-0.49233829980000005, -1.0202715397, -1.06337...   \n",
       "4  [-0.3390540481, -0.3550684452, -1.4538880587, ...   \n",
       "\n",
       "                                  generated_entities answerRetrievedType   \n",
       "0  [Q16867, Q23434, Q5686, Q131149, Q34597, Q3616...                  Q5  \\\n",
       "1  [1, 2, 3, 4, 5, 11, 6, 0, 8, 7, 9, 10, 13, 12,...              Number   \n",
       "2  [Q7559, Q2121062, Q5140439, Q9916, Q713099, Q5...                  Q5   \n",
       "3  [2, 3, 4, 5, 6, 1, 8, 9, 0, 7, 11, 10, Q348559...              Number   \n",
       "4  [True, False, None, None, None, None, None, No...               yesno   \n",
       "\n",
       "                              filtered_by_type_preds goldAnswerRetrievedType   \n",
       "0  [Q16867, Q23434, Q5686, Q131149, Q34597, Q3616...                      Q5  \\\n",
       "1  [1, 2, 3, 4, 5, 11, 6, 0, 8, 7, 9, 10, 13, 12,...                  Number   \n",
       "2  [Q2121062, Q5140439, Q9916, Q713099, Q513019, ...                      Q5   \n",
       "3         [2, 3, 4, 5, 6, 1, 8, 9, 0, 7, 11, 10, 13]                  Number   \n",
       "4                                      [True, False]                   yesno   \n",
       "\n",
       "   isAnswerEntity  \n",
       "0            True  \n",
       "1            True  \n",
       "2            True  \n",
       "3            True  \n",
       "4           False  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df['isAnswerEntity'] = test_df['answerEntity'].apply(lambda entities: len(entities) > 0)\n",
    "print(test_df['isAnswerEntity'].value_counts())\n",
    "test_df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtered by type With oracle for question: is answer entity or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Group          Hits@1 (Correct Of Total)\n",
      "All          = 0.2750 (1100 Of 4000)\n",
      "\n",
      "comparative  = 0.4600 ( 184 Of  400)\n",
      "count        = 0.2725 ( 109 Of  400)\n",
      "difference   = 0.2050 (  82 Of  400)\n",
      "generic      = 0.1988 ( 159 Of  800)\n",
      "intersection = 0.2850 ( 114 Of  400)\n",
      "multihop     = 0.1050 (  42 Of  400)\n",
      "ordinal      = 0.1575 (  63 Of  400)\n",
      "superlative  = 0.3875 ( 155 Of  400)\n",
      "yesno        = 0.4800 ( 192 Of  400)\n",
      "\n",
      "Q5           = 0.3264 ( 329 Of 1008)\n",
      "Number       = 0.1561 ( 128 Of  820)\n",
      "yesno        = 0.4651 ( 253 Of  544)\n",
      "Q11424       = 0.1270 (  31 Of  244)\n",
      "Q7889        = 0.2649 (  49 Of  185)\n",
      "Q3624078     = 0.4368 (  38 Of   87)\n",
      "Q35657       = 0.3924 (  31 Of   79)\n",
      "Q482994      = 0.1304 (   9 Of   69)\n",
      "Q7725634     = 0.2154 (  14 Of   65)\n",
      "Q1093829     = 0.2692 (  14 Of   52)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "preds = test_df.apply(\n",
    "    lambda row: [row['filtered_by_type_preds'][0]] if row['isAnswerEntity'] is True else row['generated_entities'][0],\n",
    "    axis=1\n",
    ")\n",
    "df = calculate_metrics_for_prediction(\n",
    "    dict(zip(dataset[dataset_split]['id'], preds)),\n",
    "    dataset_split,\n",
    "    'kg',\n",
    ")\n",
    "df['answerRetrievedType'] = test_df['answerRetrievedType']\n",
    "_ = print_eval(df=df, groupbycols=['complexityType', 'answerRetrievedType'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate only predictions, when answer in list of generated entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "206939c9a9704585a873ce398c9cae2c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.5014204545454546"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def _is_answer_in_generate(row):\n",
    "    gold_true_answers = [e['name'] for e in row['answerEntity'] if Entity._validate_entity_id(e['name'])]\n",
    "    return len(set(gold_true_answers).intersection(row['generated_entities'])) > 0\n",
    "\n",
    "test_df['is_answer_in_generated'] = test_df.progress_apply(_is_answer_in_generate, axis=1)\n",
    "test_df[test_df['isAnswerEntity']]['is_answer_in_generated'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ONLY ANSWER IN GENERATED DATA. FILTERED BY TYPE\n",
      "Group          Hits@1 (Correct Of Total)\n",
      "All          = 0.4873 ( 688 Of 1412)\n",
      "\n",
      "comparative  = 0.5619 ( 109 Of  194)\n",
      "count        = 0.0000 (   0 Of    3)\n",
      "difference   = 0.4091 (  72 Of  176)\n",
      "generic      = 0.4689 ( 143 Of  305)\n",
      "intersection = 0.4669 ( 113 Of  242)\n",
      "multihop     = 0.4043 (  38 Of   94)\n",
      "ordinal      = 0.3812 (  61 Of  160)\n",
      "superlative  = 0.6387 ( 152 Of  238)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "_test_df = calculate_metrics_for_prediction(\n",
    "    dict(zip(test_df['id'].values, preds)),\n",
    "    split='test',\n",
    "    mode='kg',\n",
    ")\n",
    "\n",
    "print('ONLY ANSWER IN GENERATED DATA. FILTERED BY TYPE')\n",
    "_ = print_eval(df=_test_df[test_df['isAnswerEntity'] & test_df['is_answer_in_generated']], mode='kg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ONLY ANSWER IN GENERATED DATA. WITHOUT FILTRATION BY TYPE\n",
      "Group          Hits@1 (Correct Of Total)\n",
      "All          = 0.4851 ( 685 Of 1412)\n",
      "\n",
      "comparative  = 0.5567 ( 108 Of  194)\n",
      "count        = 0.0000 (   0 Of    3)\n",
      "difference   = 0.3352 (  59 Of  176)\n",
      "generic      = 0.4918 ( 150 Of  305)\n",
      "intersection = 0.4752 ( 115 Of  242)\n",
      "multihop     = 0.3936 (  37 Of   94)\n",
      "ordinal      = 0.3875 (  62 Of  160)\n",
      "superlative  = 0.6471 ( 154 Of  238)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "_test_df = calculate_metrics_for_prediction(\n",
    "    dict(zip(test_df['id'].values, test_df['generated_entities'].apply(lambda lst: lst[0]))),\n",
    "    split='test',\n",
    "    mode='kg',\n",
    ")\n",
    "\n",
    "print('ONLY ANSWER IN GENERATED DATA. WITHOUT FILTRATION BY TYPE')\n",
    "_ = print_eval(df=_test_df[test_df['isAnswerEntity'] & test_df['is_answer_in_generated']], mode='kg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    1412.00000\n",
       "mean        4.50779\n",
       "std         9.77895\n",
       "min         0.00000\n",
       "25%         0.00000\n",
       "50%         1.00000\n",
       "75%         4.00000\n",
       "max       101.00000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def _position_of_answer_in_generated(row):\n",
    "    gold_true_answers = [e['name'] for e in row['answerEntity'] if Entity._validate_entity_id(e['name'])]\n",
    "    for idx, answer_candidate in enumerate(row['generated_entities']):\n",
    "        if answer_candidate in gold_true_answers:\n",
    "            return idx\n",
    "\n",
    "position_of_answer_in_generated = test_df[test_df['isAnswerEntity'] & test_df['is_answer_in_generated']].apply(\n",
    "    _position_of_answer_in_generated,\n",
    "    axis=1\n",
    ")\n",
    "position_of_answer_in_generated.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     685\n",
       "1     217\n",
       "2      78\n",
       "3      61\n",
       "4      42\n",
       "5      32\n",
       "8      29\n",
       "7      28\n",
       "6      24\n",
       "10     15\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "position_of_answer_in_generated.value_counts().iloc[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>two_hop_neighbours</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>fae46b21</td>\n",
       "      <td>[[Q1497, P17, Q30], [Q30, P37, Q1860], [Q30, P...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bc8713cc</td>\n",
       "      <td>[[Q133313, P8839, Q116790562], [Q116790562, P2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>d2a03f72</td>\n",
       "      <td>[[Q2121062, P6886, Q1860], [Q1860, P17, Q27], ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9a296167</td>\n",
       "      <td>[[Q22686, P27, Q30], [Q30, P37, Q1860], [Q30, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>e343ad26</td>\n",
       "      <td>[[Q474573, P1434, Q99415917], [Q99415917, P170...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id                                 two_hop_neighbours\n",
       "0  fae46b21  [[Q1497, P17, Q30], [Q30, P37, Q1860], [Q30, P...\n",
       "1  bc8713cc  [[Q133313, P8839, Q116790562], [Q116790562, P2...\n",
       "2  d2a03f72  [[Q2121062, P6886, Q1860], [Q1860, P17, Q27], ...\n",
       "3  9a296167  [[Q22686, P27, Q30], [Q30, P37, Q1860], [Q30, ...\n",
       "4  e343ad26  [[Q474573, P1434, Q99415917], [Q99415917, P170..."
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for _, row in tqdm(dataset[dataset_split].to_pandas().iterrows(), total=len(dataset[dataset_split])):\n",
    "#     with open(f'mintaka_{dataset_split}_question_entities_two_hop_neighbours.jsonl', 'a+') as f:\n",
    "#         try:\n",
    "#             question_entities = [\n",
    "#                 Entity(e['name'])\n",
    "#                 for e in row['questionEntity']\n",
    "#                 if e['entityType'] == 'entity' and 'Q' == e['name'][0]\n",
    "#             ]\n",
    "\n",
    "#             question_entities_neighbours = []\n",
    "#             for q_entity in question_entities:\n",
    "#                 for one_hop_neighbour_prop, one_hop_neighbour_entity in q_entity.forward_one_hop_neighbours:\n",
    "#                     question_entities_neighbours.append((\n",
    "#                         q_entity.idx,\n",
    "#                         one_hop_neighbour_prop.idx,\n",
    "#                         one_hop_neighbour_entity.idx,\n",
    "#                     ))\n",
    "\n",
    "#                     for two_hop_neighbour_prop, two_hop_neighbour_entity in one_hop_neighbour_entity.forward_one_hop_neighbours:\n",
    "#                         question_entities_neighbours.append((\n",
    "#                             one_hop_neighbour_entity.idx,\n",
    "#                             two_hop_neighbour_prop.idx,\n",
    "#                             two_hop_neighbour_entity.idx,\n",
    "#                         ))\n",
    "\n",
    "#             f.write(\n",
    "#                 ujson.dumps({\n",
    "#                     'id': row['id'],\n",
    "#                     'two_hop_neighbours': question_entities_neighbours\n",
    "#                 }) + '\\n'\n",
    "#             )\n",
    "#         except Exception as e:\n",
    "#             print(f\"Error with id={row['id']}: {e}\")\n",
    "\n",
    "question_entities_neighbours_df = pd.read_json(\n",
    "    f'mintaka_{dataset_split}_question_entities_two_hop_neighbours.jsonl',\n",
    "    lines=True,\n",
    ")\n",
    "question_entities_neighbours_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>lang</th>\n",
       "      <th>question</th>\n",
       "      <th>answerText</th>\n",
       "      <th>category</th>\n",
       "      <th>complexityType</th>\n",
       "      <th>questionEntity</th>\n",
       "      <th>answerEntity</th>\n",
       "      <th>generated_text</th>\n",
       "      <th>sequences_scores</th>\n",
       "      <th>generated_entities</th>\n",
       "      <th>answerRetrievedType</th>\n",
       "      <th>filtered_by_type_preds</th>\n",
       "      <th>goldAnswerRetrievedType</th>\n",
       "      <th>isAnswerEntity</th>\n",
       "      <th>is_answer_in_generated</th>\n",
       "      <th>neighbours_entities</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>fae46b21</td>\n",
       "      <td>en</td>\n",
       "      <td>What man was a famous American author and also...</td>\n",
       "      <td>Mark Twain</td>\n",
       "      <td>history</td>\n",
       "      <td>intersection</td>\n",
       "      <td>[{'name': 'Q1497', 'entityType': 'entity', 'la...</td>\n",
       "      <td>[{'name': 'Q7245', 'label': 'Mark Twain'}]</td>\n",
       "      <td>[Edgar Allan Poe, Ernest Hemingway, Charles Di...</td>\n",
       "      <td>[-0.2734780908, -0.3756849766, -0.418252229700...</td>\n",
       "      <td>[Q16867, Q23434, Q5686, Q131149, Q34597, Q3616...</td>\n",
       "      <td>Q5</td>\n",
       "      <td>[Q16867, Q23434, Q5686, Q131149, Q34597, Q3616...</td>\n",
       "      <td>Q5</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>[Q30, Q1860, Q61, Q30, Q49, Q6256, Q4917, Q627...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bc8713cc</td>\n",
       "      <td>en</td>\n",
       "      <td>How many Academy Awards has Jake Gyllenhaal be...</td>\n",
       "      <td>1</td>\n",
       "      <td>movies</td>\n",
       "      <td>count</td>\n",
       "      <td>[{'name': 'Q133313', 'entityType': 'entity', '...</td>\n",
       "      <td>[{'name': 'Q106291', 'label': 'Academy Award f...</td>\n",
       "      <td>[1, 2, 3, 4, 5, 11, 6, 0, 8, 7, 9, 10, 13, 12,...</td>\n",
       "      <td>[-0.6568749547, -0.7941160798, -0.851152122, -...</td>\n",
       "      <td>[1, 2, 3, 4, 5, 11, 6, 0, 8, 7, 9, 10, 13, 12,...</td>\n",
       "      <td>Number</td>\n",
       "      <td>[1, 2, 3, 4, 5, 11, 6, 0, 8, 7, 9, 10, 13, 12,...</td>\n",
       "      <td>Number</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>[Q116790562, Q111143758, Q17126303, Q1860, Q27...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>d2a03f72</td>\n",
       "      <td>en</td>\n",
       "      <td>Who is older, The Weeknd or Drake?</td>\n",
       "      <td>Drake</td>\n",
       "      <td>music</td>\n",
       "      <td>comparative</td>\n",
       "      <td>[{'name': 'Q2121062', 'entityType': 'entity', ...</td>\n",
       "      <td>[{'name': 'Q33240', 'label': 'Drake'}]</td>\n",
       "      <td>[Drake, The Weeknd, Cody Jarrett, Dwight D. Ei...</td>\n",
       "      <td>[-0.0174380932, -0.8993775845, -1.415274024, -...</td>\n",
       "      <td>[Q7559, Q2121062, Q5140439, Q9916, Q713099, Q5...</td>\n",
       "      <td>Q5</td>\n",
       "      <td>[Q2121062, Q5140439, Q9916, Q713099, Q513019, ...</td>\n",
       "      <td>Q5</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>[Q1860, Q27, Q145, Q115, Q424, Q30, Q668, Q334...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9a296167</td>\n",
       "      <td>en</td>\n",
       "      <td>How many children did Donald Trump have?</td>\n",
       "      <td>5</td>\n",
       "      <td>history</td>\n",
       "      <td>count</td>\n",
       "      <td>[{'name': 'Q22686', 'entityType': 'entity', 'l...</td>\n",
       "      <td>[{'name': 'Q3713655', 'label': 'Donald Trump J...</td>\n",
       "      <td>[2, 3, 4, 5, 6, 1, 8, 9, 0, 7, 11, 10, 6 child...</td>\n",
       "      <td>[-0.49233829980000005, -1.0202715397, -1.06337...</td>\n",
       "      <td>[2, 3, 4, 5, 6, 1, 8, 9, 0, 7, 11, 10, Q348559...</td>\n",
       "      <td>Number</td>\n",
       "      <td>[2, 3, 4, 5, 6, 1, 8, 9, 0, 7, 11, 10, 13]</td>\n",
       "      <td>Number</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>[Q30, Q1860, Q61, Q30, Q49, Q6256, Q4917, Q627...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>e343ad26</td>\n",
       "      <td>en</td>\n",
       "      <td>Is the main hero in Final Fantasy IX named Kuja?</td>\n",
       "      <td>No</td>\n",
       "      <td>videogames</td>\n",
       "      <td>yesno</td>\n",
       "      <td>[{'name': 'Q474573', 'entityType': 'entity', '...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[Yes, No, Yuna, Yuna, Yuna, Yuna and Kuja are ...</td>\n",
       "      <td>[-0.3390540481, -0.3550684452, -1.4538880587, ...</td>\n",
       "      <td>[True, False, None, None, None, None, None, No...</td>\n",
       "      <td>yesno</td>\n",
       "      <td>[True, False]</td>\n",
       "      <td>yesno</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>[Q99415917, Q312525, Q99397792, Q559618, Q2472...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id lang                                           question   \n",
       "0  fae46b21   en  What man was a famous American author and also...  \\\n",
       "1  bc8713cc   en  How many Academy Awards has Jake Gyllenhaal be...   \n",
       "2  d2a03f72   en                 Who is older, The Weeknd or Drake?   \n",
       "3  9a296167   en           How many children did Donald Trump have?   \n",
       "4  e343ad26   en   Is the main hero in Final Fantasy IX named Kuja?   \n",
       "\n",
       "   answerText    category complexityType   \n",
       "0  Mark Twain     history   intersection  \\\n",
       "1           1      movies          count   \n",
       "2       Drake       music    comparative   \n",
       "3           5     history          count   \n",
       "4          No  videogames          yesno   \n",
       "\n",
       "                                      questionEntity   \n",
       "0  [{'name': 'Q1497', 'entityType': 'entity', 'la...  \\\n",
       "1  [{'name': 'Q133313', 'entityType': 'entity', '...   \n",
       "2  [{'name': 'Q2121062', 'entityType': 'entity', ...   \n",
       "3  [{'name': 'Q22686', 'entityType': 'entity', 'l...   \n",
       "4  [{'name': 'Q474573', 'entityType': 'entity', '...   \n",
       "\n",
       "                                        answerEntity   \n",
       "0         [{'name': 'Q7245', 'label': 'Mark Twain'}]  \\\n",
       "1  [{'name': 'Q106291', 'label': 'Academy Award f...   \n",
       "2             [{'name': 'Q33240', 'label': 'Drake'}]   \n",
       "3  [{'name': 'Q3713655', 'label': 'Donald Trump J...   \n",
       "4                                                 []   \n",
       "\n",
       "                                      generated_text   \n",
       "0  [Edgar Allan Poe, Ernest Hemingway, Charles Di...  \\\n",
       "1  [1, 2, 3, 4, 5, 11, 6, 0, 8, 7, 9, 10, 13, 12,...   \n",
       "2  [Drake, The Weeknd, Cody Jarrett, Dwight D. Ei...   \n",
       "3  [2, 3, 4, 5, 6, 1, 8, 9, 0, 7, 11, 10, 6 child...   \n",
       "4  [Yes, No, Yuna, Yuna, Yuna, Yuna and Kuja are ...   \n",
       "\n",
       "                                    sequences_scores   \n",
       "0  [-0.2734780908, -0.3756849766, -0.418252229700...  \\\n",
       "1  [-0.6568749547, -0.7941160798, -0.851152122, -...   \n",
       "2  [-0.0174380932, -0.8993775845, -1.415274024, -...   \n",
       "3  [-0.49233829980000005, -1.0202715397, -1.06337...   \n",
       "4  [-0.3390540481, -0.3550684452, -1.4538880587, ...   \n",
       "\n",
       "                                  generated_entities answerRetrievedType   \n",
       "0  [Q16867, Q23434, Q5686, Q131149, Q34597, Q3616...                  Q5  \\\n",
       "1  [1, 2, 3, 4, 5, 11, 6, 0, 8, 7, 9, 10, 13, 12,...              Number   \n",
       "2  [Q7559, Q2121062, Q5140439, Q9916, Q713099, Q5...                  Q5   \n",
       "3  [2, 3, 4, 5, 6, 1, 8, 9, 0, 7, 11, 10, Q348559...              Number   \n",
       "4  [True, False, None, None, None, None, None, No...               yesno   \n",
       "\n",
       "                              filtered_by_type_preds goldAnswerRetrievedType   \n",
       "0  [Q16867, Q23434, Q5686, Q131149, Q34597, Q3616...                      Q5  \\\n",
       "1  [1, 2, 3, 4, 5, 11, 6, 0, 8, 7, 9, 10, 13, 12,...                  Number   \n",
       "2  [Q2121062, Q5140439, Q9916, Q713099, Q513019, ...                      Q5   \n",
       "3         [2, 3, 4, 5, 6, 1, 8, 9, 0, 7, 11, 10, 13]                  Number   \n",
       "4                                      [True, False]                   yesno   \n",
       "\n",
       "   isAnswerEntity  is_answer_in_generated   \n",
       "0            True                   False  \\\n",
       "1            True                   False   \n",
       "2            True                   False   \n",
       "3            True                   False   \n",
       "4           False                   False   \n",
       "\n",
       "                                 neighbours_entities  \n",
       "0  [Q30, Q1860, Q61, Q30, Q49, Q6256, Q4917, Q627...  \n",
       "1  [Q116790562, Q111143758, Q17126303, Q1860, Q27...  \n",
       "2  [Q1860, Q27, Q145, Q115, Q424, Q30, Q668, Q334...  \n",
       "3  [Q30, Q1860, Q61, Q30, Q49, Q6256, Q4917, Q627...  \n",
       "4  [Q99415917, Q312525, Q99397792, Q559618, Q2472...  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question_entities_neighbours_df['neighbours_entities'] = question_entities_neighbours_df['two_hop_neighbours'].apply(\n",
    "    lambda triplet_list: [triplet[-1] for triplet in triplet_list]\n",
    ")\n",
    "test_df = test_df.merge(question_entities_neighbours_df[['id', 'neighbours_entities']], on='id')\n",
    "test_df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtered by by availability in question entities two hop forward neighbours With oracle for question: is answer entity or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Group          Hits@1 (Correct Of Total)\n",
      "All          = 0.2795 (1118 Of 4000)\n",
      "\n",
      "comparative  = 0.4725 ( 189 Of  400)\n",
      "count        = 0.2700 ( 108 Of  400)\n",
      "difference   = 0.1925 (  77 Of  400)\n",
      "generic      = 0.2325 ( 186 Of  800)\n",
      "intersection = 0.3025 ( 121 Of  400)\n",
      "multihop     = 0.1075 (  43 Of  400)\n",
      "ordinal      = 0.1500 (  60 Of  400)\n",
      "superlative  = 0.3550 ( 142 Of  400)\n",
      "yesno        = 0.4800 ( 192 Of  400)\n",
      "\n",
      "Q5           = 0.3115 ( 314 Of 1008)\n",
      "Number       = 0.1549 ( 127 Of  820)\n",
      "yesno        = 0.4651 ( 253 Of  544)\n",
      "Q11424       = 0.1721 (  42 Of  244)\n",
      "Q7889        = 0.2649 (  49 Of  185)\n",
      "Q3624078     = 0.4253 (  37 Of   87)\n",
      "Q35657       = 0.3924 (  31 Of   79)\n",
      "Q482994      = 0.0870 (   6 Of   69)\n",
      "Q7725634     = 0.2000 (  13 Of   65)\n",
      "Q1093829     = 0.3462 (  18 Of   52)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def take_answer_filtered_by_two_hop_neighbours(row):\n",
    "    filtered_candidates = [e for e in row['generated_entities'] if e in row['neighbours_entities']]\n",
    "    if row['isAnswerEntity'] is True and len(filtered_candidates) > 0:\n",
    "        return filtered_candidates[0]\n",
    "    else:\n",
    "        return row['generated_entities'][0]\n",
    "\n",
    "preds = test_df.apply(\n",
    "    take_answer_filtered_by_two_hop_neighbours,\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "df = calculate_metrics_for_prediction(\n",
    "    dict(zip(dataset[dataset_split]['id'], preds)),\n",
    "    dataset_split,\n",
    "    'kg',\n",
    ")\n",
    "df['answerRetrievedType'] = test_df['answerRetrievedType']\n",
    "_ = print_eval(df=df, groupbycols=['complexityType', 'answerRetrievedType'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtered by by Type and availability in question entities two hop forward neighbours With oracle for question: is answer entity or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Group          Hits@1 (Correct Of Total)\n",
      "All          = 0.2757 (1103 Of 4000)\n",
      "\n",
      "comparative  = 0.4625 ( 185 Of  400)\n",
      "count        = 0.2700 ( 108 Of  400)\n",
      "difference   = 0.1775 (  71 Of  400)\n",
      "generic      = 0.2263 ( 181 Of  800)\n",
      "intersection = 0.2950 ( 118 Of  400)\n",
      "multihop     = 0.1100 (  44 Of  400)\n",
      "ordinal      = 0.1550 (  62 Of  400)\n",
      "superlative  = 0.3550 ( 142 Of  400)\n",
      "yesno        = 0.4800 ( 192 Of  400)\n",
      "\n",
      "Q5           = 0.3115 ( 314 Of 1008)\n",
      "Number       = 0.1549 ( 127 Of  820)\n",
      "yesno        = 0.4651 ( 253 Of  544)\n",
      "Q11424       = 0.1393 (  34 Of  244)\n",
      "Q7889        = 0.2595 (  48 Of  185)\n",
      "Q3624078     = 0.4483 (  39 Of   87)\n",
      "Q35657       = 0.3924 (  31 Of   79)\n",
      "Q482994      = 0.1159 (   8 Of   69)\n",
      "Q7725634     = 0.2308 (  15 Of   65)\n",
      "Q1093829     = 0.2885 (  15 Of   52)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def take_answer_filtered_by_types_and_two_hop_neighbours(row):\n",
    "    filtered_candidates = [e for e in row['filtered_by_type_preds'] if e in row['neighbours_entities']]\n",
    "    if row['isAnswerEntity'] is True and len(filtered_candidates) > 0:\n",
    "        return filtered_candidates[0]\n",
    "    else:\n",
    "        return row['generated_entities'][0]\n",
    "\n",
    "preds = test_df.apply(\n",
    "    take_answer_filtered_by_types_and_two_hop_neighbours,\n",
    "    axis=1\n",
    ")\n",
    "df = calculate_metrics_for_prediction(\n",
    "    dict(zip(dataset[dataset_split]['id'], preds)),\n",
    "    dataset_split,\n",
    "    'kg',\n",
    ")\n",
    "df['answerRetrievedType'] = test_df['answerRetrievedType']\n",
    "_ = print_eval(df=df, groupbycols=['complexityType', 'answerRetrievedType'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter question entities two hop forward neighbours (Only TOP-100) by type extracted from seq2seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "105a8bbf165345c2bf4b6759c769cb8f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Group          Hits@1 (Correct Of Total)\n",
      "All          = 0.1978 ( 791 Of 4000)\n",
      "\n",
      "comparative  = 0.3350 ( 134 Of  400)\n",
      "count        = 0.2700 ( 108 Of  400)\n",
      "difference   = 0.1100 (  44 Of  400)\n",
      "generic      = 0.1288 ( 103 Of  800)\n",
      "intersection = 0.1500 (  60 Of  400)\n",
      "multihop     = 0.0775 (  31 Of  400)\n",
      "ordinal      = 0.0925 (  37 Of  400)\n",
      "superlative  = 0.2050 (  82 Of  400)\n",
      "yesno        = 0.4800 ( 192 Of  400)\n",
      "\n",
      "Q5           = 0.1359 ( 137 Of 1008)\n",
      "Number       = 0.1549 ( 127 Of  820)\n",
      "yesno        = 0.4651 ( 253 Of  544)\n",
      "Q11424       = 0.1230 (  30 Of  244)\n",
      "Q7889        = 0.1514 (  28 Of  185)\n",
      "Q3624078     = 0.1494 (  13 Of   87)\n",
      "Q35657       = 0.2658 (  21 Of   79)\n",
      "Q482994      = 0.0725 (   5 Of   69)\n",
      "Q7725634     = 0.1077 (   7 Of   65)\n",
      "Q1093829     = 0.1346 (   7 Of   52)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def take_answer_filtered_by_types_from_two_hop_neighbours(row):\n",
    "    if row['isAnswerEntity'] is True:\n",
    "        for entity_id in row['neighbours_entities'][:100]:\n",
    "            answer_type = AnswerItem(entity_id).type\n",
    "            if isinstance(answer_type, list):\n",
    "                if row['answerRetrievedType'] in [e.idx for e in answer_type]:\n",
    "                    return entity_id\n",
    "            elif answer_type == row['answerRetrievedType']:\n",
    "                return entity_id\n",
    "\n",
    "    return row['generated_entities'][0]\n",
    "\n",
    "preds = test_df.progress_apply(\n",
    "    take_answer_filtered_by_types_from_two_hop_neighbours,\n",
    "    axis=1\n",
    ")\n",
    "df = calculate_metrics_for_prediction(\n",
    "    dict(zip(dataset[dataset_split]['id'], preds)),\n",
    "    dataset_split,\n",
    "    'kg',\n",
    ")\n",
    "df['answerRetrievedType'] = test_df['answerRetrievedType']\n",
    "_ = print_eval(df=df, groupbycols=['complexityType', 'answerRetrievedType'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Request two hop question entities neighbours forward and backward filtered by retrieved type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>two_hop_neighbours</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>fae46b21</td>\n",
       "      <td>[[Q1497, P19, Q5075459], [Q5075459, P22, Q2020...</td>\n",
       "      <td>Q5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>d2a03f72</td>\n",
       "      <td>[[Q2121062, P451, Q21286612], [Q21286612, P451...</td>\n",
       "      <td>Q5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>b41ae115</td>\n",
       "      <td>[]</td>\n",
       "      <td>Q5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7ed1858c</td>\n",
       "      <td>[[Q128532, P161, Q20949964], [Q20949964, P136,...</td>\n",
       "      <td>Q11424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>bfc9807b</td>\n",
       "      <td>[]</td>\n",
       "      <td>Q35657</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id                                 two_hop_neighbours    type\n",
       "0  fae46b21  [[Q1497, P19, Q5075459], [Q5075459, P22, Q2020...      Q5\n",
       "1  d2a03f72  [[Q2121062, P451, Q21286612], [Q21286612, P451...      Q5\n",
       "2  b41ae115                                                 []      Q5\n",
       "3  7ed1858c  [[Q128532, P161, Q20949964], [Q20949964, P136,...  Q11424\n",
       "4  bfc9807b                                                 []  Q35657"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from pywikidata.utils import request_to_wikidata\n",
    "\n",
    "# def get_neighbours_with_type_filter(\n",
    "#     entity_id: str,\n",
    "#     type_entity_id: str, # InstanceOf or SubclassOf\n",
    "# ):\n",
    "#     query = \"\"\"\n",
    "#     PREFIX wd: <http://www.wikidata.org/entity/>\n",
    "#     PREFIX wdt: <http://www.wikidata.org/prop/direct/>\n",
    "\n",
    "#     SELECT DISTINCT ?property ?object WHERE {\n",
    "#     VALUES ?p { wdt:P31 wdt:P279 } \n",
    "#     {\n",
    "#         ?object ?property wd:<ENTITY> .\n",
    "#         ?object ?p wd:<TYPE>\n",
    "#     } UNION {\n",
    "#         wd:<ENTITY> ?property ?object .\n",
    "#         ?object ?p wd:<TYPE> .\n",
    "#     }\n",
    "#     }\n",
    "#     \"\"\".replace('<ENTITY>', entity_id).replace('<TYPE>', type_entity_id)\n",
    "#     for responce in request_to_wikidata(query):\n",
    "#         yield Entity(responce['property']['value']), Entity(responce['object']['value'])\n",
    "\n",
    "\n",
    "# for _, row in tqdm(test_df.iterrows(), total=test_df.index.size, desc='two_hop_neighbours_type_filtered'):\n",
    "#     with open(f'mintaka_test_question_entities_two_hop_neighbours_filtered_by_type.jsonl', 'a+') as f:\n",
    "#         try:\n",
    "#             if Entity._validate_entity_id(row['answerRetrievedType']):\n",
    "#                 question_entities = [\n",
    "#                     Entity(e['name'])\n",
    "#                     for e in row['questionEntity']\n",
    "#                     if e['entityType'] == 'entity' and 'Q' == e['name'][0]\n",
    "#                 ]\n",
    "\n",
    "#                 question_entities_neighbours = []\n",
    "#                 for q_entity in question_entities:\n",
    "#                     for one_hop_neighbour_prop, one_hop_neighbour_entity in get_neighbours_with_type_filter(q_entity.idx, row['answerRetrievedType']):\n",
    "#                         question_entities_neighbours.append((\n",
    "#                             q_entity.idx,\n",
    "#                             one_hop_neighbour_prop.idx,\n",
    "#                             one_hop_neighbour_entity.idx,\n",
    "#                         ))\n",
    "\n",
    "#                         for two_hop_neighbour_prop, two_hop_neighbour_entity in get_neighbours_with_type_filter(one_hop_neighbour_entity.idx, row['answerRetrievedType']):\n",
    "#                             question_entities_neighbours.append((\n",
    "#                                 one_hop_neighbour_entity.idx,\n",
    "#                                 two_hop_neighbour_prop.idx,\n",
    "#                                 two_hop_neighbour_entity.idx,\n",
    "#                             ))\n",
    "\n",
    "#                 f.write(\n",
    "#                     ujson.dumps({\n",
    "#                         'id': row['id'],\n",
    "#                         'two_hop_neighbours': question_entities_neighbours,\n",
    "#                         'type': row['answerRetrievedType'],\n",
    "#                     }) + '\\n'\n",
    "#                 )\n",
    "#         except Exception as e:\n",
    "#             print(f\"Error with id={row['id']}: {e}\")\n",
    "#             break\n",
    "\n",
    "\n",
    "question_entities_filtered_neighbours_df = pd.read_json(\n",
    "    f'mintaka_test_question_entities_two_hop_neighbours_filtered_by_type.jsonl',\n",
    "    lines=True,\n",
    ")\n",
    "question_entities_filtered_neighbours_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count       96.000000\n",
       "mean      4842.677083\n",
       "std      12761.744159\n",
       "min          0.000000\n",
       "25%         95.000000\n",
       "50%        358.500000\n",
       "75%       2492.500000\n",
       "max      85216.000000\n",
       "Name: two_hop_neighbours, dtype: float64"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question_entities_filtered_neighbours_df['two_hop_neighbours'].apply(len).describe()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate ChatGPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>predText</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>fae46b21</td>\n",
       "      <td>Mark Twain.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bc8713cc</td>\n",
       "      <td>Zero.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>d2a03f72</td>\n",
       "      <td>The Weeknd.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9a296167</td>\n",
       "      <td>5.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>e343ad26</td>\n",
       "      <td>No.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id     predText\n",
       "0  fae46b21  Mark Twain.\n",
       "1  bc8713cc        Zero.\n",
       "2  d2a03f72  The Weeknd.\n",
       "3  9a296167           5.\n",
       "4  e343ad26          No."
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpt_preds = pd.read_json('mintaka_test_chatgpt_gpt_3_5_turbo_0301_answers.jsonl', lines=True)\n",
    "gpt_preds.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Group          Hits@1 (Correct Of Total)\n",
      "All          = 0.3425 (1370 Of 4000)\n",
      "\n",
      "comparative  = 0.3500 ( 140 Of  400)\n",
      "count        = 0.2950 ( 118 Of  400)\n",
      "difference   = 0.1900 (  76 Of  400)\n",
      "generic      = 0.5250 ( 420 Of  800)\n",
      "intersection = 0.5275 ( 211 Of  400)\n",
      "multihop     = 0.3075 ( 123 Of  400)\n",
      "ordinal      = 0.4100 ( 164 Of  400)\n",
      "superlative  = 0.2950 ( 118 Of  400)\n",
      "yesno        = 0.0000 (   0 Of  400)\n",
      "\n",
      "books        = 0.3240 ( 162 Of  500)\n",
      "geography    = 0.3720 ( 186 Of  500)\n",
      "history      = 0.3480 ( 174 Of  500)\n",
      "movies       = 0.2900 ( 145 Of  500)\n",
      "music        = 0.3260 ( 163 Of  500)\n",
      "politics     = 0.3920 ( 196 Of  500)\n",
      "sports       = 0.3880 ( 194 Of  500)\n",
      "videogames   = 0.3000 ( 150 Of  500)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "_ = print_eval(dict(gpt_preds.values), mode='text')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "785ba5a4f7d640688d4ecdfb83044f3a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Group          Hits@1 (Correct Of Total)\n",
      "All          = 0.3595 (1438 Of 4000)\n",
      "\n",
      "comparative  = 0.6750 ( 270 Of  400)\n",
      "count        = 0.2175 (  87 Of  400)\n",
      "difference   = 0.1325 (  53 Of  400)\n",
      "generic      = 0.3563 ( 285 Of  800)\n",
      "intersection = 0.3650 ( 146 Of  400)\n",
      "multihop     = 0.1975 (  79 Of  400)\n",
      "ordinal      = 0.2225 (  89 Of  400)\n",
      "superlative  = 0.2025 (  81 Of  400)\n",
      "yesno        = 0.8700 ( 348 Of  400)\n",
      "\n",
      "books        = 0.3080 ( 154 Of  500)\n",
      "geography    = 0.3820 ( 191 Of  500)\n",
      "history      = 0.3440 ( 172 Of  500)\n",
      "movies       = 0.3480 ( 174 Of  500)\n",
      "music        = 0.3120 ( 156 Of  500)\n",
      "politics     = 0.4380 ( 219 Of  500)\n",
      "sports       = 0.3960 ( 198 Of  500)\n",
      "videogames   = 0.3480 ( 174 Of  500)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gpt_preds['predKG'] = gpt_preds['predText'].progress_apply(AnswerItem.text_to_answer)\n",
    "\n",
    "_ = print_eval(dict(gpt_preds[['id', 'predKG']].values), mode='kg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79a528aa76944486b8f30fc506b7f0f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>question</th>\n",
       "      <th>translations</th>\n",
       "      <th>questionEntity</th>\n",
       "      <th>answer</th>\n",
       "      <th>category</th>\n",
       "      <th>complexityType</th>\n",
       "      <th>pred</th>\n",
       "      <th>exact_match</th>\n",
       "      <th>f1</th>\n",
       "      <th>hits1</th>\n",
       "      <th>predKG</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>fae46b21</td>\n",
       "      <td>What man was a famous American author and also...</td>\n",
       "      <td>{'ar': '      ...</td>\n",
       "      <td>[{'name': 'Q1497', 'entityType': 'entity', 'la...</td>\n",
       "      <td>Mark Twain</td>\n",
       "      <td>history</td>\n",
       "      <td>intersection</td>\n",
       "      <td>Mark Twain.</td>\n",
       "      <td>True</td>\n",
       "      <td>0.5</td>\n",
       "      <td>True</td>\n",
       "      <td>Q7245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bc8713cc</td>\n",
       "      <td>How many Academy Awards has Jake Gyllenhaal be...</td>\n",
       "      <td>{'ar': '       ...</td>\n",
       "      <td>[{'name': 'Q133313', 'entityType': 'entity', '...</td>\n",
       "      <td>1</td>\n",
       "      <td>movies</td>\n",
       "      <td>count</td>\n",
       "      <td>Zero.</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>Q204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>d2a03f72</td>\n",
       "      <td>Who is older, The Weeknd or Drake?</td>\n",
       "      <td>{'ar': '   The Weeknd  Drake'...</td>\n",
       "      <td>[{'name': 'Q2121062', 'entityType': 'entity', ...</td>\n",
       "      <td>Drake</td>\n",
       "      <td>music</td>\n",
       "      <td>comparative</td>\n",
       "      <td>The Weeknd.</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>Q2121062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9a296167</td>\n",
       "      <td>How many children did Donald Trump have?</td>\n",
       "      <td>{'ar': '    ', 'de': 'Wi...</td>\n",
       "      <td>[{'name': 'Q22686', 'entityType': 'entity', 'l...</td>\n",
       "      <td>5</td>\n",
       "      <td>history</td>\n",
       "      <td>count</td>\n",
       "      <td>5.</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>e343ad26</td>\n",
       "      <td>Is the main hero in Final Fantasy IX named Kuja?</td>\n",
       "      <td>{'ar': '       F...</td>\n",
       "      <td>[{'name': 'Q474573', 'entityType': 'entity', '...</td>\n",
       "      <td>False</td>\n",
       "      <td>videogames</td>\n",
       "      <td>yesno</td>\n",
       "      <td>No.</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id                                           question   \n",
       "0  fae46b21  What man was a famous American author and also...  \\\n",
       "1  bc8713cc  How many Academy Awards has Jake Gyllenhaal be...   \n",
       "2  d2a03f72                 Who is older, The Weeknd or Drake?   \n",
       "3  9a296167           How many children did Donald Trump have?   \n",
       "4  e343ad26   Is the main hero in Final Fantasy IX named Kuja?   \n",
       "\n",
       "                                        translations   \n",
       "0  {'ar': '      ...  \\\n",
       "1  {'ar': '       ...   \n",
       "2  {'ar': '   The Weeknd  Drake'...   \n",
       "3  {'ar': '    ', 'de': 'Wi...   \n",
       "4  {'ar': '       F...   \n",
       "\n",
       "                                      questionEntity      answer    category   \n",
       "0  [{'name': 'Q1497', 'entityType': 'entity', 'la...  Mark Twain     history  \\\n",
       "1  [{'name': 'Q133313', 'entityType': 'entity', '...           1      movies   \n",
       "2  [{'name': 'Q2121062', 'entityType': 'entity', ...       Drake       music   \n",
       "3  [{'name': 'Q22686', 'entityType': 'entity', 'l...           5     history   \n",
       "4  [{'name': 'Q474573', 'entityType': 'entity', '...       False  videogames   \n",
       "\n",
       "  complexityType         pred  exact_match   f1  hits1    predKG  \n",
       "0   intersection  Mark Twain.         True  0.5   True     Q7245  \n",
       "1          count        Zero.        False  0.0  False      Q204  \n",
       "2    comparative  The Weeknd.        False  0.0  False  Q2121062  \n",
       "3          count           5.         True  0.0   True         5  \n",
       "4          yesno          No.        False  0.0  False     False  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpt_df = calculate_metrics_for_prediction(dict(gpt_preds[['id', 'predText']].values), split='test', mode='text')\n",
    "gpt_df['predKG'] = gpt_df['pred'].progress_apply(AnswerItem.text_to_answer)\n",
    "gpt_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
